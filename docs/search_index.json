[["index.html", "Introdução à Bioestatística usando o R Capítulo 1 Introdução 1.1 Importância da Bioestatística 1.2 Pílulas históricas da Estatística 1.3 História resumida do R", " Introdução à Bioestatística usando o R Petrônio Fagundes de Oliveira Filho 2023-04-22 Capítulo 1 Introdução 1.1 Importância da Bioestatística Os indivíduos variam em relação as suas características biológicas, psicológicas e sociais na saúde e na doença. Esta variabilidade gera uma grande quantidade de incertezas. A Bioestatística, estatística aplicada às ciências biológicas e da saúde, é a ferramenta utilizada pelos pesquisadores para trabalhar com essas incertezas advindas da variabilidade. Várias definições foram escritas para a estatística, uma delas é a seguinte (1): Estatística é a disciplina interessada com o tratamento dos dados numéricos obtidos a partir de grupos de indivíduos A Bioestatística lida com a variabilidade humana utilizando técnicas estatísticas quantitativas (2) que ajudam a diminuir a ignorância em relação a esta diversidade. A compreensão da variabilidade humana torna a medicina mais ciência, diminuindo as incertezas, na tentativa de verificar se os resultados encontrados de fato existem ou são apenas obra do acaso. Na década de 1990, houve um acesso maior aos computadores. Os profissionais da saúde não estatísticos passaram a ter mais interesse no campo da bioestatística. Isto gerou uma onda que facilitou o aparecimento de novas ferramentas estatísticas de ponta. Apesar disso, o conhecimento da Bioestatística permanece restrito aos especialistas na área. Nos últimos anos, os pacotes de softwares foram aprimorados, tornando-se mais amigáveis e diminuindo significativamente o pânico ao se defrontar com uma série de números uma vez que a maioria deles exige apenas conhecimento básico de matemática. Para a tomada de decisão em saúde é fundamental o acúmulo de conhecimento adquirido através da prática clínica, geradora da experiência do profissional, do intercâmbio com os pares e da análise adequada das evidências científicas publicadas em periódicos de qualidade. Para atingir este objetivo, é fundamental o conhecimento de bioestatística, incluindo aqui que o pensamento que deve nortear os profissionais da saúde ao lidar com o ser humano é o pensamento probabilístico. 1.2 Pílulas históricas da Estatística A história deve começar em algum lugar, mas a história não tem começo (3) Entretanto, é natural, que se trace as raízes voltando ao passado, tanto quanto possível. Alguns referem-se à curiosidade em relação ao registro de dados à dinastia Shank, na China, possivelmente no século XIII a.c, com a realização de censos populacionais. Há relatos bíblicos de possíveis censos realizados por Moisés (1491 a.C.) e por Davi (1017 a.C.). Os romanos e os gregos já realizavam censos por volta do século VIII a IV a.C. Em 578-534 a.C., o imperador Servo Túlio mandou realizar um censo de população masculina adulta e suas propriedades que serviu para estabelecer o recrutamento para o exército, para o exercício dos direitos políticos e para o pagamento de impostos. Os romanos fizeram 72 censos entre 555 a.C. e 72 d.C. A punição para quem não respondia, geralmente era a morte! Na Idade Média, na Europa, existem registros de diversos censos: durante o domínio muçulmano, na Península Ibérica, nos séculos VII a XV; no reinado de Carlos Magno (712-814) e ainda o maior registro estatístico feito na época, o Domesday Book (Figura 1.1), realizado na Inglaterra, por Guilherme I (3) , o Conquistador, onde registravam nascimentos, mortes, batismos e casamentos. Houve, também, recenseamentos nas repúblicas italianas no século XII ao XIII (4). Figure 1.1: Domesday Book John Graunt (24/04/1620 - 18/04/1674) foi um cientista britânico a quem se deve vários estudos demográficos ingleses. Foi o precursor da construção de Tábuas de Mortalidade. Realizou estudos com William Petty (1623 - 1687), economista britânico que propôs a aritmética política. Em 1791, Sir John Sinclair (1754 - 1835) concebeu um plano de uma pesquisa empírica na Escócia para fornecer informações estatísticas. Foi a primeira vez que o termo estatística foi usado em inglês. Girolamo Cardano (24/09/1501 - 21/09/1576) foi um médico, matemático, físico e filósofo italiano. É tido como o primeiro a introduzir ideias gerais da teoria das equações algébricas e as primeiras regras da probabilidade, descritas no livro Liber de Ludo Aleae, publicado em 1663. Descreveu pela primeira vez a clínica da febre tifoide. Foi amigo de Leonardo da Vinci. Pierre-Simon Laplace, Marquês Laplace (23/03/1749 - 05/03/1927) foi um matemático, astrônomo e físico francês. Embora conduzisse pesquisas substanciais sobre física, outro tema principal dos esforços de sua vida foi a teoria das probabilidades. Em seu Essai philosophique sur les probabilités, Laplace projetou um sistema matemático de raciocínio indutivo baseado em probabilidades, que hoje coincidem com as ideias bayesianas. Antoine Gombaud, conhecido como Chevalier de Méré (1607 - 1684) foi um nobre e jogador. Como não tinha mais sucesso nos jogos de azar, buscou ajuda de Blaise Pascal (19/06/1623 – 19/08/1662), matemático, físico francês, que se correspondeu com Pierre Fermat (matemático e cientista francês), nascendo desta colaboração a teoria matemática das probabilidades (1812). Blaise Pascal foi mais tarde chamado de o Pai da Teoria das Probabilidades. A moderna teoria das probabilidades foi atribuída a Abraham De Moivre (25/05/1667 – 27/11/1754), matemático francês, que adquiriu fama por seus estudos na trigonometria, teoria das probabilidades e pela equação da curva normal. Em 1742, Thomas Bayes (1701 – 07/04/1761, matemático e pastor presbiteriano, inglês, desenvolveu o Teorema de Bayes que descreve a probabilidade de um evento ocorrer, baseado em um conhecimento a priori. Adrien-Marie Legendre (18/09/1752 - 10/01/1833) foi um matemático francês. Em 1783, tornou-se membro adjunto da Academie des Sciences, instituição que esteve na vanguarda dos desenvolvimentos científicos dos séculos XVII e XVIII. Fez importantes contribuições à estatística, à teoria dos números e à álgebra abstrata. Johann Carl Friedrich Gauss (30/04/1777 - 23/02/1855) foi um matemático, astrônomo e físico alemão (Figura 1.2) que contribuiu em diversas áreas das ciências como teoria dos números, estatística, geometria diferencial, eletrostática, astronomia e ótica. Muitos referem-se a ele como o Príncipe da Matemática, o mais notável dos matemáticos. Descobriu o método dos mínimos quadrados e a lei de Gauss da distribuição normal de erros e sua curva em formato de sino, hoje tão familiar para todos que trabalham com estatística. Figure 1.2: Johann Carl Friedrich Gauss Lambert Adolphe Jacques Quételet (22/02/1796 - 17/02/1874) foi um astrônomo, matemático, demógrafo e estatístico francês. Seu trabalho se concentrou em estatística social, criando regras de determinação de propensão ao crime Francis Galton (16/02/1822 – 17/01/1911) foi um antropólogo, matemático e estatístico inglês. Entre muitos artigos e livros, criou o conceito estatístico de correlação e da regressão à média. Ele foi o primeiro a aplicar métodos estatísticos para o estudo das diferenças e herança humanas de inteligência. Criou o conceito de eugenia e afirmava que era possível a melhoria da espécie por seleção artificial. Acreditava que a raça humana poderia ser melhorada caso fossem evitados relacionamentos indesejáveis. Isto acompanhava o pensamento burguês europeu da época. Criou a psicometria, onde desenvolveu testes de inteligência para selecionar homens e mulheres brilhantes. Esta teoria teve papel importante na formação do fascismo e nazismo (5). William Farr (30/11/1807 - 14/04/1883) foi um médico sanitarista e estatístico inglês, nascido na vila de Kenley, Shropshire. Foi o primeiro investigador a examinar séries temporais de morbimortalidade para longos períodos e, assim, considerado o criador da Estatística da Saúde Pública Moderna. Seus relatórios foram fundamentais para o desencadeamento das reformas sanitárias britânicas, em meados e final do século XIX (6). Florence Nightingale (12/05/1820 – 13/08/1910) foi uma enfermeira (Figura 1.3) que ficou famosa por ser pioneira no tratamento de feridos, durante a Guerra da Criméia (7). Ficou conhecida na história pelo apelido de “A dama da lâmpada”, pelo fato de servir-se de uma lamparina para auxiliar no cuidado aos feridos durante a noite. Também contribuiu no campo da Estatística, sendo pioneira na utilização de métodos de representação visual de informações, como por exemplo gráfico de setores (habitualmente conhecido como gráfico do tipo “pizza”) Figure 1.3: Florence Nightingale John Snow (York, 15/03/1813 - Londres, 15/03/1858) foi um médico inglês (Figura 1.4), considerado pai da Epidemiologia Moderna. Recebeu, em 1853, o título de Sir após ter anestesiado a rainha Vitória no parto sem dor de seu oitavo filho, Leopoldo de Albany. Este fato ajudou a divulgar a técnica entre os médicos da época. Demonstrou que a cólera era causada pelo consumo de águas contaminadas com matérias fecais, ao comprovar que os casos dessa doença se agrupavam em determinados locais da cidade de Londres, em 1854, onde havia fontes dessas águas (6). Figure 1.4: John Snow Karl Pearson (27/03/1857 - 27/04/1936) foi um importante estatístico inglês, fundador do Departamento de Estatística Aplicada da University College London em 1911. Juntamente com Weldon e Galton fundou, em 1901, a revista Biometrika com o objetivo era desenvolver as teorias estatísticas, editada até os dias de hoje. O trabalho de Pearson como estatístico fundamentou muitos métodos estatísticos de uso comum, nos dias atuais: regressão linear e o coeficiente de correlação, teste do qui-quadrado de Pearson, classificação das distribuições (8). Charles Edward Spearman (10/09/1863 - 17/09/1945) foi um psicólogo inglês conhecido pelo seu trabalho na área da estatística, como um pioneiro da análise fatorial e pelo coeficiente de correlação de postos de Spearman. Ele também fez bons trabalhos de modelos da inteligência humana. William Sealy Gosset (13/07/1876 - 16/10/1937) foi um químico e estatístico inglês (Figura 1.5). Em 1907, enquanto trabalhava químico da cervejaria experimental de Arthur Guinness &amp; Son, criou a distribuição t que usou para identificar a melhor variedade de cevada, trabalhando com pequenas amostras. A cervejaria Guinness tinha uma política que proibia que seus empregados publicassem suas descobertas em seu próprio nome. Ele, então, usou o pseudônimo “Student” e o teste é chamado “t de Student” em sua homenagem (9). Figure 1.5: William Sealy Gosset Ronald Aylmer Fisher (17/02/1890 - 29/07/1962) foi um estatístico, biólogo e geneticista inglês. Em 1919, Fisher se envolveu com pesquisa agrícola no centro de experimentos de Rothamsted Research, em Harpenden, Inglaterra, e desenvolveu novas metodologias e teoria no ramo de experimentos (10). Durante sua vida, Fisher (Figura 1.6) escreveu 7 livros e publicou cerca de 400 artigos acadêmicos em estatística e genética . Em um dos seus livros, The design of Experiments (1935), Fisher relata um experimento que surgiu de uma pergunta curiosa: o gosto do chá muda de acordo com a ordem em que as ervas e o leite são colocados? Essa simples questão resultou em um estudo pioneiro na área e serviu de sustentação para análise da aleatorização de dados experimentais (9). Ronald A. Fisher foi descrito (11) como “um gênio que criou praticamente sozinho os fundamentos para o moderno pensamento estatístico”. Era muito temperamental. Seus atritos com outros estatísticos ficaram famosos, entre eles encontra-se ninguém menos do que Karl Pearson, outro notável estatístico. Figure 1.6: Ronald A. Fisher Austin Bradford Hill (08/07/1897 - 18 /04/1991) foi um epidemiologista e estatístico inglês (Figura 1.7), pioneiro no estudo do acaso nos ensaios clínicos e, juntamente com Richard Doll, foi o primeiro a demonstrar a ligação entre o uso do cigarro e o câncer de pulmão. Hill é amplamente conhecido pelos Critérios de Hill, conjunto de critérios para a determinação de uma associação causal (12). Figure 1.7: Bradford Hill John Wilder Tukey (16/06/1915 - 26/07/2000) foi um estatístico norte-americano. Desenvolveu uma filosofia para a análise de dados que mudou a maneira de pensar dos estatísticos, sugerindo que se faça uma visualização dos dados, interpretando o formato, centro, dispersão, presença de valores atípicos, sumarizar numericamente e por fim escolher um modelo matemático. Foi o criador do boxplot e introduziu a palavra “bit” como uma contração do termo binary digit. Douglas G. Altman (12 /07/1948 - 03/06/2018) foi um estatístico inglês (Figura 1.8), conhecido por seu trabalho em melhorar a confiabilidade dos artigos de pesquisa médica (13) e por artigos altamente citados sobre metodologia estatística. Ele foi professor de estatística em medicina na Universidade de Oxford. Há praticamente 30 anos, Altman (14) escreveu um artigo sobre problema da qualidade da pesquisa em medicina que causou um grande impacto e permanece válido até hoje. Nesta publicação ele afirma: A má qualidade de muitas pesquisas médicas é amplamente reconhecida, mas, de forma perturbadora, os líderes da profissão médica parecem apenas minimamente preocupados com o problema e não fazem nenhum esforço aparente para encontrar uma solução. Figure 1.8: Douglas G. Altman 1.3 História resumida do R O R é uma linguagem e um ambiente de desenvolvimento voltado fundamentalmente para a computação estatística. Foi inspirado em duas linguagens: S (John Chambers, do Bell Labs) que forneceu a sintaxe e Scheme (Hal Abelson e Gerald Sussman) implementou e forneceu a semântica. O nome R provém em parte das iniciais dos criadores, George Ross Ihaka e Robert Gentleman (Figura 1.9), e também de um jogo figurado com a linguagem S. Em 29 de Fevereiro de 2000, o software foi considerado com funcionalidades e estável o suficiente para a versão 1.0. O R é um projeto GNU 1. Software Livre significa que os usuários têm liberdade para executar, copiar, distribuir, estudar, alterar e melhorar o software. Foi desenvolvido em um esforço colaborativo de pessoas em vários locais do mundo (15). O projeto R fornece uma grande variedade de técnicas estatísticas e gráficas. É uma linguagem e um ambiente similar ao S. A linguagem do S que também é uma linguagem de computador voltada para cálculos estatísticos. Um dos pontos fortes de R é a facilidade com que produções gráficas de qualidade podem ser produzidas. O R é também altamente expansível com o uso dos pacotes, que são bibliotecas para sub-rotinas específicas ou áreas de estudo específicas. Um conjunto de pacotes é incluído com a instalação de R e muito outros estão disponíveis na rede de distribuição do R - Comprehensive R Archive Network (CRAN) (16). Figure 1.9: Robert Gentlemen (E) e George Ross (D) A linguagem R é largamente usada entre estatísticos e analistas de dados para desenvolver softwares de estatística e análise de dados. Pesquisas e levantamentos com profissionais da área mostram que a popularidade do R aumentou substancialmente nos últimos anos (17). Esta sigla está associada ao animal gnu africano, símbolo de software de distribuição livre, quer dizer is Not Unix, sigla recursiva muito comum entre nerds!↩︎ "],["natureza-dos-dados.html", "Capítulo 2 Natureza dos Dados 2.1 Variáveis e Dados 2.2 População e Amostra 2.3 Estimativas e Parâmetros 2.4 Escalas de medição 2.5 Tipos de Variáveis", " Capítulo 2 Natureza dos Dados 2.1 Variáveis e Dados As pesquisas manuseiam dados referentes às variáveis que estão sendo estudadas. Variável é toda característica ou condição de interesse que pode de ser mensurada ou observada em cada elemento de uma amostra ou população. Como o próprio nome diz, seus valores são passíveis variar de um indivíduo a outro ou no mesmo indivíduo. Em contraste com a variável, o valor de uma constante é fixo. As variáveis podem ter valores numéricos ou não numéricos. O resultado da mensuração ou observação de uma variável é denominado dado. A Tabela 2.1 mostra um conjunto de variáveis e suas medidas (dados) de um grupo de pacientes internados em uma determinada UTI. O termo medida deve ser entendido num sentido amplo, pois não é possível “medir” o sexo (observação) ou o estado geral (critérios) de alguém, ao contrário do peso e da pressão arterial que podem ser mensurados com instrumentos. Table 2.1: Variáveis e dados. Id Nome Idade Sexo PAS PAD Estado Geral 1 45 João masculino 140 90 bom 2 32 Maria feminino 110 70 regular 3 27 Pedro masculino 120 80 grave 4 18 Teresa feminino 100 60 bom 2.2 População e Amostra Na pesquisa em saúde, a não ser quando se realiza um censo, coleta-se dados de um subconjunto de indivíduos denominado de amostra, pertencente a um grupo maior, conhecido como população. A população de interesse é, geralmente, chamada de população-alvo. A amostra para ser representativa da população deve ter as mesmas características desta. A partir dos dados encontrados na amostra, presume-se o resultado é condizente com a população. Este processo é denominado de inferência estatística. O interesse na amostra não está propriamente nela, mas na informação que ela fornece ao investigador sobre a população de onde ela provém. A amostra fornece estimativas (estatísticas) da população (Figura 2.1). População ou população-alvo consiste em todos os elementos (indivíduos, itens, objetos) cujas características estão sendo estudadas. Amostra é a parte, subconjunto, da população selecionada para estudo. Em decorrência do acaso, diferentes amostras de uma mesma população fornecem resultados diferentes. Este fato deve ser levado em consideração ao usar uma amostra para fazer inferência sobre uma população. Este fenômeno é denominado de variação amostral ou erro amostral e é a essência da estatística. O grau de certeza na inferência estatística depende da representatividade da amostra. O processo de obtenção da amostra é chamado de amostragem. Mesmo que este processo seja adequado, a amostra nunca será uma cópia perfeita da população de onde ela foi extraída. Desta forma, em qualquer conclusão baseada em dados de uma amostra, sempre haverá o que é conhecido como erro amostral. Este erro deve ser tratado estatisticamente tendo em mente a teoria da amostragem, baseada em probabilidades. Figure 2.1: População, amostra e inferência estatística 2.3 Estimativas e Parâmetros Estimativa é uma característica que resume os dados de uma amostra (estatística amostral) e o parâmetro é uma característica estabelecida para toda a população. Os valores dos parâmetros são normalmente desconhecidos, porque é inviável medir uma população inteira. A estimativa é um valor aproximado do parâmetro. As estimativas são representadas por letras romanas e os parâmetros por letras gregas. Por exemplo, a media da população é representada por \\(\\mu\\) e a média da amostra por \\(\\bar{x}\\); o desvio padrão da população é denotado \\(\\sigma\\) e o desvio padrão da amostra por s. Na maioria dos estudos, são utilizadas amostras que fornecem estimativas que, para serem representativas da população, devem ser probabilísticas. Ou seja, a amostra deve ser recrutada de forma aleatória, permitindo que cada um dos membros da população tenha a mesma probabilidade de ser incluído na amostra. Além disso, uma amostra deve ter um tamanho adequado para permitir inferências válidas. 2.4 Escalas de medição Em um estudo científico, há necessidade de registrar os dados para que eles representem acuradamente as variáveis observadas. Este registro de valores necessita de escalas de medição. Mensuração ou medição é o processo de atribuir números ou rótulos a objetos, pessoas, estados ou eventos de acordo com regras específicas para representar quantidades ou qualidades dos dados. Para a mensuração das variáveis são usadas as escalas nominal, ordinal, intervalar e de razão (18). 2.4.1 Escala Nominal As escalas nominais são meramente classificativas, permitindo descrever as variáveis ou designar os sujeitos, sem recurso à quantificação. É o nível mais elementar de representação. São usados nomes, números ou outros símbolos para designar a variável. Os números, quando usados, representam códigos e como tal não permitem operações matemáticas. As variáveis nominais não podem ser ordenadas. Podem apenas ser comparadas utilizando as relações de igualdade ou de diferença, através de contagens. Os números atribuídos às variáveis servem como identificação, ou para associá-la a uma dada categoria. As categorias de uma escala nominal são exaustivas e mutuamente exclusivas. Quando existem duas categorias, a variável é dita dicotômica e com três ou mais categorias, politômicas. Os nomes e símbolos que designam as categorias podem ser intercambiáveis sem alterar a informação essencial. Exemplos: Tipos sanguíneos: A, B, AB, O; variáveis dicotômicas: morto/vivo, homem/mulher, sim/não; cor dos olhos, etc. 2.4.2 Escala Ordinal As variáveis são medidas em uma escala ordinal quando ocorre uma ordem, crescente ou decrescente, inerente entre as categorias, estabelecida sob determinado critério. A diferença entre as categorias não é necessariamente igual e nem sempre mensuráveis. Geralmente, designam-se os valores de uma escala ordinal em termos de numerais ou postos (ranks), sendo estes apenas modos diferentes de expressar o mesmo tipo de dados. Também não faz sentido realizar operações matemática com variáveis ordinais. Pode-se continuar a usar contagem. Exemplos: classe social (baixa, média, alta); estado geral do paciente: bom, regular, mau; estágios do câncer: 0, 1, 2, 3 e 4; escore de Apgar: 0, 1, 2… 10. 2.4.3 Escala Intervalar Uma escala intervalar contém todas as características das escalas ordinais com a diferença de que se conhece as distâncias entre quaisquer números. Em outras palavras, existe um espectro ordenado com intervalos quantificáveis. Este tipo de escala permite que se verifique a ordem e a diferença entre as variáveis, porém não tem um zero verdadeiro, o zero é arbitrário. O exemplo clássico é a mensuração da temperatura, usando as escalas de: Celsius ou Fahrenheit. Aqui é legítimo ordenar, fazer soma ou médias. No entanto, 0ºC não significa ausência de temperatura, portanto a operação divisão não é possível. Uma temperatura de 40ºC não é o dobro de 20ºC. Se 40ºC e 20ºC forem transformados para a escala Fahrenheit, passarão, respectivamente, para 104ºF e 68ºF e, sem dúvida, 104 não é o dobro de 68! 2.4.4 Escala de Razão Há um espectro ordenado com intervalos quantificáveis como na escala intervalar. Entretanto, as medidas iniciam a partir de um zero verdadeiro e a escala tem intervalos iguais, permitindo as comparações de magnitude entre os valores. Refletem a quantidade real de uma variável, permitindo qualquer operação matemática. Os dados tanto na escala intervalar como na de razão, podem ser contínuos ou discretos. Dados contínuos necessitam de instrumentos para a sua mensuração e assumem qualquer valor em um certo intervalo. Por exemplo, o tempo para terminar qualquer tarefa pode assumir qualquer valor, 10 min, 20 min, 35 min, etc., de acordo com o tipo de tarefa. Outros exemplos: peso, dosagem de colesterol, glicemia. Dados discretos possuem valores iguais a números inteiros, não existindo valores intermediários. A mensuração é feita através da contagem. Por exemplo: número de filhos, número de fraturas, número de pessoas. 2.5 Tipos de Variáveis A primeira etapa na descrição e análise dos dados é classificar as variáveis, pois a apresentação dos dados e os métodos estatísticos variam de acordo com os seus tipos. As variáveis, primariamente, podem ser divididas em dois tipos: numéricas ou quantitativas e categóricas ou qualitativas (19). 2.5.1 Variáveis Numéricas As variáveis numéricas são classificadas em dois tipos de acordo com a escala de mensuração: continuas e discretas. As variáveis contínuas são aquelas cujos dados foram mensurados em uma escala intervalar ou de razão, podendo assumir, como visto, qualquer valor dentro de um intervalo de números reais, dependendo da precisão do instrumento de medição. O tratamento estatístico tanto para variável intervalar como de a razão é o mesmo. A diferença entre elas está na presença do zero absoluto. As variáveis numéricas contínuas têm unidade de medida. Por exemplo, um menino de 4 anos tem 104 cm. Uma variável numérica é considerada discreta quando é apenas possível quantificar os resultados possíveis através do processo de contagem. Também têm unidade de medida – número de elementos. Por exemplo, o número de fraturas, o número de acidentes, etc. 2.5.2 Variáveis Categóricas As variáveis categóricas ou qualitativas são de dois tipos: nominal e ordinal, de acordo com a escala de mensuração. Um tipo particularmente comum é uma variável binária (ou variável dicotômica), que tem apenas dois valores possíveis. Por exemplo, o sexo é masculino ou feminino. Este tipo de variável é bastante utilizado na área da saúde, em Epidemiologia. As variáveis nominais não têm quaisquer unidades de medida e a nominação das categorias é completamente arbitrária e pertencer a uma categoria não significa ter maior importância do que pertencer à outra. Uma variável ordinal tem uma ordem inerente ou hierarquia entre as categorias. Do mesmo modo que as variáveis nominais, as variáveis ordinais não têm unidades de medida. Entretanto, a ordenação das categorias não é arbitrária. Assim, é possível ordená-las de modo lógico. Um exemplo comum de uma variável categórica ordinal é a classe social, que tem um ordenamento natural da maioria dos mais desfavorecidos para os mais ricos. As escalas, como a escore de Apgar e a escala de coma de Glasgow (20), também são variáveis ordinais. Mesmo que pareçam numéricas, elas apenas mostram uma ordem no estado dos pacientes. O escore de Apgar (21) é uma escala, desenvolvida para a avaliação clínica do recém-nascido imediatamente após o nascimento. Originalmente, a escala foi usada para avaliar a adaptação imediata do recém-nascido à vida extrauterina. A pontuação pode variar de zero a 10. Uma pontuação igual ou maior do que oito, indica um recém-nascido normal. Uma pontuação de sete ou menos pode significar depressão do sistema nervoso e abaixo de quatro, depressão grave. As variáveis ordinais, da mesma forma que as nominais, não são números reais e não convém aplicar as regras da aritmética básica para estes tipos de dados. Este fato gera uma limitação na análise dos dados. 2.5.3 Como identificar o tipo da variável? A maneira mais fácil de dizer se os dados são numéricos é verificar se eles têm unidades ligadas a eles, tais como: g, mm, ºC, ml, número de úlceras de pressão, número de mortes e assim por diante. Se não, podem ser ordinais ou nominais – ordinais se os valores podem ser colocados em ordem. A Figura @ref{fig:caminho} é uma ajuda para o reconhecimento do tipo de variável (22). Figure 2.2: Caminho para identificar o tipo de variável 2.5.4 Variáveis Dependentes e Independentes De um modo geral as pesquisas são realizadas para testar as hipóteses dos pesquisadores e, para isso, eles medem variáveis com a finalidade de compará-las. A maioria das hipóteses podem ser expressas por duas variáveis: uma variável explicativa ou preditora e uma variável desfecho (19). A variável preditora ou explanatória é a que se acredita ser a causa e também é conhecida como variável independente, porque o seu valor não depende de outras variáveis. Em Epidemiologia, é com frequência referida como exposição ou fator de risco. A variável desfecho é aquela que é o efeito, consequência ou resultado da ação de outra variável, por isso, também chamada de variável dependente. Em um estudo que tenta verificar se o tabagismo, durante a gestação, pode interferir no peso do recém-nascido, tem o fumo (variável categórica) como variável preditora (exposição ou fator de risco) e o peso do recém-nascido (variável numérica contínua) como variável desfecho "],["produção-dos-dados.html", "Capítulo 3 Produção dos Dados 3.1 Processo de Pesquisa 3.2 Processo de Amostragem 3.3 Principais Delineamentos de Pesquisa 3.4 Estudos Observacionais 3.5 Ensaios Clínicos", " Capítulo 3 Produção dos Dados 3.1 Processo de Pesquisa A pesquisa é um processo de construção do conhecimento. O objetivo deste processo é gerar um novo conhecimento e/ou confirmar ou refutar algum conhecimento prévio. A pesquisa é um processo de aprendizagem tanto do pesquisador quanto da sociedade que se beneficiará deste novo conhecimento. Para ser chamada de científica, a pesquisa deve obedecer aos princípios consagrados pela ciência (23). A pesquisa nasce de uma dúvida do pesquisador, de algum questionamento que ele considerou interessante sobre o mundo, ou seja, de algo que se costuma chamar de pergunta ou questão da pesquisa. Existem vários motivos que geram questões de pesquisa: Avaliação crítica de pesquisas realizadas por outros pesquisadores. Condução de uma pesquisa primária com a finalidade de responder uma questão (ou questões), gerando um novo conhecimento ou ampliação do conhecimento existente. Para obter habilidades de pesquisa ou experiência, com frequência como parte de um programa educacional. Testar a viabilidade de um projeto ou técnica de pesquisa. 3.1.1 Questão de Pesquisa A pesquisa visa estabelecer novos conhecimentos em torno de um tema específico. O tema de pesquisa pode surgir do próprio interesse ou experiência do pesquisador, ou partir da encomenda de alguma instituição financiadora. Algumas vezes, a pesquisa se origina de outros estudos realizados pelo próprio pesquisador ou outros pesquisadores. À medida que a ideia da pesquisa cresce, o pesquisador estabelece uma pergunta de pesquisa específica ou um conjunto de questões que ele deseja responder. Algumas vezes, o tema da pesquisa é tão amplo que o pesquisador tem que ter cuidado para não se perder do seu objetivo. Este objetivo é que vai guiá-lo no estabelecimento da pergunta ou perguntas a serem respondidas no estudo. Estes questionamentos são conhecidos como questão de pesquisa ou pergunta de partida. O foco da questão de pesquisa pode ser na descrição de um fenômeno clínico. Neste caso a pergunta é dita descritiva, por exemplo, pesquisa de prevalência de uma enfermidade, proporção de utilização de um serviço de saúde, características de um teste, etc. Quando a pergunta busca a explicação para um fenômeno, ela é dita analítica, por exemplo, comparação entre dois fenômenos. Em geral, perguntas analíticas são mais interessantes. Entretanto, as perguntas descritivas são fundamentais no início de um estudo analítico. Uma boa pergunta de pesquisa deve ter as seguintes características (24): Factível: o pesquisador deve conhecer desde o início os limites e problemas práticos que podem interferir na pesquisa. A viabilidade está relacionada com o tamanho amostral, com o domínio técnico adequado, com o tempo e custos envolvidos e com um foco dirigido estritamente aos objetivos mais importantes. Interessante: a questão de pesquisa deve despertar o interesse não apenas do pesquisador, mas também de seus pares e agentes financiadores. Nova: a pesquisa deve ser inovadora, original, em algum sentido, para que o estudo seja uma contribuição ao conhecimento ou amplie um conhecimento existente; Ética: se o estudo impõe riscos físicos ou invasão de privacidade ou não traz nenhuma informação nova, o pesquisador deve suspendê-lo. É importante discutir previamente com pesquisadores mais experientes ou com algum representante do Comitê de Ética em Pesquisa da instituição. Relevante: nenhuma das características da questão de pesquisa é mais importante do que a sua relevância. Para isto basta pensar nos benefícios que os resultados da pesquisa trarão à Medicina atual. Ou seja, antes de dedicar tempo e esforço para escrever um projeto de pesquisa deve-se avaliar se a questão de pesquisa é FINER (Factível, Interessante, Nova, Ética e Relevante). 3.1.2 Hipótese de Pesquisa Uma vez estabelecida a(s) pergunta(s) de pesquisa adequada(s), os pesquisadores formulam hipóteses para serem testadas. Enquanto a pergunta de pesquisa possa ser um pouco vaga em sua natureza como: “existe uma relação entre o tipo psicológico e a capacidade de parar de usar drogas?” Uma hipótese de pesquisa, necessita ser precisa. Há necessidade de especificar qual o tipo psicológico está relacionado à habilidade de parar de usar drogas. A precisão da hipótese é fundamental em um projeto de pesquisa, pois ela determinará o delineamento de pesquisa a ser seguido pelo pesquisador e as técnicas estatísticas apropriadas para a análise dos dados. A fonte e o tipo de dados são determinados pela característica do delineamento recomendado pela hipótese de pesquisa. O objetivo da pesquisa, usando o método científico, é refutar ou não as hipóteses de pesquisa. Se a hipótese do pesquisador não for rejeitada, houve a geração de um novo conhecimento. 3.2 Processo de Amostragem Após o estabelecimento das hipóteses a serem testadas, há necessidade de coletar os dados. Uma vez que é praticamente impossível analisar toda a população que constitui a população-alvo, extrai-se uma amostra desta população. Este processo é denominado de amostragem (25). Uma amostra deve ser representativa da população, ou seja, deve ter características semelhantes às da população e ser fidedigna. A fidedignidade está relacionada à precisão dos dados que sofrem influência dos instrumentos de aferição, questionários não validados e falhas humanas. Uma amostra inadequada ameaça a validade da pesquisa. Os dados coletados de maneira não aleatória são chamados de evidência anedótica. O nível de confiança nos resultados de uma pesquisa está diretamente relacionado à qualidade da amostra. A amostra deve ser representativa. Uma amostra deve conter apenas dados úteis que permitam a resposta da pergunta de pesquisa, evitando desperdício e fuga dos objetivos traçados. A aleatoriedade provoca uma diferença entre o resultado da amostra e o verdadeiro valor da população que é denominada erro amostral. Não importa quão bem a amostra seja coletada, os erros amostrais irão sempre ocorrer. Entretanto, não existe técnica estatística que salve amostras coletadas incorretamente, tendenciosas! 3.2.1 Amostras probabilística Para evitar vieses, erros sistemáticos, que favorecem determinados desfechos, o ideal é coletar uma amostra probabilística. A amostra probabilística adota o princípio da equiprobabilidade, isto é, “todos os sujeitos da população têm a mesma probabilidade de fazerem parte da amostra”. Esta probabilidade é conhecida e diferente de zero. As amostras probabilísticas têm o potencial de ser possível a generalização para a população; ser imparcial e com menor erro amostral. Amostra aleatória simples: é a mais utilizada pois garante representatividade da amostra junto à população. A amostra aleatória simples não emprega nenhum critério particular para a definição da amostra. O mecanismo mais comum de obter este tipo de amostra é por um simples sorteio, em geral, usando programas de computador. Amostra aleatória estratificada: quando a população é constituída por subpopulações ou estratos e é razoável supor que a variável de interesse apresenta comportamento diferente nos diferentes estratos, pode-se usar este tipo de amostragem. Neste caso, a amostra deve ter a mesma estratificação da população para ser representativa. Um exemplo comum de estratificação é o nível socioeconômico. A partir do momento que os estratos estão definidos se procede uma amostra aleatória simples de cada estrato. Amostra aleatória sistemática: as unidades amostrais são selecionadas a partir de um esquema rígido preestabelecido de sistematização que tem o propósito de abranger toda a população-alvo. Para isso, ordena-se os indivíduos da população (por exemplo, um grande arquivo com 20000 fichas) e calcula-se uma constante conveniente, \\(c = N/n\\), onde \\(N\\) é tamanho da população e \\(n\\) é o tamanho da amostra. Se \\(n = 500\\), a constante será \\(40\\), ou seja, será selecionado aleatoriamente o primeiro membro da amostra (\\(k\\)), de maneira que \\(k\\) seja menor do que a constante e maior do que \\(1\\). A partir daí os sucessivos membros serão: \\(k + c\\); \\(k + 2c\\); \\(k + 3c\\); … até atingir \\(n\\). Amostra aleatória por conglomerados (clusters): este tipo de amostra é utilizada quando dentro da população são identificados agrupamentos (clusters) naturais, por exemplo, espaços, vilas, etc. Neste tipo de amostragem o elemento focal não é o sujeito, mas o cluster. Identificados estes, sorteiam-se os conglomerados e se analisa todos os indivíduos dos conglomerados sorteados. 3.2.2 Amostras não probabilísticas Na amostragem não aleatória ou intencionada há uma escolha deliberada da amostra, subordinada a objetivos específicos do pesquisador. Não há garantia de representatividade da população. É importante averiguar, neste tipo de amostragem, a presença de conflitos de interesse. Amostra de conveniência: é uma técnica comum onde é selecionada uma mostra que esteja acessível. Em outras palavras, os indivíduos são recrutados porque eles estão prontamente disponíveis. Neste tipo de amostra há incapacidade de fazer afirmações gerais com rigor estatístico sobre a população. Amostra por cotas: é uma versão não probabilística da amostra estratificada. Tem três etapas: Segmentação, onde se divide em grupos, por exemplo, sexo, classe social, região, etc.; Definição do tamanho das cotas; Seleção por meio de amostras de conveniência. Amostra de resposta voluntária: o pesquisador solicita aos membros de uma população-alvo para que eles participem da amostra e as pessoas decidem se entram ou não. Esses tipos de amostras são enviesados porque as pessoas podem ter interesses particulares ou opiniões negativas e tendem a querer participar. 3.2.3 Tamanho amostral A determinação do tamanho de uma amostra é de suma importância, pois amostras desnecessariamente grandes acarretam desperdício de tempo e de dinheiro e amostras muito pequenas podem levar a resultados não confiáveis, ameaçando a validade da pesquisa. Não existe um número estabelecido para o tamanho da amostra. Há uma solução para cada caso. O tamanho da amostra depende (26): do tipo de problema; do tipo de variável; da magnitude do erro estatístico aceito pelo pesquisador; da diferença minimamente importante entre os grupos; da probabilidade de que a amostra identifique uma diferença verdadeira: Poder estatístico; do tempo, dinheiro e pessoal disponível, bem como da dificuldade em se obterem dados e da complexidade da pesquisa. O tamanho amostral mínimo é determinado por fórmulas estatísticas complexas. Os cálculos são muito pesados, mas agora, felizmente, existem programas de computador disponíveis que realizam este trabalho, por exemplo o G-Power3 (27). Além disso, é possível acessar um site que fornece informações e ferramentas para o cálculo amostral em pesquisas da área da saúde 2. Existem tabelas extensas para calcular o número de participantes (28) para um determinado nível de poder (e vice-versa). 3.3 Principais Delineamentos de Pesquisa Em geral, a pesquisa clínica, é dividida em dois tipos de investigação. O primeiro é aquele em que o observador apenas observa o doente, as características da sua doença e sua evolução, sem atuar de modo a modificar qualquer aspecto que esteja estudando. Trata-se de estudo observacional. O segundo corresponde aos estudos experimentais, onde o pesquisador não se limita a observar, mas promove uma intervenção com o objetivo de conhecer os efeitos dessa sobre os participantes da pesquisa. A intervenção pode ser a prescrição de um medicamento, uma dieta, atividade física ou repouso, ou simplesmente, o estabelecimento de um programa de atenção à saúde. Os estudos podem ser também classificados em primários ou secundários ou integrativos (29). Estudos primários correspondem a pesquisas originais que constituem a maioria das publicações encontradas nas revistas médicas. Estudos secundários são aqueles que procuram sumarizar e extrair conclusões de estudos primários Estudos Primários Estudos Observacionais Relato de Caso e Série de Casos Estudo Transversal Estudo Caso-controle Estudo de Coorte Estudos Experimentais Experimento laboratorial Ensaio Clínico Estudos Secundários Revisões não sistemáticas Revisões Sistemáticas Direrizes (Guidelines) Análise de decisão Análise Econômica 3.3.1 Elementos básicos de um delineamento de pesquisa Os estudos contêm três elementos básicos: Variáveis componentes: Nas investigações das relações entre as variáveis identificam-se pelo menos duas variáveis nos estudos epidemiológicos. Desfecho: Aquilo que vai acontecer durante uma investigação na mensuração da condição de saúde-doença. Sinônimo: variável dependente. Exposição: O fator que precede o desfecho. Sinônimos: fator em estudo, variável preditora, variável independente. Temporalidade: Quanto ao tempo os estudos podem ser contemporâneos, retrospectivos e prospectivos, de acordo como os dados são obtidos em relação ao momento atual. Enfoque: Um estudo pode ter vários enfoques. Na maioria deles, na área médica, eles relacionam-se à prevenção, ao diagnóstico, à terapêutica e ao prognóstico. 3.4 Estudos Observacionais 3.4.1 Relato de Caso ou Série de casos No relato de caso, descrevem-se casos raros, eventos não comuns ou inesperados, doenças desconhecidas ou raras. Um evento notável deve ser identificado. Um relato de caso tem a descrição de até dez casos. Acima deste número tem-se uma série de casos (30). Metodologicamente, faz-se um relato descritivo simples de características interessantes observadas em um paciente ou grupo de pacientes. Os indivíduos são acompanhados em um espaço de tempo curto e não possuem participantes-controles. A coleta dos dados é, na maioria das vezes, retrospectiva. Uma série de casos não é planejada e não envolve quaisquer hipóteses investigativas. Pode ser empregada como precursor de outros estudos. 3.4.2 Estudos Transversais ou Seccionais Os estudos transversais são também conhecidos como estudos seccionais. Este tipo de estudo fornece a informação sobre a prevalência, ou seja, a proporção dos indivíduos que tem a doença ou condição clínica em um determinado momento. Por este motivo são também conhecidos como estudos de prevalência (31). Observam dados coletados em um grupo de indivíduos em um único momento, sem um período de seguimento. O desfecho e exposição são avaliados no mesmo momento no tempo. Os dados são coletados apenas uma vez para cada indivíduo, podendo ser em dias diferentes em diferentes sujeitos. As informações são, em geral, obtidas em um curto espaço de tempo. É um estudo estático, representa a “fotografia” de um momento. Entretanto, se as variáveis preditora e de desfecho são definidas apenas com base nas hipóteses causa-efeito do investigador e não no delineamento do estudo, é possível também examinar associações. Os estudos de corte transversal, de um modo geral, são desenhados para determinar “O que está acontecendo?”. São usados para: Determinar a prevalência de uma doença, como a prevalência de HIV em gestantes. Pesquisar atitudes ou opiniões em relação a um determinado assunto (pesquisa de satisfação) Verificar interrelações entre variáveis, como observação das características de fumantes pesados em relação ao sexo, idade, etc. Enquetes Cuidados na interpretação de dados de estudos transversais Efeito temporal Como os dados (exposição e desfecho) são coletados no mesmo momento, fica difícil estabelecer qualquer relação temporal entre eles (dilema ovo/galinha). Por exemplo, não é possível estabelecer uma relação de causalidade entre hipertensão e doença cardíaca se os dados são coletados de forma a ficar impossível saber que surgiu em primeiro lugar. Estudos transversais repetidos Os estudos transversais, algumas vezes, são repetidos em outro momento ou em outros locais com a finalidade de verificar variabilidade nos achados. Por exemplo, medir a prevalência de uma doença em momentos diferentes ou em diferentes locais. Os indivíduos serão um pouco diferentes, devendo-se interpretar as diferenças destes resultados com cautela. Estudos transversais que parecem longitudinais Uma armadilha comum é confundir um estudo seccional com um longitudinal porque os dados foram coletados através do tempo até completar o tamanho amostral previsto. O importante é que os dados (variável preditora e desfecho) foram coletados somente uma vez para cada indivíduo e no mesmo momento. Isto gera uma interpretação errônea se analisarmos como um estudo longitudinal. Análise dos Estudos Transversais Quando se compara a prevalência de doença em expostos e não expostos, a medida de associação usada é a Razão de Prevalência Pontual (RPP). 3.4.3 Estudos Caso-Controle Para examinar a possível associação de uma exposição a uma determinada doença, identifica-se um grupo de doentes (casos) e, com a finalidade de comparação, um grupo de pessoas sem a doença (controles) e determina-se a chance (odds) de exposição e não exposição entre casos e entre controles. Os estudos caso-controle, portanto, partem da presença ou ausência de um desfecho e após olham para trás no tempo (retrospectivamente) para detectar possíveis fatores de risco (Figura 3.1)(32). Analisam o que aconteceu e são usados para investigar fatores de risco de doenças raras onde um estudo prospectivo seria muito longo para identificar uma quantidade suficiente de casos. É útil também para investigar surtos agudos (infecção alimentar) para identificar se existe ou não associação entre a exposição e o desfecho investigado. Com frequência, os estudos caso-controle são o primeiro passo na busca de uma etiologia quando há suspeita de que alguma de várias exposições esteja associada a uma determinada doença. Figure 3.1: Desenho de um estudo caso controle. Seleção dos casos Os casos podem ser selecionados de várias fontes, incluindo indivíduos hospitalizados, de consultórios ou clínicas, principalmente quando registros adequados são mantidos. Muitos problemas podem ocorrer na seleção de casos, neste tipo de estudo. Se os casos forem selecionados de um único hospital, quaisquer fatores de risco identificados podem ser apenas daquele hospital, em decorrência do padrão de referência e nível de atendimento (um hospital terciário que apenas atende um determinado convênio, por exemplo, o Sistema Único de Saúde). Por isso, devem ser utilizados casos procedentes de vários hospitais da comunidade, pois aí os casos pertenceriam a diferentes grupos sociais e diferentes graus de gravidade da doença. Casos incidentes ou prevalentes Os casos usados nos estudos caso-controle podem ser casos incidentes (recém-diagnosticados) ou casos prevalentes da doença (pessoas que apresentaram a doença em algum período). O problema do uso de casos incidentes é que há necessidade de se esperar que novos casos sejam diagnosticados e isto pode requerer muito tempo. Enquanto os casos prevalentes já estão disponíveis havendo um maior número disponível para o estudo. Em ambos os modelos existem problemas, pois nos casos prevalentes algumas pessoas podem morrer logo após o diagnóstico e estarem pouco representadas no estudo. Por outro lado, nos casos incidentes, serão excluídos os pacientes que morreram antes do diagnóstico ser feito. Não existe uma solução fácil para este problema, mas é importante lembrar-se destas questões ao interpretar os resultados e tirar conclusões do estudo. Seleção dos controles Da mesma forma do que nos estudos experimentais, a escolha dos controles afeta a comparação com os casos (33). A escolha dos controles inclui: Pacientes do mesmo hospital, mas com condições ou doenças não relacionadas; Pacientes pareados um a um em relação a fatores prognósticos, tais como sexo e idade; Uma amostra aleatória originária da mesma população de onde provêm os casos. Sem dúvida, o melhor grupo controle é a terceira opção, mas esta é raramente possível. Por este motivo, alguns estudos caso-controle incluem mais de um grupo controle para tornar o estudo mais robusto Controles pareados O emparelhamento é definido como processo de seleção dos controles para que sejam semelhantes aos casos em algumas características como, por exemplo, idade, gênero, raça, condição socioeconômica e ocupação. Controles emparelhados são bastante comuns. O autor deve ter o cuidado de especificar cuidadosamente o modo como houve o pareamento. Por exemplo, “emparelhado por idade dentro de dois anos” mostra a amplitude do pareamento. É difícil realizar o emparelhamento para muitos fatores, pois um pareamento seguro não existe. Em um delineamento pareado, a análise estatística deve levar em conta o emparelhamento e os fatores usados por ele. Onde um indivíduo em um par tiver um dado perdido, ambos devem ser omitidos da análise estatística. Estudos caso-controle aninhados Um delineamento do tipo caso-controle aninhado é um estudo de caso-controle ’’aninhado” em um estudo de coorte (34). É um excelente desenho para variáveis preditoras que são caras para medir e que podem ser avaliadas no final do estudo em indivíduos que desenvolvem o resultado durante o estudo (casos) e em uma amostra daqueles que não o fazem (controles). O investigador começa com uma coorte adequada (Figura 3.2) (35) com casos suficientes ao final do acompanhamento para fornecer poder adequado para responder à pergunta de pesquisa. No final do estudo, aplica critérios que definem o resultado de interesse para identificar todos aqueles que desenvolveram o resultado (casos). Em seguida, seleciona uma amostra aleatória dos indivíduos que não desenvolveram o resultado (controles). A principal razão para usar delineamentos caso-controle aninhado é reduzir o trabalho e o custo na coleta de dados. A principal desvantagem desse projeto é que muitas questões e circunstâncias da pesquisa não são passíveis de armazenamento para posterior análise. Figure 3.2: Desenho de um estudo caso-controle aninhado. Estudo caso-controle de base populacional São os estudos caso-controle onde os casos e controles são uma amostra completa ou probabilística de uma população definida. Limitações dos estudos caso-controle Várias limitações podem afetar os estudos caso-controle: A escolha do grupo controle afeta as comparações entre casos e controles; Os dados da exposição ao fator de risco são coletados retrospectivamente e dependem da memória dos participantes, registros médicos e, portanto, podem ser incompletos, sem acurácia ou enviesados (viés de memória); Se o processo que conduz à identificação dos casos está relacionado a um possível fator de risco, a interpretação dos resultados será difícil (viés averiguação). Por exemplo: suponha que os casos sejam mulheres jovens com hipertensão selecionadas de uma clínica de contracepção. Nesta situação, um possível fator de risco, o anticoncepcional oral (ACO), estará vinculado à seleção dos casos e, desta forma, o uso de ACO será mais comum entre os casos do que entre os controles populacionais. Análise dos Estudos Caso-controle A principal estratégia de análise é o cálculo da odds ratio (Razão de Chances), que pode ser interpretado como uma estimativa do Risco Relativo. O Risco Relativo somente pode ser calculado quando é possível o cálculo da incidência (ver seção ??). Nos estudos caso-controle, isso não é possível, pois aqui o estudo começa com casos e controles em vez de indivíduos expostos e não expostos ao fator de risco. Desta maneira, se comparam as odds (chance) de uma exposição passada a um fator de risco suspeitado em indivíduos doentes e em controles não doentes. Esta relação é denominada de odds ratio (ver seção ??). 3.4.4 Estudos de Coorte Os estudos de coorte são considerados o padrão-ouro dos estudos observacionais. Seu nome se originou das coortes dos soldados romanos, cada uma delas constituída por 480 a 600 legionários. As coortes romanas eram distintas entre si e tinham sua identidade determinada por, ao menos, uma característica comum entre os indivíduos de cada grupo. Podia ser por características estratégicas no campo de batalha, por uma cor presente na indumentária, ou outras. Em Epidemiologia, o termo coorte permaneceu com significado semelhante. Em um estudo de coorte, um grupo de pacientes sadios (coorte), expostos ou não a um suspeitado fator de risco, é seguido através do tempo para determinar a incidência da doença em questão em cada um dos grupos (36). Neste modelo de estudo, a característica comum aos dois grupos é a exposição. Tem-se uma coorte de expostos e uma coorte de não expostos que são acompanhadas por um período de tempo que permita o aparecimento do desfecho. No final do estudo, compara-se a incidência do desfecho (doença) entre os expostos com a incidência do desfecho entre os não expostos. Se existe uma associação positiva entre a exposição e o desfecho, se espera que a incidência do desfecho entre os expostos seja maior do que a incidência de desfecho entre não expostos. Um esquema simplificado de um estudo de coorte é mostrado na Figura 3.3(37). Figure 3.3: Desenho de um estudo de coorte sobre risco. Observar que como se identifica novos casos (incidência) à medida que eles ocorrem, é possível determinar uma relação temporal entre a exposição e a doença, isto é, se a exposição precedeu o início da doença. Isto é fundamental para estabelecer uma relação causal entre a exposição e a doença. Os estudos de coorte têm semelhança com os ensaios clínicos randomizados. Ambos os estudos comparam grupos expostos a grupos não expostos. Não havendo possibilidade de realizar a randomização, por exemplo, por motivos éticos quando a exposição é sabidamente prejudicial, é indicado um estudo de coorte. A diferença fundamental, portanto, é a ausência de randomização nos estudos de coorte. Existem duas maneiras básicas para formar os grupos: Seleciona-se a população-alvo baseado no fato dos indivíduos estarem expostos ou não ao fator em estudo (Figura 3.3); Ou seleciona-se a população-alvo antes que qualquer um dos seus membros se torne exposto, ou antes, que a exposição seja identificada (Figura 3.4). Um exemplo típico deste modelo é o clássico Estudo de Framingham (38). Figure 3.4: Desenho de uma coorte com grupos expostos e não expostos. (39). Tipos de estudo de coorte De acordo com as características do seguimento, as coortes podem ser: Estudo de Coorte Prospectivo (Coorte Concorrente ou Longitudinal), onde os grupos são montados no presente, coletados os dados basais deles e continua-se a coletar dados com o passar do tempo até a doença se desenvolver ou não. Estudo de Coorte Retrospectivo ou Histórico (Coorte não concorrente), onde a exposição é avaliada em dados passados e o desfecho (doença ou não) é verificado no momento do início do estudo. O problema aqui é que a averiguação da exposição depende dos registros pregressos. Estudo de Coorte Misto (Prospectivo e Retrospectivo), onde a exposição é verificada em registros objetivos no passado (como em uma coorte histórica) e o seguimento e a medida do desfecho se fazem no futuro. Vieses em estudos de coorte Os potenciais vieses nos estudos de coorte são os seguintes: Viés de confusão – é a grande ameaça dos estudos observacionais. O confundimento causa um erro sistemático na inferência, podendo aumentar ou diminuir uma associação observada entre exposição e doença. Uma variável funciona como fator de confusão quando ela está associada com a exposição e ao mesmo tempo com a doença. Ela não deve fazer parte da cadeia causal da exposição à doença. Por exemplo, num estudo sobre fatores de risco, uma associação entre o hábito de beber café e a doença coronária é detectada. Porém, se não for considerado o fato de que os fumantes bebem mais café do que os não-fumantes, pode-se chegar à errônea conclusão de que o café é um fator de risco independente para doença coronária, o que não corresponde à realidade. Neste caso, o café é um fator de confusão e não um fator causal independente para a doença coronária (40). Viés na avaliação dos desfechos – este viés pode ocorrer quando o pesquisador que avalia o desfecho também sabe sobre o status de exposição dos sujeitos da pesquisa. Evita-se este problema “cegando” a pessoa que faz a avaliação da doença. Viés de informação – ocorrem principalmente em estudos históricos onde as informações dependem de registros passados e podem ser diferentes entre as pessoas expostas e não expostas. Viés de não resposta e perdas de acompanhamento – a não participação e as perdas podem introduzir um grande viés, alterando o cálculo da incidência nos expostos e entre os não expostos. Viés de análise – se os estatísticos tiverem alguma hipótese em relação aos dados que estão analisando, eles podem introduzir vieses em suas análises. Análise dos estudos de coorte Para verificar se existe associação entre certo desfecho (doença) e uma determinada exposição calcula-se o Risco Relativo (RR). Este é definido como a razão entre a incidência (risco) em expostos e a incidência (risco) em não expostos (ver seção ??). Vantagens e desvantagens dos estudos de coorte Vantagens Adequado para exposições raras Bom poder para testar hipóteses Importante em estudos etiológicos e prognósticos Salienta os múltiplos desfechos de uma exposição Desvantagens Inadequado em desfechos raros Perdas no seguimento levam a viés de seleção Demorado/elevado custo 3.5 Ensaios Clínicos Experimentos são estudos nos quais o pesquisador manipula a variável preditora (intervenção) e observa o efeito no desfecho que está sendo avaliado ao longo do tempo. A abordagem experimental, especificamente, o ensaio clínico randomizado controlado é a ferramenta de escolha para comparar terapêuticas ou intervenções. Os estudos experimentais podem também comparar os cuidados prestados por serviços de saúde, programas de educação em saúde e estratégias administrativas. Os estudos experimentais realizados com seres humanos são denominados de ensaios clínicos. Nos ensaios clínicos não controlados os indivíduos servem como seus próprios controles (antes-e-depois). Os resultados destes estudos estão sujeitos vários problemas: Melhora previsível. Paciente melhora espontaneamente e não pelo tratamento. Flutuação na gravidade da doença. Efeito Hawthorne: o indivíduo melhora pela atenção e não pela terapêutica (41). Regressão à média: uma limitação importante surge quando se quer avaliar a evolução de um grupo que tenha sido selecionado por estar no extremo de uma distribuição sem que haja um grupo controle. Empiricamente, observa-se que indivíduos que se encontrem num determinado momento, em um dos extremos de uma distribuição, tendem a estarem menos distantes da média em um momento posterior, sem que qualquer intervenção tenha sido desenvolvida. Este fenômeno é conhecido como efeito de regressão à média. Por exemplo: uma pessoa com uma doença crônica tem dias piores e outros melhores. Se ela é medicada com gotas homeopáticas ou faz uso de florais nos dias em que se sente excepcionalmente mal vai notar que é frequente uma melhora, seguindo estes “tratamentos”. Não que eles funcionem, mas pela regressão à média (42). 3.5.1 Características de um ensaio clínico Um ensaio clínico deve ter algumas características fundamentais (Figura 3.5)(43): Os indivíduos devem ser designados por randomização para os grupos de comparação. A randomização é a melhor abordagem no delineamento de um ensaio clínico (44). Randomizar significa sortear (por meio de computadores, tábua de números aleatórios) os indivíduos para decidir a alocação dos mesmos em um dos grupos de estudo. O elemento decisivo da randomização é a imprevisibilidade da próxima alocação. O pesquisador compara o grupo de estudo com um grupo controle apropriado. O investigador manipula a variável independente (preditora). Figure 3.5: Estrutura de um ensaio clínico randomizado. 3.5.2 Elementos básicos de um ensaio clínico Seleção dos participantes Os pesquisadores devem determinar e explicar detalhadamente os critérios de inclusão e de exclusão: Objetivos dos critérios de inclusão e exclusão Restringir a heterogeneidade da amostra Diminuir o número de variáveis independentes Fazer com que exista uma chance maior de que as diferenças nos desfechos estejam relacionadas aos tratamentos Melhorar a validade interna, ou seja, o grau em que os resultados do estudo são consistentes para aquela amostra particular de indivíduos. Esta validade depende basicamente do rigor metodológico usado para delinear o ensaio clínico, podendo ser ameaçada por dois tipos de erros: sistemático ou aleatório. Tornar a generalização (validade externa) mais precisa. Entretanto deve-se ter cuidado com critérios de inclusão e exclusão muito rígidos, pois podem diminuir esta capacidade de generalização O grau de detalhamento deve ser suficientemente preciso para permitir que outros reproduzam o estudo. O tamanho da amostra deve ser claramente determinado pelo poder do teste estatístico. Poder é a habilidade de o teste estatístico detectar diferenças entre os grupos, dado que tais diferenças existam na população em estudo. Lembrar que resultados não significativos podem ser apenas uma evidência para um inadequado tamanho amostral. O grupo controle deve ser selecionado utilizando-se os mesmos critérios do grupo experimental. Prestar atenção em possíveis armadilhas que podem gerar vieses: Uso de grupo controle histórico (não concorrente); Grupo controle selecionado de outros locais (outras clínicas, outros hospitais). O grupo controle adequado é um grupo controle concorrente, tratado no mesmo momento e no mesmo local do grupo experimental. O característico é o grupo controle não receber tratamento. Mais comumente recebem um placebo, indistinguível do tratamento experimental, mas sem componente ativo. Mesmo assim, pode haver melhora dos participantes do grupo controle (Efeito Placebo ) (45). Quando não for ético suspender o tratamento e administrar placebo, o grupo controle pode ser constituído por indivíduos que recebem o tratamento padrão. Alocação A alocação deve ser aleatória. A randomização é a principal técnica para reduzir o viés, criando grupos homogêneos. Como foi visto, é uma das características fundamentais dos ensaios clínicos. O poder da randomização depende da ocultação da sequência de alocação. A randomização pode ser: Completa: os indivíduos que obedecem ao critério de inclusão e exclusão são randomizados de modo que todos têm a mesma probabilidade de pertencer a cada um dos grupos. Isto maximiza o poder. Pode ser feita por blocos para assegurar a igualdade numérica dos grupos (estudos multicêntricos). Estratificada: os participantes são estratificados de acordo com possíveis variáveis de confusão (gravidade da doença, idade, sexo, etc.) e a randomização é realizada dentro de cada estrato. Randomização e alocação desigual: os sujeitos têm uma maior probabilidade de ser randomizados em um grupo (em geral, grupo experimental) do que o outro (comparação). Este tipo de estudo tem menor poder. Condução/Seguimento/Avaliação Em um ensaio clínico deve estar assegurado de que o estudo tenha um tempo de seguimento adequado, pois nem todos os indivíduos participam conforme o plano original. Podem ocorrer perdas de alguns pacientes durante o acompanhamento, seja porque com o tempo se constata que eles não têm a doença em estudo ou porque não aderiram ao tratamento ou intervenção e abandonaram o estudo. Quanto maior o número de pacientes perdidos e menos informações sobre eles, menos confiança pode ser colocada nos resultados do estudo. De um modo geral, não se deve tolerar perdas que sejam maiores que a incidência do desfecho no estudo. Uma regra simples é que perdas menores que 5% produzem pouco viés e perdas maiores que 20% são uma ameaça importante à validade do estudo. As perdas entre 5 e 20% devem ser avaliadas com cuidado, se possível utilizando-se uma análise de sensibilidade (pior cenário), principalmente se as perdas forem diferentes nos grupos pelo maior risco de viés. Neste tipo de análise, nos estudos com resultado positivo, todos os pacientes perdidos no grupo experimental, inicialmente, são considerados como tendo o desfecho. Posteriormente, analisa-se como se nenhum dos indivíduos perdidos no grupo controle atingiu o desfecho. Se o resultado permanecer positivo, as perdas não afetaram a validade do estudo. Estudos sem relato adequado ou nenhum relato de perdas ou exclusões devem ser avaliados com muito cuidado. Outro aspecto importante, no seguimento dos sujeitos da pesquisa, é o tratamento igual de todos os grupos. Para garantir este princípio, utiliza-se da técnica de cegamento ou mascaramento (46). Esta técnica impede que os participantes da pesquisa (pesquisadores, avaliadores e participantes) tomem conhecimento de qual grupo de tratamento o participante se encontra. Este conhecimento antecipado pode influenciar as expectativas, as opiniões e as crenças em relação aos resultados do estudo. O cegamento tem como principal finalidade a eliminação do viés de aferição, além de melhorar a adesão ao tratamento, reduzir as perdas de seguimento e diminuir o viés causado por co-intervenções (assistência suplementar maior para um dos grupos). Quando o cegamento ocorre nos pacientes e nos pesquisadores, diz-se que o estudo é duplo-cego. Se ele também incluir os avaliadores do estudo, ele é triplo cego. Um ensaio clínico em que não há cegamento é dito aberto (open label, no caso de estudos com fármacos). A avaliação dos desfechos também pode afetar os resultados. É importante garantir-se que aqueles que registram os desfechos estejam cegados em relação a que grupo o sujeito da pesquisa pertence. Os autores devem estabelecer regras cuidadosas para decidir se um desfecho ocorreu ou não e despender esforços iguais para identificar desfechos para todos os pacientes no estudo. Intenção de tratar Os pesquisadores violam a randomização se omitirem da análise os pacientes que não receberam a intervenção designada ou, pior ainda, contarem eventos que ocorreram nos sujeitos não aderentes que foram designados para a intervenção contra o grupo controle. Os sujeitos de uma pesquisa, para evitar tal viés, devem ser analisados dentro do grupo para o qual eles foram alocados pela randomização (47). Este princípio é denominado intenção de tratar. Análise da magnitude do efeito Calcula-se uma série de estimativas quantitativas para analisar a magnitude do efeito da intervenção em um ensaio clínico. Entre elas, destacam-se o Risco Relativo, Redução Relativa do Risco, Número Necessário para Tratar que serão estudados no capítulo ??. Outro método para avaliar resultados de um ensaio clínico para dados de tempo até o evento é a análise de sobrevida. Esta fornece informação sobre a rapidez com que os eventos ocorrem. A curva de sobrevida pode utilizar dados de pacientes acompanhados por diferentes períodos de tempo. 3.5.3 Ensaios clínicos de equivalência e não inferioridade Ensaios clínicos controlados com placebo são ideais para avaliar a eficácia de um tratamento. Eles permitem o controle do efeito placebo e são mais eficientes, exigindo um menor número de pacientes para detectar um efeito do tratamento. Um ensaio clínico placebo controlado é eticamente justificado se não existe tratamento padrão, se o tratamento padrão não se mostrou eficaz, não há riscos associados com o retardo no tratamento e se a possiblidade de se retirar do estudo está incluída no protocolo. Sempre que possível e justificado, os ensaios clínicos placebo controlados devem ser a primeira escolha para avaliação de um tratamento. Dado que um grande número de tratamentos eficazes comprovados está disponível, ensaios clínicos controlados por placebo são, muitas vezes, antiéticos. Nestas situações, ensaios clínicos com controle ativo são geralmente apropriados. Se o objetivo do ensaio clínico é testar se um novo tratamento é similar em eficácia a um tratamento já existente, ele é denominado de Estudo de Equivalência. O Ensaio Clínico é delineado de maneira que possa demonstrar que, dentro limites aceitáveis, os dois tratamentos são igualmente eficazes. Existe equivalência quando a diferença observada entre os dois tratamentos for menor que a máxima diferença aceitável, determinada previamente. Estes limites devem ser clinicamente apropriados. Se condição em investigação for muito grave, os limites para a equivalência devem ser estreitados. Quanto menor forem os limites de equivalência, maior o tamanho amostral. Este delineamento é útil se o novo tratamento trouxer benefícios, tais como menores efeitos colaterais, facilidade no uso e ser mais barato. Em muitos estudos com controle ativo, os pesquisadores desejam comprovar que o tratamento em estudo, no mínimo, não é substancialmente pior que o tratamento controle. Estes estudos são chamados de Estudos de Não Inferioridade. Um aspecto importante do delineamento e da interpretação desses estudos é a determinação da margem de não inferioridade. Os estudos de não inferioridade devem demonstrar, pelo menos, que o tratamento em estudo tem alguma eficácia, não inferior ao tratamento padrão. A análise dos estudos de não inferioridade é, por natureza, unidirecional. Quando um ensaio clínico busca evidenciar que um tratamento é melhor do que outro ele é denominado Estudos de Superioridade. Quando o ensaio clínico é delineado, ele deve ter uma hipótese bilateral e o tamanho da amostra definido de maneira que haja alto poder estatístico para detectar uma diferença clinicamente significativa entre os dois tratamentos. Os ensaios clínicos clássicos têm esta característica. Entretanto, nos dias atuais, este desenho de estudo pode não ser eticamente possível, uma vez que é pouco provável que não exista um tratamento com algum benefício comprovado. A comparação, portanto, deverá ser feita com o tratamento já existente, provando que o tratamento em estudo é similar ou, pelo menos, não seja inferior (48). 3.5.4 Outros tipos de ensaios clínicos Ensaio clínico com delineamento cruzado No delineamento cruzado (crossover design), os sujeitos da pesquisa são randomizados para um grupo e depois mudados para o outro grupo (Figura 3.6). Cada sujeito serve como seu próprio controle, diminuindo a variabilidade intragrupo, aumentando o poder e consequentemente, reduzindo o erro \\(\\beta\\) (erro que ocorre quando a análise estatística dos dados não consegue rejeitar uma hipótese, no caso desta hipótese ser falsa). É um tipo de delineamento bastante atrativo e útil (49). A maior desvantagem é o efeito residual (carryover), por isso os estudos cruzados devem ter um período de washout, período sem nenhum tratamento. Este período de tempo deve ser suficiente para a eliminação da droga para se ter certeza de que nenhum efeito da terapia permaneceu. Também pode haver um viés de acordo com a ordem de administração das terapias, pois os pacientes podem reagir de modo diferente como resultado do entusiasmo no início do tratamento que pode diminuir com o tempo. Figure 3.6: Ensaio clínico randomizado com delineamento cruzado. Delineamento Fatorial Uma variação interessante de ensaio clínico é o delineamento fatorial. Este tipo de estudo permite que sejam testadas duas drogas em apenas um estudo, assumindo que os desfechos antecipados para as duas são diferentes e que seus modos de ação são independentes. Este desenho de estudo gera economia. Um exemplo de delineamento fatorial é observado no Physician’s Health Study onde usando um delineamento fatorial 2 x 2 foi testada a aspirina para a prevenção primária de doença cardiovascular (50), e betacaroteno para a prevenção primária de câncer. No estudo da prevenção primária do câncer, os autores concluíram, após 12 anos de suplementação de betacaroteno, que o mesmo não produziu nem benefícios e nem prejuízos em termos de incidência de câncer (51). 3.5.5 Fases de um ensaio clínico Para a realização de um ensaio clínico, a intervenção deve passar por várias fases (52). Fase Não Clínica Antes de começar a testar novos tratamentos em seres humanos, os cientistas testam as substâncias em laboratórios (in vitro) e em animais de experimentação. O objetivo principal desta fase é verificar como esta substância se comporta em um organismo. Assim, após esta fase se pode verificar se o medicamento é seguro para ser testado em seres humanos. Todo este processo é regido por leis da bioética em pesquisa em animais. Fase Clínica A fase clínica é a fase de testes em seres humanos. Esta etapa é constituída por quatro fases consecutivas e somente depois de finalizadas todas as fases, a droga poderá ser autorizada para comercialização e disponibilizada para uso em seres humanos. As sucessivas fases dentro da fase clínica são: Fase I - Um estudo de fase I testa a droga pela primeira vez. O objetivo principal é avaliar a segurança do produto investigado. Nesta fase, o medicamento é testado em pequenos grupos (10 – 30 pessoas), geralmente, de voluntários sadios. Podemos ter exceções se estivermos avaliando medicamentos para câncer ou portadores de HIV-AIDS. Se a droga se mostrar segura, é possível ir para a Fase II. Fase II - Nesta fase, o número de pacientes é maior (70 - 100). O objetivo é avaliar a eficácia da medicação, isto é, se ela funciona para tratar determinada doença, e também conseguir informações mais detalhadas sobre a segurança (toxicidade). Somente se os resultados forem bons é que o medicamento será estudado como um estudo clínico fase III. Fase III - Nesta fase, o novo tratamento é comparado com o tratamento padrão existente. São os ensaios clínicos. O número de pacientes aumenta e depende da hipótese (em geral, 100 a 1.000). Devem de preferência utilizar desfechos clínicos, grupo controle, além de serem randomizados e duplo-cegos. Fase IV - Estes estudos são realizados para se confirmar que os resultados obtidos na fase III são aplicáveis a grande parte dos doentes. Nesta fase, o medicamento já foi aprovado para ser comercializado. A vantagem dos estudos fase IV é que eles permitem acompanhar os efeitos dos medicamentos em longo prazo. É uma fase de vigilância pós-comercialização. http://calculoamostral.bauru.usp.br/calculoamostral/index.php↩︎ "],["ambiente-do-r.html", "Capítulo 4 Ambiente do R 4.1 Instalação do R básico 4.2 RStudio 4.3 Pacotes 4.4 Diretório de trabalho 4.5 Projeto 4.6 O R como calculadora 4.7 Objetos 4.8 Funções 4.9 Classes 4.10 Vetores 4.11 Dataframes 4.12 Fatores", " Capítulo 4 Ambiente do R 4.1 Instalação do R básico Para usar o R, há necessidade de carregar o programa básico que contém a sua linguagem de programação. O sistema é formado por um programa básico, Graphical User Interface (R-Gui) e muitos pacotes com procedimentos adicionais. O site oficial do R fornece as versões atualizadas do software e informações sobre este sofisticado projeto de computação estatística. Para baixar o R, usa-se um “CRAN Mirror”, clicando em CRAN (Comprehensive R Archive Network) na margem esquerda, abaixo de Download. O CRAN é central no uso do R: é o local de onde se carrega o software e todos os pacotes necessários para instalar e para expandir o R. Em vez de ter um único local, o CRAN é “espelhado” em diferentes locais do mundo. “Espelhado” significa simplesmente que existem versões idênticas do CRAN distribuídas por todo o mundo. É possível baixar o R diretamente da nuvem ou escolher uma origem mais próxima do seu local de atuação. No Brasil, encontram-se várias opções, como a Universidade Federal do Paraná, Fundação Oswaldo Cruz, RJ, Universidade de São Paulo, São Paulo e Universidade de São Paulo, Piracicaba Após escolher uma das alternativas acima (pode ser qualquer uma delas) surgirá a página The Comprehensive R Archive Network com as opções para escolher o sistema operacional. Escolha o sitema de acordo com o seu computador (Windows, macOS ou Linux). Ao clicar em uma dessas opções, se o sistema operacional escolhido é o Windows, aparecerá a página R for Windows. Nesta, deve-se clicar em base. No caso de outros sistemas operacionais, seguir as orientações mostradas no site do R. Clicando em base, haverá um redirecionamento para a a página onde aparece a versão do R para o Windows mais atual. Clique no link que diz Download R-…for Window para baixar o instalador em um diretório do computador, em geral Downloads. Para instalar o programa básico, basta executar o instalador R-…-win.exe baixado no diretório. Ao fazer isso, aparece na tela do computador,no canto esquerdo, em baixo, o arquivo salvo. Execute este arquivo com um clique sobre ele. Aparecerá u,a janela perguntando “Deseja permitir que este aplicativo faça alterações no seu dispositivo?”. Clique em Sim. A seguir o instalador pedirá para escolher o Idioma. Selecione Português Brasileiro. Em sequência aparecerão informações sobre o diretório no qual o R será instalado em seu computador. Recomenda-se aceitar a configuração padrão sugerida pelo instalador do software. A próxima janela pedirá para personalizar os componentes que serão instalados. Recomenda-se usar as configurações sugeridas pelo instalador que irá reconhecer automaticamente a arquitetura do seu sistema Windows (32 e/ou 64 bits). A partir daqui, siga as recomendações padrão propostas pelo instalador até completar a instalação, clicando em Concluir. O R não precisa ser iniciado, pois o software que será usado, neste livro, é o RStudio. Este, para ser executado, necessita ter o R instalado no computador. Ou seja, o R é o programa “cérebro” necessário para as análises de dados que serão realizadas. Ele precisa estar instalado para permitir o funcionamento do RStudio. 4.2 RStudio O RStudio é um membro ativo da comunidade R. Foi fundado em 2009 por Joseph J. Allaire, engenheiro de software americano. O RStudio, inspirado pelas inovações dos usuários de R em ciência, educação e indústria, desenvolveu ferramentas gratuitas e abertas para facilitar o uso do R. O RStudio é um projeto filiado à Foundation for Open Access Statistics (FOAS). A FOAS trabalha para garantir o sucesso do projeto R. Eles promovem o uso e o desenvolvimento de software livre para estatísticas, como a linguagem R e o ambiente para estatísticas computacionais. Junto está o R Consortium que é uma colaboração entre a Fundação R, RStudio, Microsoft, TIBCO, Google, Oracle, HP e outros. O RStudio é patrocinado para financiar e inspirar ideias que permitirão que o R se torne uma plataforma ainda melhor para a ciência. 4.2.1 Instalação do R Studio Para instalar o RStudio, acessar o site e clicar em Download para obter a versão desejada. Recomenda-se a versão RStudio Desktop – Open Source License que é gratuita. Esta versão entrega as ferramentas integradas para o R. A seguir, aparecerão os instaladores disponíveis, conforme a plataforma suportada pelo seu computador. As mais utilizadas são Windows e Mac OS X. Neste livro, como base, serão mostrados os passos para a plataforma Windows 3. Em sequência, executar o instalador baixado RStudio-2023.03.0-386.exe 4 e seguir as suas instruções. 4.2.2 Iniciando o RStudio Para iniciar o RStudio basta clicar no ícone indicativo (Figura 4.1) que se encontra no menu Iniciar do Windows. Figure 4.1: Ícone do RStudio O RStudio abre como mostrado na Figura 4.2. O RStudio é uma interface mais funcional e amigável para o R. Contém um conjunto de ferramentas integradas projetadas para ajudá-lo a ser mais produtivo com o R. Figure 4.2: Tela inicial do RStudio Inclui um console, editor texto que suporta execução direta de códigos e uma variedade de ferramentas robustas para plotagem, exibição de histórico, depuração e gerenciamento de seu espaço de trabalho incluídos em uma interface que está, inicialmente, dividida em 3 paineis: Console Environment, History, Connections, Tutorial Files, Plots, Packages, Help Console e R Script Do lado esquerdo fica o Console (Figura 4.2, em vermelho), onde os comandos podem ser digitados e onde aparecem os resultados da execução dos comandos. Ao abrir o RStudio, aparece no Console uma série de informações sobre o R, como versão em uso e, por último, o diretório onde está armazenado o espaço de trabalho (workspace). Estas informações podem ser facilmente apagadas, clicando na barra de ferramentas, no menu Edit, e após em Clear Console ou, usando as teclas Ctrl+L. O Console é a principal parte do R. Aqui é onde o R realmente executa o comando. No início do Console, existe um caractere (&gt;). Este é um prompt que informa que o R está pronto para receber um novo código. Pode-se digitar o código diretamente no Console após o prompt e obter uma resposta imediata. Por exemplo, se for digitado 1 + 1 e pressionado Enter, o R imediatamente gera uma saída de 2 (Figura 4.3). Figure 4.3: Console Recomenda-se que a maior parte dos comandos sejam digitados no bloco de notas do RStudio, o R Script. Reservar o Console apenas para depurar ou fazer análises e cálculos rápidos. A razão para isso é simples: se o comando for digitado diretamente no Console, ele não será salvo e se for cometido um erro na digitação, haverá necessidade de digitar tudo novamente. Portanto, é melhor escrever os comandos no R Script e, quando estiver pronto para executar, enviar para o Console. O R Script é o quarto painel do RStudio e seu bloco de notas. Ele é criado através do menu File &gt; New File &gt; R Script ou clicando no botão verde com o sinal (+), na barra de ferramentas de acesso rápido, na parte superior à esquerda. Ao criar um novo R Script será aberto o painel do bloco de notas (Figura 4.4, em verde). Figure 4.4: R Script Um diferencial do RStudio é que os comandos são autocompletáveis. Basta começar a escrever o comando, inserindo 3 ou mais carcteres, por exemplo, summ referente a função summary (), usada para sumarizar um conjunto de dados, e surge um menu de opções, facilitando a digitação (Figura 4.5). Figure 4.5: Menu autocompletável Após digitar no Console, para que seja executado o comando há necessidade de clicar na tecla Enter; no RScript, clicar em Run, acima, na barra, no lado direito, ou usar o atalho Ctrl + Enter. Textos podem ser copiados e colados no script e linhas em branco podem ser inseridas. Além disso, no final da sua sessão, é possível salvar o arquivo, que poderá ser recarregado no futuro, se precisar refazer a análise. Os scripts do R são apenas arquivos de texto com a extensão (.R). Quando se cria um R Script, aparece como Sem título (Untitled). Antes de começar a digitar um novo script no R Sem título, recomenda-se salvar o arquivo com um novo nome de arquivo. Dessa forma, se algo no computador falhar durante o trabalho, o R terá o código protegido. Ao digitar o código em um script, o R não executa o código enquanto se digita. Para que o R realmente avalie o código digitado, há necessidade de primeiro enviar o código para o Console, clicando no botão Run ou usando a tecla de atalho Crtl+Enter. Cada linha é marcada no início por um número em sequência. Além da digitação de comandos, o R Script permite fazer comentários onde tudo que for escrito após o símbolo \\(\\#\\) são considerados apenas como comentários . Os comentários são literais, escritos diretamente para explicar o comando executado. São repetidos na saída do Console sem não aparecer nos resultados. Ambiente, História, Conexão e Tutorial No lado superior direito há um painel com quatro abas (Figura 4.2, em azul): Ambiente (Environment) - onde ficam armazenados os objetos criados, as bases de dados importadas, etc., na sessão ativa. É possível visualizar informações como o número de observações e linhas dos bancos de dados ativos. A guia também tem algumas ações clicáveis, como Import Dataset, que permite importar arquivos csv, Excel, SPSS, etc. História (History) - onde fica o histórico dos comandos executados no Console. Estes comandos podem ser pesquisados nesta guia. Os comandos são exibidos em ordem (mais recentes na parte inferior) e agrupados por bloco de tempo. Conexões (Connections) - mostra todas as conexões feitas com fontes de dados suportadas e permite saber quais conexões estão ativas no momento. O RStudio suporta múltiplas conexões de banco de dados simultâneas. Tutorial - a partir da versão 1.3, o R Script ganhou um painel Tutorial dedicado, usado para executar tutoriais que ajudarão você a aprender e dominar a linguagem de programação R. Na primeira vez que se abre o programa, clicando nesta aba, o RStudio solicita que seja instalado o pacote learnr (Figura 4.6). Isto permite acesso a vários tutoriais úteis que merecem ser explorados Figure 4.6: Tutoriais do RStudio Arquivos, Gráficos, Pacotes e Ajuda No lado direito, abaixo, existem outras abas muito úteis (Figura 4.2, em amarelo): Arquivos (Files) - esta guia dá acesso ao diretório onde se encontram os seus arquivos. Um bom recurso do painel Files é que se pode usá-lo para definir seu diretório de trabalho. Para isso, clique em More e depois em Set As Working Directory. Gráficos (Plots) - local onde ficam os gráficos gerados. Existem botões para abrir o gráfico em uma janela separada e exportar o gráfico como um .pdf ou .jpeg. Pacotes (Packages) - mostra uma lista de todos os pacotes R instalados no seu computador e indica se eles estão atualmente carregados ou não. Pacotes que estão sendo executados na sessão atual, estão marcados, enquanto aqueles que estão instalados, mas ainda inativos, estão desmarcados. Ajuda (Help) - menu de ajuda para as funções R. Você pode digitar o nome de uma função na janela de pesquisa (por exemplo, histogram ou usar o ?hist), no Console ou no R Script, para procurar ajuda sobre uma função (Figura 4.7). A Ajuda no R Studio pode também ser acessada no menu Help da barra de ferramentas onde existem várias opções. Para complementar, alguns livros são muito uteis, como o R Cookbook (53) ou Using R for introductory statistics (54). No entanto, na maioria das vezes a forma mais prática de conseguir ajuda com uma dúvida específica é a busca em fóruns na internet, como o Stack Overflow: https://stackoverflow.com/. Figure 4.7: Ajuda do RStudio 4.3 Pacotes Para que o R cumpra a sua função de dialogar com o usuário para realizar análises estatística e construir gráficos, ele necessita ter instalado pacotes. Quando se instala o R básico, ele vem com vários pacotes que permitem uma grande quantidade de análises. Entretanto, à medida que se utiliza o R, torna-se necessário instalar novos pacotes criados pela comunidade do R. Esses novos pacotes contêm novas funções e novos comandos que aumentarão a funcionalidade do R. Um pacote é uma coleção de funções, dados e documentação que expande os recursos do R base. O uso dos pacotes é a chave para o uso bem-sucedido do R. Eles são instalados à medida que o trabalho com o R exigir. 4.3.1 Repositório de pacotes Quando se identifica a necessisdade de um novo pacote, há necessidade de saber onde ele se encontra. O principal repositório de pacotes é o CRAN (Comprehensible R Archive Network), já comentado anteriormente. Para acessar este repositório, use o link e escolha um espelho (0-Cloud ou o mais próximo geograficamente). Depois que o pacote for instalado, ele será mantido em sua biblioteca (library) R associada à sua versão principal atual do R. Haverá necessidade de atualizar e reinstalar os pacotes sempre que atualizar uma versão principal do R. Estando na página do CRAN, no menu, à esquerda, clique em Packages . Isto o colocará na página dos Contributed Packages, onde a maioria dos pacotes podem ser encontrados em Table of available packages, sorted by name . Também é possível clicar em CRAN Task Views , onde encontramos os pacotes separados por tópicos. 4.3.2 Instalação de um novo pacote Instalar um pacote significa simplesmente baixar o código do pacote em um computador pessoal. Existem duas maneiras principais de instalar novos pacotes. O método mais comum é baixá-los do CRAN, usando a função install.packages (). Dentro dos parênteses, como argumento, coloca-se entre aspas (duplas ou simples) o nome do pacote. Como visto, deve-se, de preferência, digitar o comando no R Script. Por exemplo, será instalado o pacote ggplot2 que contém múltiplas funções gráficas como abaixo: install.packages(&quot;ggplot2&quot;) library(ggplot2) Para carregar o pacote, isto é, para fazer com que suas funções se tornem ativas para uso na na sessão, deve-se usar a função library(), como mostrado no comando acima. Se o RStudio for fechado e reaberto, o o pacote deverá ser novamente ativado. Observe que a função library() não requer que o nome do pacote seja digitado entre aspas. Isto acontece porque antes de o pacote ser instalado o R não o reconhece , portanto, há necessidade de indicar o nome (caracteres), para que o R procure na internet, por exemplo, o que ele deve baixar. Já, depois de instalado, o pacote é um objeto conhecido pelo R, logo as aspas não são mais necessárias. Uma outra maneira de instalar pacotes no R, é usar o botão Install, localizado na aba Packages, no painel inferior, à direita. Clicando em Install, abre-se a caixa de diálogo da Figura 4.8. Digitar em Packages o nome do pacote (ggplot2) e o RStudio completará com opções para achar o pacote. Clicar em ggplot2 e verifique se Install dependencies foi selecionado. A seguir clicar em Install e aguardar aparecer no Console a mensagem que o pacote foi instalado com sucesso. Figure 4.8: Instalação do pacote ‘ggplot2’ usando a caixa de diálogo ‘Install Packages’ 4.3.3 Atualização dos pacotes Periodicamente, há necessidade de atualizar os pacotes instalados. Essa necessidade advém do fato que, com o tempo, os autores de pacotes lançarão novas versões com correções de defeitos e novos recursos e, geralmente, é uma boa ideia manter-se atualizado. Para realizar a atualização proceda da seguinte maneira: # atualiza todos os pacotes disponíveis, solicitando permissão update.packages() # atualiza, sem solicitações de permissão/esclarecimento update.packages(ask = FALSE) # atualiza um pacote específico update.packages(&quot;ggplot2&quot;) 4.3.4 Instalando e carregando mais de um pacote Para carregar mais de um pacote simultaneamente, pode-se usar uma das funções: libraries() ou packages() do pacote easypackages. Em primeiro lugar, instalar e carregar o pacote: install.packages(&quot;easypackages&quot;) library(easypackages) Posteriormente, basta usar uma das funções do easypackages: libraries(&quot;readxl&quot;, &quot;dplyr&quot;, &quot;ggplot2&quot;, &quot;car&quot;) Outro pacote que gerencia pacotes do R é o pacman. Este pacote tem a função p_load() que instala e carrega um ou mais pacotes. Usar esta função, escrevendo o nome dos pacotes sem necessidade de aspas: install.packages(&quot;pacman&quot;) library(pacman) p_load(readxl, dplyr, ggplot2, car) Ou, escrever diretamente: pacman::p_load(readxl, dplyr, ggplot2, car) O pacote pacman tem outas funções, entre elas a função p_update() que atualiza o pacote e , se usada sem especificar o pacote , atualiza todos. Para saber mais sobre o pacote pacman, use a ajuda. p_update(readxl, dplyr, ggplot2, car) 4.3.5 Citação de pacotes em publicações No R existe um comando que mostra como citar o R ou um de seus pacotes. Basta digitar a função citation() no Console ou no R Script e observar a saída. Para um pacote específico, basta colocar o nome do pacote entre aspas, na função. citation() ## ## To cite R in publications use: ## ## R Core Team (2023). R: A language and environment for statistical ## computing. R Foundation for Statistical Computing, Vienna, Austria. ## URL https://www.R-project.org/. ## ## A BibTeX entry for LaTeX users is ## ## @Manual{, ## title = {R: A Language and Environment for Statistical Computing}, ## author = {{R Core Team}}, ## organization = {R Foundation for Statistical Computing}, ## address = {Vienna, Austria}, ## year = {2023}, ## url = {https://www.R-project.org/}, ## } ## ## We have invested a lot of time and effort in creating R, please cite it ## when using it for data analysis. See also &#39;citation(&quot;pkgname&quot;)&#39; for ## citing R packages. citation (&quot;ggplot2&quot;) ## ## To cite ggplot2 in publications, please use: ## ## H. Wickham. ggplot2: Elegant Graphics for Data Analysis. ## Springer-Verlag New York, 2016. ## ## A BibTeX entry for LaTeX users is ## ## @Book{, ## author = {Hadley Wickham}, ## title = {ggplot2: Elegant Graphics for Data Analysis}, ## publisher = {Springer-Verlag New York}, ## year = {2016}, ## isbn = {978-3-319-24277-4}, ## url = {https://ggplot2.tidyverse.org}, ## } 4.4 Diretório de trabalho O diretório de trabalho (Working Directory) é uma pasta onde o R lê e salva arquivos. Deve-se criar um diretório de trabalho para a sessão . Para isso, no RStudio siga o caminho: Session &gt; Set Working Directory &gt; Choose Directory ou use o atalho Ctrl + Shift + H e escolha o diretório desejado ou crie um novo. Ao finalizar, aparecerá no Console (Figura 4.9): Figure 4.9: Diretório de trabalho Note que o R usou a função setwd() que significa “definir diretório de trabalho”. Também é possível usar esta função diretamente no R Script ou no Console, digitando conforme o caminho do diretório. Para saber qual é o diretório de trabalho que está sendo usado pelo R pode-se executar a função getwd(). A saída no Console mostrará o diretório de trabalho usado, portanto é recomendado que se faça isso no início da sessão para verificar se há ou não necessidade de modificar o diretório. 4.5 Projeto Uma funcionalidade importante do RStudio é a possibilidade de se criar projetos. Um projeto nada mais é do que uma pasta no seu computador. Nessa pasta, estarão todos os arquivos que serão usados ou criados na sua análise. A principal razão de se utilizar projetos é simplesmente organização. Com eles, fica muito mais fácil importar conjunto de dados para dentro do R, criar análises reprodutíveis e compartilhar o trabalho realizado. Ao se começar uma nova análise, é interessante criar um Novo Projeto. Para isso, clicar File &gt; New Project ou clicar no menu que está na parte superior, à direita, Project (none) &gt; New Project…. Abrirá a janela da Figura 4.10. Figure 4.10: Assistente de novo projeto. Clique em New Directory para criar um novo diretório. Por exemplo, para as aulas de Bioestatística, pode-se criar um diretório com, por exemplo, o nome bioestatistica (evite usar acentos, maiúsculas ou caracteres especiais) ou qualquer outro nome. Quaisquer documentos Excel ou arquivos de texto associados podem ser salvos nesta nova pasta e facilmente acessados de dentro de R, indo ao menu Project (none) &gt; Open Project…. A partir daí, é possível realizar análises de dados ou produzir visualizações com seus dados importados. Quando um projeto estiver aberto no RStudio, o seu nome aparecerá no canto superior direito da tela. Na aba Files, aparecerão todos os arquivos contidos no projeto. Quando se clica no nome do projeto, abre um menu que torna muito fácil a navegação pelos projetos existentes. Basta clicar em qualquer um deles para trocar de projeto, isto é, deixar de trabalhar em uma análise e começar a trabalhar em outra. 4.6 O R como calculadora O R pode ser utilizado para uma série de operações matemáticas desde as mais simples às mais complexas. Para isso, basta digitar no Console ou no R Script, usando os operadores. 4.6.1 Operadores Operadores são usados para realizar operações com variáveis e valores. Operadores aritméticos No R, você pode usar operadores aritméticos para realizar operações matemáticas comuns. # Adição 10 + 5 ## [1] 15 # Subtração 10 - 5 ## [1] 5 # Multiplicação 10 * 5 ## [1] 50 # Divisão 10 / 5 ## [1] 2 # Potência 10 ^ 5 ## [1] 1e+05 # Divisão modular (divisão com resto) 10 %% 3 ## [1] 1 # Divisão inteiro 10 %/% 3 ## [1] 3 O resultado da exponenciação é exibido como notação científica, onde \\(e+05\\) significa \\(10^5\\). Operadores de atribuição Operadores de atribuição são usados para atribuir valores a variáveis, como será visto na seção Objetos, adiante. Operadores de comparação São usados para comparar dois valores. # Igualdade 3 == 3 ## [1] TRUE 3 == 4 ## [1] FALSE # Não igual (diferente) 3 != 4 ## [1] TRUE # Maior 6 &gt; 3 ## [1] TRUE # Menor 3 &lt; 4 ## [1] TRUE # Maior ou igual 5 &gt;= 3 ## [1] TRUE # Menor ou igual 3 &lt;= 4 ## [1] TRUE Observe que, na linguagem R, o sinal de igualdade é escrito com duplo \\(=\\). Operadores lógicos Operadores lógicos são usados para combinar declarações condicionais: # Conjunção lógica E, retorna TRUE se ambos elementos são verdadeiros 6 == 6 &amp; 7 == 8 ## [1] FALSE # Conjunção lógica E, retorna TRUE se ambos elementos são verdadeiros 2 * 3 &amp;&amp; 1 * 6 ## [1] TRUE # Conjunção lógica OU, retorna TRUE se um dos elementos é verdadeiro (2 * 2) | sqrt(16) ## [1] TRUE 6 == 6 | 7 == 8 ## [1] TRUE # Conjunção lógica NÃO, retorna FALSE se o elemento é verdadeiro !6==6 ## [1] FALSE !2==4 ## [1] TRUE Logarítimo # Logarítmo natural (base e) log (10) ## [1] 2.302585 # Logarítmo base 10 log10 (10) ## [1] 1 Raiz quadrada sqrt (81) ## [1] 9 Resultado absoluto abs (3 - 6) ## [1] 3 4.7 Objetos O R permite salvar valores dentro de um objeto. Os objetos são criados utilizando o operador de atribuição (&lt;-). Para digitar este operador, basta teclar o sinal menor que (&lt;), seguido de hífen (-) , sem espaços. Existe um atalho que é pressionar (Alt) \\(+\\) (-). O símbolo \\(=\\) pode ser usado no lugar de &lt;-, mas não é recomendado. Objeto é um pequeno espaço na memória do computador onde o R armazenará um valor ou o resultado de um comando, utilizando um nome arbitrariamente definido. Tudo criado pelo R pode se constituir em um objeto, por exemplo: uma variável, uma operação aritmética, um gráfico, uma matriz ou um modelo estatístico. Através de um objeto torna-se simples acessar os dados armazenados na memória. Ao criar um objeto, se faz uma declaração. Isto significa que se está afirmando, por exemplo, que uma determinada operação aritmética irá, agora, tornar-se um objeto que irá armazenar um determinado valor. As declarações são feitas uma em cada linha do R Script. Os objetos devem receber um nome e é obrigatório que ele comece por uma letra (ou um ponto) e não é permitido o uso do hífen. Pode-se usar o ponto e underlines para separar palavras. Deve ser evitado o uso de nomes que sejam de objetos do sistema, ou outros objetos já criados, funções ou constantes. Por exemplo, não deve ser utilizado: c, q, r, s, t, C, D, F, I, T, diff, exp, log, mean, pi, range, rank, var, NA, NaN, NULL, FALSE, TRUE, break, else, if, break, function, in, while que devem ser reservados, pois têm significados especiais. Quando se usa um objeto com o nome pi, ele assumirá outro valor diferente de 3,141593. Preservando este nome, toda vez que usarmos a palavra pi, o R assume o valor pré-estabelecido. Além disso, o R faz a diferença entre letras maiúsculas e minúsculas. Ou seja, soma é um objeto diferente de Soma e ambos são diferentes de SOMA. Para exibir o conteúdo de um objeto, basta digitar seu nome no R Script ou no Console e executar. Em análises mais extensas, verificar se já há um objeto com o mesmo nome, pois seus valores serão substituídos ao executar o novo objeto. Para saber se já existe um objeto com o nome definido, digite as primeiras letras do objeto criado e o R Studio listará, usando a sua função de autocompletar, tudo que começar com essas letras no arquivo. Assim ficará fácil verificar se já existe um objeto com o nome desejado. No comando abaixo, é criado um objeto que receberá a soma de dez números, utilizando a função sum(). O objeto foi denominado de soma. Para exibir o valor contido no objeto soma, é necessário digitar soma no R Script ou Console e executar: soma &lt;- sum (2, 3, 12, 15, 21, 4, 8, 7, 13, 21) soma ## [1] 106 4.8 Funções A função é uma orientação ao R para que ele execute algum procedimento específico, por isso, em geral, têm nomes sugestivos do que elas realizam. Por exemplo, a função mean () realiza a média aritmética de uma série de números colocados entre parênteses. O resultado, como regra geral, deve ser colocado em um objeto que será armazenado na memória do computador. Esta série de números pode antes ser armazenada por um objeto, nomeado dadose, posteriormente, se usa a função mean()com este objeto dados. O resultado da função mean, exibido no Console, será recebido por outro objeto media_dados que será colocado na memória do computador. dados &lt;- c(3, 5, 7, 9, 6, 7) media_dados &lt;- mean(dados) media_dados ## [1] 6.166667 As funções podem ser criadas pelo pesquisador, de acordo com as suas necessidades. Entretanto, na maioria das vezes, elas são encontradas prontas, fazendo parte de um pacote. Pacotes contêm muitas funções que para serem executadas necessitam que estes estejam instalados e carregados. As funções para exercerem a sua ação devem receber dentro delas (entre parênteses) os argumentos que elas exigem. Os argumentos de uma função são sempre separados por vírgulas. Para se saber quais argumentos necessários para uma determinada função basta consultar a ajuda, onde se encontrará a documentação da mesma. Para isso basta digitar no Console, no caso da função mean(), help(mean) ou ?mean: help(mean) O resultado deste comando aparecerá na aba Help, na parte inferior, à direita (Figura 4.11: Figure 4.11: Ajuda para Média Aritmética. Os principais argumentos da função mean() são: x \\(\\longrightarrow\\) vetor numérico trim \\(\\longrightarrow\\) fração das observações (varia de 0 a 0,5) extraída de cada extremidade de x para calcular a média aparada na.rm \\(\\longrightarrow\\) valor lógico (TRUE ou FALSE) que indicam se os valores ausentes (NA) devem ser removidos antes que o cálculo continue Este último argumento é muito importante quando, na sequência de valores existe algum não informado ou inexistente. No R, els são denominados de valores ausentes (missing values) e denotados por NA (Not Available). Por exemplo, em uma coleta de uma série de valores, correspondentes ao peso de 15 recém-nascidos, havendo a “falta” de um dos registros, ao calcular a média com a função mean(), ela retornará NA. pesoRN &lt;- c (3340,3345,3750,3650,3220,4070,NA,3970,3060,3180, 2865,2815,3245,2051,2630) mean (pesoRN) ## [1] NA Colocando o argumento na.rm = TRUE, para remover os valores faltantes, a função retornará a média aritmética sem este valor: mean (pesoRN, na.rm = TRUE) ## [1] 3227.929 4.8.1 Criando funções No R, é possível criar funções pessoais que podem simplificar um código e, eventualmente, diminuir o tempo de execução das análises. Fórmula geral As funções têm uma fórmula geral: nome_da_funcao &lt;- function (x){transformar x} Por exemplo, a área de um circulo é igual a \\(\\pi\\times raio^2\\). Para calcular a área do círculo, pode-se criar uma função que faça este trabalho: area.circ &lt;- function(r){ area &lt;- pi*r^2 return(area) } Ao executar essa função, é possível usá-la para calcular a área de um círculo, cujo raio é igual a 5 cm: r = 5 area.circ(5) ## [1] 78.53982 Outros exemplos O Indice de Massa Corporal é igual ao peso (kg) dividido pela \\(altura^2\\), em metros. Uma função para fazer este cálculo é: imc &lt;- function(peso, altura){ res &lt;- peso/altura^2 return(res) } Logo, o IMC de um indivíduo que tenha 67 kg e 1,7 m é: peso &lt;- 67 altura &lt;- 1.70 imc(67, 1.70) ## [1] 23.18339 Ativação de uma função criada Para ativar uma função previamente criada, usa-se a função nativa source (). O argumento desta função é o caminho (no exemplo, é o diretório do autor) onde se encontra a função buscada, por exemplo, a função imc() criada acima: source(&#39;C:/Users/petro/Dropbox/Estatistica/Bioestatistica_usando_R/Funcoes/imc.R&#39;) 4.9 Classes São os atributos de um objeto e o seu conhecimento é de suma importância. A partir do conhecimento do tipo de classe que as funções sabem o que extamente fazer com um objeto. Por exemplo, não é possivel somar duas letras e se for feita a tentativa de somar “a” e “b”, O R retorna um erro: Error in “a” + “b”: non-numeric argument to binary operator . No R, os textos são escritos entre aspas simples ou duplas. As aspas servem para diferenciar nomes (objetos, funções, pacotes) de textos (letras e palavras). Os textos são muito comuns em variáveis categóricas e são popularmente chamados de strings ou character. Alé desta classe, o R tem outras classes básicas que são a numeric e a logical. Um objeto de qualquer uma dessas classes é chamado de objeto atômico. Esse nome se deve ao fato de essas classes não se misturarem (55). Para saber qual o tipo de classe que um objeto pertence, basta usar a função class (). idade &lt;- c(3, 5, 7, 9, 6, 7) class (idade) ## [1] &quot;numeric&quot; nome &lt;- c(&quot;Pedro&quot;, &quot;Maria&quot;, &quot;Margarida&quot;, &quot;Alice&quot;, &quot;João&quot;, &quot;Luís&quot;) class(nome) ## [1] &quot;character&quot; 4.10 Vetores Um vetor é uma variável com um ou mais valores do mesmo tipo. Por exemplo, o número de filhos em 10 famílias foi 4, 5, 3, 2, 2, 1, 2, 1, 3 e 2. O vetor nomeado de n.filhos é um objeto numérico de comprimento = 10. A maneira mais fácil de criar um vetor em R é concatenar (ligar) os 10 valores, usando a função concatenar c() assim: n.filhos &lt;- c(4, 5, 3, 2, 2, 1, 2, 1, 3, 2) n.filhos ## [1] 4 5 3 2 2 1 2 1 3 2 Como os vetores são conjuntos indexados, pode-se dizer que cada valor dentro de um vetor tem uma posição. Essa posição é dada pela ordem em que os elementos foram colocados no momento em que o vetor foi criado. Isso nos permite acessar individualmente cada valor de um vetor (55). Para acessar um determinado valor, basta colocar a posição do mesmo entre colchetes [ ]. Se há interesse em conhecer o número de filhos da quinta família, procede-se da seguinte forma: n.filhos[5] ## [1] 2 Se houver tentativa de acessar um valor inexixtente, o R retorna NA. n.filhos[11] ## [1] NA Se houver necessidade de excluir um dos elementos, basta colocar entre colchetes a posição do mesmo com sinal negativo. Por exemplo, para excluir o valor correspondente a sexta família, usa-se: n.filhos[-6] ## [1] 4 5 3 2 2 2 1 3 2 Observa-se que o valor 1 foi excluído da série de elementos. Quando são colocados elementos em um vetor que pertençam a classes diferentes, o R promove o que se denomina de coerção, pois o vetor pode ter apenas uma classe de objeto. Dessa forma, as classes mais fortes reprimem as mais fracas. Por exemplo, sempre que for misturado números e texto em um vetor, os números serão considerados como texto: vetor &lt;- c(12, 15, 4, 6, &quot;A&quot;, &quot;D&quot;) vetor ## [1] &quot;12&quot; &quot;15&quot; &quot;4&quot; &quot;6&quot; &quot;A&quot; &quot;D&quot; Observe que, agora, todos os elementos do vetor passaram a ser textos e, porisso, estão entre aspas. 4.10.1 Tipos de vetores Dado um vetor, pode-se determinar seu tipo com typeof(), ou verificar se é um tipo específico com uma das funções: is.character(), ’is.double(),is.integer(),is.logical( )`. n.filhos &lt;- c(4, 5, 3, 2, 2, 1, 2, 1, 3, 2) typeof(n.filhos) ## [1] &quot;double&quot; is.numeric(n.filhos) ## [1] TRUE As expressões do tipo character devem aparecer entre aspas duplas ou simples. Os números no R são geralmente tratados como objetos numéricos (números reais de dupla precisão). Mesmo números inteiros são tratados como numéricos. Para fazer um número inteiro ser tratado como objeto inteiro, deve-se utilizar a letra L após o número. Os valores lógicos (ou booleanos) são TRUE ou FALSE. T ou F também são aceitos. n.filhos &lt;- c(4L, 5L, 3L, 2L, 2L, 1L, 2L, 1L, 3L, 2L) typeof(n.filhos) ## [1] &quot;integer&quot; is.numeric(n.filhos) ## [1] TRUE is.double(n.filhos) ## [1] FALSE nomes &lt;- c(&#39;Maria&#39;, &#39;João&#39;, &#39;Manuel&#39;, &#39;Petronio&#39;, &#39;José&#39;) typeof(nomes) ## [1] &quot;character&quot; is.numeric(nomes) ## [1] FALSE is.double(nomes) ## [1] FALSE altura &lt;- c(1.60, 1.78, 1.55, 1.67, 1.69) typeof(altura) ## [1] &quot;double&quot; is.numeric(altura) ## [1] TRUE is.double(altura) ## [1] TRUE 4.11 Dataframes Dataframes são objetos de dados genéricos de R, usados para armazenar os dados tabulares, onde os dados são organizados de maneira lógica em um formato de linha-e-coluna semelhante ao de uma planilha do Excel. O data frame é uma estrutura bidimensional. Estas dimensões podem ser encontradas com a função dim(). Os Data frames podem ser formados com objetos criados previamente, desde que tenham o mesmo comprimento (56). Abaixo serão criadas algumas variáveis, todas relacionadas ao nascimento de 15 bebês: id &lt;- c(1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15) pesoRN &lt;- c (3340,3345,3750,3650,3220,4070,3380,3970,3060,3180, 2865,2815,3245,2051,2630) compRN &lt;- c (50,48,52,48,50,51,50,51,47,47,47,49,51,50,44) sexo &lt;- c (2,2,2,1,1,1,2,1,1,1,2,2,1,1,2) tipoParto &lt;- c (1,1,2,1,2,2,1,2,1,1,1,2,1,1,1) idadeMae &lt;- c (40,19,26,19,32,24,27,20,21,19,23,36,21,23,23) Tem-se um grupo de variáveis isoladas. Seria útil reuni-las em um só objeto, usando a função data.frame(). Este novo objeto receberá o nome de dadosNeonatos. dadosNeonatos &lt;- data.frame (id, pesoRN, compRN, sexo, tipoParto, idadeMae) Ao ser executado o comando retornará um novo objeto da classe data.frame: class (dadosNeonatos) ## [1] &quot;data.frame&quot; Havendo necessidade de acrescentar outra variável no banco de dados dadosNeonatos, por exemplo, os dados da ida ou não dos recém-nascidos para a UTI. Para isso, será atribuido a um vetor, contendo a situação dos 15 recém-nascidos, o nome de utiNeo e para relacioná-lo a uma coluna do dataframe dadosNeonatos, será usado o símbolo $, como mostrado abaixo 5: dadosNeonatos$utiNeo &lt;- c (2,2,2,2,1,2,1,2,2,2,2,1,2,2,2) Para observar o novo banco de dados, pode-se usar a função str() do R base. Digitar no R Script: str (dadosNeonatos) ## &#39;data.frame&#39;: 15 obs. of 7 variables: ## $ id : num 1 2 3 4 5 6 7 8 9 10 ... ## $ pesoRN : num 3340 3345 3750 3650 3220 ... ## $ compRN : num 50 48 52 48 50 51 50 51 47 47 ... ## $ sexo : num 2 2 2 1 1 1 2 1 1 1 ... ## $ tipoParto: num 1 1 2 1 2 2 1 2 1 1 ... ## $ idadeMae : num 40 19 26 19 32 24 27 20 21 19 ... ## $ utiNeo : num 2 2 2 2 1 2 1 2 2 2 ... Observando a saida da função, verifica-se que o dataframe contém 15 linhas e 6 colunas e que todas as variáveis estão como variáveis numéricas , mas as variáveis sexo, tipoParto são variáveis categóricas, bem como a variável utiNeo, acrescentada depois. Há necessidade de fazer uma transformação dessas variáveis. 4.12 Fatores Os fatores, no R, são usados para trabalhar com variáveis categóricas. São variáveis usadas para categorizar e armazenar os dados, tendo um número limitado de valores diferentes. Um fator armazena os dados como um vetor de valores inteiros. O fator em R também é conhecido como uma variável categórica que armazena valores de dados de string e inteiros como níveis. O fator é usado principalmente em modelagem estatística e análise exploratória de dados com R (57). 4.12.1 Criando fatores No data frame dadosNeonatos, criado anteriormente, contém três variáveis (sexo, tipoParto e utiNeo) que estão como variáveis numéricas. É possível, desta forma, realizar operações aritméticas com elas. Isto, obviamente, seria um absurdo. Assim, é necessário transformá-las em fatores. Para isso, é usada a função factor(), nativa do R. Os principais argumentos desta função são: x \\(\\longrightarrow\\) vetor numérico levels \\(\\longrightarrow\\) vetor opcional dos valores que x pode assumir labels \\(\\longrightarrow\\) vetor de caracteres dos rótulos para os níveis, na mesma ordem ordered \\(\\longrightarrow\\) vetor lógico (TRUE ou FALSE). Se TRUE, os níveis dos fatores são assumidos como ordenados No exemplo, as variáveis não têm uma ordem lógica, então, o argumento ordered não será usado. dadosNeonatos$utiNeo &lt;- factor (dadosNeonatos$utiNeo, levels = c(1,2), labels = c(&#39;sim&#39;,&#39;não&#39;)) dadosNeonatos$tipoParto &lt;- factor(dadosNeonatos$tipoParto, levels = c(1,2), labels = c(&quot;normal&quot;,&quot;cesareo&quot;)) dadosNeonatos$sexo &lt;- factor (dadosNeonatos$sexo, levels = c(1,2), labels = c(&quot;M&quot;,&quot;F&quot;)) Após a transformação, executa-se novamente a função str() para ver como ficou o dataframe: str(dadosNeonatos) ## &#39;data.frame&#39;: 15 obs. of 7 variables: ## $ id : num 1 2 3 4 5 6 7 8 9 10 ... ## $ pesoRN : num 3340 3345 3750 3650 3220 ... ## $ compRN : num 50 48 52 48 50 51 50 51 47 47 ... ## $ sexo : Factor w/ 2 levels &quot;M&quot;,&quot;F&quot;: 2 2 2 1 1 1 2 1 1 1 ... ## $ tipoParto: Factor w/ 2 levels &quot;normal&quot;,&quot;cesareo&quot;: 1 1 2 1 2 2 1 2 1 1 ... ## $ idadeMae : num 40 19 26 19 32 24 27 20 21 19 ... ## $ utiNeo : Factor w/ 2 levels &quot;sim&quot;,&quot;não&quot;: 2 2 2 2 1 2 1 2 2 2 ... Agora, as três varáveis passaram a ser fatores e as outras mantiveram-se numéricas. Desta forma, é possível trabalhar com ela fazendo, por exemplo, uma contagem da frequência do tipo de parto, usando a função table(): table(dadosNeonatos$tipoParto) ## ## normal cesareo ## 10 5 Ou seja, aproximadamente 70% dos partos desta amostra são normais. 4.12.2 Salvando o dataframe criado O data frame, criado e modificado anteriormente, pode ser salvo para uso posterior no diretório de trabalho. Para isso existe a função save (), fornecendo como argumentos o data frame a ser salvo e o nome do arquivo (file =) entre aspas. Por convenção, esta função salva com a extensão .RData que deve ser digitada, pois o R não a adiciona automaticamente. save(dadosNeonatos, file = &quot;dadosNeonatos.RData&quot;) Este comando colocará o arquivo no diretório de trabalho em uso. Portanto, se o objetivo é salvar em outro local, deve ser informado ao R qual o novo diretório. Para carregar o objeto salvo anteriormente com o comando save (), usa-se a função load (). Se o arquivo a ser lido não estiver no diretório de trabalho da sessão, há necessidade de especificar o caminho até o arquivo: load(&quot;dadosNeonatos.RData&quot;) Ou, indicando o diretório onde está o arquivo: load(&quot;C:/Users/petro/Dropbox/Estatistica/Meus_Livros/Bioestatistica_R/Book/dadosNeonatos.RData&quot;) É possível salvar em outro tipo de extensão como Excel (.xlsx), Valores Separados por Vírgula (.csv), etc. O procedimento é o mesmo, mudando a função. Para salvar em uma extensão .xlsx,utiliza-se a função write_xlsx () do pacote writexl (58): writexl::write_xlsx(dadosNeonatos, &quot;dadosNeonatos.xlsx&quot;) Para salvar com a extensão .csv, usar a função write.csv() ou write.csv2() que faz parte do pacote utils, incluido no R base. A primeira função, usa \".\" para a separação dos decimais e \",\" para separar as variáveis; a segunda função usa \",\" para os decimais e \";\" para separar as variáveis, convenção do Excel para algumas localidades, como o Brasil (59). Portanto, uma maneira de salvar o arquivo é: write.csv2 (dadosNeonatos, &quot;dadosNeonatos.csv&quot;) A instalação para Mac OS X pode ser facilmente obtida em busca do Google. Depois de instalado, o uso do RStudio não difere do Windows↩︎ Versão disponível em 10/04/2023↩︎ A variável criada, utiNeo, possui dois níveis: 1 = sim; 2 = não, referente se o bebê foi ou não para a UTI.↩︎ "],["manipulando-os-dados-no-r-studio.html", "Capítulo 5 Manipulando os dados no R Studio 5.1 Importando dados de outros softwares 5.2 Tibble 5.3 Pacote dplyr 5.4 Manipulação de datas", " Capítulo 5 Manipulando os dados no R Studio 5.1 Importando dados de outros softwares Foi visto. quando estudou-se os dataframes, que é possível inserir dados diretamente no R. Entretanto, se o conjunto de dados for muito extenso, torna-se complicado. Desta forma, é melhor importar os dados de outro software, como o Excel, SPSS, etc. A recomendação é que se construa o banco de dados, por exemplo, no Excel, e depois exporte o arquivo em um formato que o R reconheça – .xlsx, .csv, .sav, por exemplo. 5.1.1 Importando dados de um arquivo CSV O formato CSV significa Comma Separated Values, ou seja, é um arquivo de valores separados por vírgula. Esse formato de armazenamento é simples e agrupa informações de arquivos de texto em planilhas. É possível gerar um arquivo .csv, a partir de uma planilha do Excel, usando o menu salvar como e escolher CSV. As funções read.csv() e read.csv2(), incluídas no R base, podem ser utilizadas para importar arquivos CSV. Existe uma pequena diferença entre elas. Dois argumentos dessas funções têm padrão diferentes em cada uma. São eles: sep (separador de colunas) e dec (separador de decimais). Em read.csv(), o padrão é sep = ”,” e dec = ”.” e em read.csv2() o padrão é sep = “;” e dec = ”,”. Portanto, quando se importa um arquivo .csv, é importante saber qual a sua estrutura. Verificar se os decimais estão separados por ponto ou por vírgula e se as colunas (variáveis), por vírgula ou ponto e vírgula. Quando se usa o read.csv() há necessidade de informar o separador e o decimal, pois senão ele usará o padrão inglês e o arquivo não será lido. Já com read.csv2(), que o usa o padrão brasileiro, não há necessidade de informar ao R qual o separador de colunas e nem o separador dos decimais. Além disso, é necessário saber em que diretório do computador está o arquivo para informar ao comando. Recomenda-se colocar o arquivo na pasta do diretório de trabalho, pois assim basta apenas colocar o nome do arquivo na função de leitura dos dados. Caso contrário, tem-se que se usar todo o caminho (path). Como exemplo, será importado o arquivo dadosNeonatos.csv que se encontra no diretório de trabalho do autor, salvo anteriormente. Para obter o arquivo, clique no link e salve em seu diretório de trabalho. A estrutura deste arquivo mostra que as colunas estão separadas por ponto-e-virgula e, portanto, a leitura dos dados será feita com a função read.csv2() e, como o arquivo está no diretório de trabalho, não há necessidade de informar o diretório completo. Os dados serão colocados em um objeto de nome neonatos: neonatos &lt;- read.csv2(&quot;./Arquivos/dadosNeonatos.csv&quot;) str(neonatos) ## &#39;data.frame&#39;: 15 obs. of 7 variables: ## $ id : int 1 2 3 4 5 6 7 8 9 10 ... ## $ pesoRN : int 3340 3345 3750 3650 3220 4070 3380 3970 3060 3180 ... ## $ compRN : int 50 48 52 48 50 51 50 51 47 47 ... ## $ sexo : chr &quot;F&quot; &quot;F&quot; &quot;F&quot; &quot;M&quot; ... ## $ tipoParto: chr &quot;normal&quot; &quot;normal&quot; &quot;cesareo&quot; &quot;normal&quot; ... ## $ idadeMae : int 40 19 26 19 32 24 27 20 21 19 ... ## $ utiNeo : chr &quot;n\\xe3o&quot; &quot;n\\xe3o&quot; &quot;n\\xe3o&quot; &quot;n\\xe3o&quot; ... Recentemente, foi desenvolvido o pacote readr, incluído no conjunto de pacotes tidyverse(60), para lidar rapidamente com a leitura de grandes arquivos. O pacote fornece substituições para funções como read.csv(). As funções read_csv() e read_csv2() oferecidas pelo readr são análogas às do R base. Entretanto, são muito mais rápidas e fornecem mais recursos, como um método compacto para especificar tipos de coluna. Uma leitura típica para read_csv2() terá a seguinte aparência. Será criado um outro objeto de nome recemNascidos apenas para facilitar, didaticamente, ele é exatamente igual ao neonatos: library(readr) recemNascidos &lt;- read_csv2(&quot;Arquivos/dadosNeonatos.csv&quot;) ## ℹ Using &quot;&#39;,&#39;&quot; as decimal and &quot;&#39;.&#39;&quot; as grouping mark. Use `read_delim()` for more control. ## Rows: 15 Columns: 7 ## ── Column specification ──────────────────────────────────────────────────────── ## Delimiter: &quot;;&quot; ## chr (3): sexo, tipoParto, utiNeo ## dbl (4): id, pesoRN, compRN, idadeMae ## ## ℹ Use `spec()` to retrieve the full column specification for this data. ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message. str(recemNascidos) ## spc_tbl_ [15 × 7] (S3: spec_tbl_df/tbl_df/tbl/data.frame) ## $ id : num [1:15] 1 2 3 4 5 6 7 8 9 10 ... ## $ pesoRN : num [1:15] 3340 3345 3750 3650 3220 ... ## $ compRN : num [1:15] 50 48 52 48 50 51 50 51 47 47 ... ## $ sexo : chr [1:15] &quot;F&quot; &quot;F&quot; &quot;F&quot; &quot;M&quot; ... ## $ tipoParto: chr [1:15] &quot;normal&quot; &quot;normal&quot; &quot;cesareo&quot; &quot;normal&quot; ... ## $ idadeMae : num [1:15] 40 19 26 19 32 24 27 20 21 19 ... ## $ utiNeo : chr [1:15] &quot;n\\xe3o&quot; &quot;n\\xe3o&quot; &quot;n\\xe3o&quot; &quot;n\\xe3o&quot; ... ## - attr(*, &quot;spec&quot;)= ## .. cols( ## .. id = col_double(), ## .. pesoRN = col_double(), ## .. compRN = col_double(), ## .. sexo = col_character(), ## .. tipoParto = col_character(), ## .. idadeMae = col_double(), ## .. utiNeo = col_character() ## .. ) ## - attr(*, &quot;problems&quot;)=&lt;externalptr&gt; 5.1.2 Importando um arquivo do Excel O pacote readxl, pertencente ao conjunto de pacotes do tidyverse, facilita a obtenção de dados do Excel para o R, através da função read_excel(). esta função tem o argumento sheet = , que deve ser usado indicando o número ou o nome da planilha, colocado entre aspas. Este argumento é importante se houver mais de uma planilha, caso contrário, ele é opcional. Para saber os outros argumentos da função, colque o cursor dentro da função e aperte a tecla Tab (Figura 5.1). Isto abrirá um menu com os argumentos: Figure 5.1: Argumentos da função para importar arquivos xlsx Será feita a leitura dos mesmos dados, usados na leitura de dados csv, apenas o arquivo agora está no formato .xlsx. Para obter o arquivo, siga os mesmos passos, usados anteriormante. Clique no link e salve em seu diretório de trabalho. Os dados serão atribuídos a um objeto com outro nome (recemNatos): library(readxl) recemNatos &lt;- read_excel(&quot;Arquivos/dadosNeonatos.xlsx&quot;) str(recemNatos) ## tibble [15 × 7] (S3: tbl_df/tbl/data.frame) ## $ id : num [1:15] 1 2 3 4 5 6 7 8 9 10 ... ## $ pesoRN : num [1:15] 3340 3345 3750 3650 3220 ... ## $ compRN : num [1:15] 50 48 52 48 50 51 50 51 47 47 ... ## $ sexo : chr [1:15] &quot;F&quot; &quot;F&quot; &quot;F&quot; &quot;M&quot; ... ## $ tipoParto: chr [1:15] &quot;normal&quot; &quot;normal&quot; &quot;cesareo&quot; &quot;normal&quot; ... ## $ idadeMae : num [1:15] 40 19 26 19 32 24 27 20 21 19 ... ## $ utiNeo : chr [1:15] &quot;não&quot; &quot;não&quot; &quot;não&quot; &quot;não&quot; ... 5.1.3 Importando arquivos com o RStudio O RStudio permite importar arquivos sem a necessidade de digitar comandos, que, para alguns podem ser tediosos. Na tela inicial do RStudio, à direita, na parte superior, clique na aba Environment e em Import Dataset. Esta ação abre um menu que permite importar arquivos .csv, Excel, SPSS, etc. Por exemplo, para importar o arquivo dadosNeonatos.xlsx, clicar em From Excel... Abre uma janela com uma caixa de diálogo. Clicar no botão Browse..., localizado em cima à direita, para buscar o arquivo dadosNeonatos.xlsx. Assim que o arquivo for aberto, ele mostra uma preview do arquivo e, em baixo, à direita mostra uma preview do código (Figura 5.2), igual ao digitado anteriormente, que cria um objeto denominado dadosNeonatos, nome do objeto escolhido pelo R, mas pode ser modificado na janela, à esquerda, Import Option em Name, onde pode-se digitar qualquer nome. Após encerrar as escolhas, clicar em Import. É um caminho diferente para fazer o mesmo. Este é um dos fascínios do R! Figure 5.2: Importando arquivos do excel com o RStudio. 5.2 Tibble A maneira mais comum de armazenar dados no R é usar data.frames ou tibble. Tibble é um novo tipo de dataframe. É como se fosse um dataframe mais moderno. Ele mantém muitos recursos importantes do data frame original, mas remove muitos dos recursos desatualizados. Os tibbles são outro recurso incrível adicionado ao R por Hadley Wickham, através do tidyverse, conjunto de pacotes que formam um conjunto básico de funções que facilitam a manipulação e representação gráfica dos dados (60). Para saber mais sobre tibble, veja vignette(‘tibbles’). A maioria dos pacotes do R usa dataframes tradicionais, entretanto é possível transformá-los para tibble, usando a função as_tibble(), incluída no pacote tidyr (61). O único propósito deste pacote é simplificar o processo de criação de tidy data(dados organizados). O conceito de tidy data, introduzido por Wickman (62), se refere à estrutura dos dados organizados de maneira que cada linha é uma observação, cada coluna representa variáveis e cada entrada nas células do dataframe são os valores. A transformação de um data frame tradicional em um tibble, é um procedimento rescomendável, em função da maior flexibilidade destes. Como exemplo deste procedimento, será usado o famoso conjunto de dados da flor iris (63) que fornece as medidas em centímetros das variáveis comprimento e largura da sepala e comprimento e largura da pétala, repectivamente, para 50 flores de cada uma das 3 espécies de íris (Iris setosa, versicolor e virginica). Este conjunto de dados encontra-se no pacote datasets no R base. Para visualizar os dados, será usado a função str(), também do R base, que mostra a estrutura interna de um objeto: str(iris) ## &#39;data.frame&#39;: 150 obs. of 5 variables: ## $ Sepal.Length: num 5.1 4.9 4.7 4.6 5 5.4 4.6 5 4.4 4.9 ... ## $ Sepal.Width : num 3.5 3 3.2 3.1 3.6 3.9 3.4 3.4 2.9 3.1 ... ## $ Petal.Length: num 1.4 1.4 1.3 1.5 1.4 1.7 1.4 1.5 1.4 1.5 ... ## $ Petal.Width : num 0.2 0.2 0.2 0.2 0.2 0.4 0.3 0.2 0.2 0.1 ... ## $ Species : Factor w/ 3 levels &quot;setosa&quot;,&quot;versicolor&quot;,..: 1 1 1 1 1 1 1 1 1 1 ... Observa-se que é um conjunto de dados da classe data.frame, contendo 150 observações de 5 variáveis (colunas). Fazendo a coerção para um tibble, tem-se: library(tidyr) as_tibble(iris) ## # A tibble: 150 × 5 ## Sepal.Length Sepal.Width Petal.Length Petal.Width Species ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;fct&gt; ## 1 5.1 3.5 1.4 0.2 setosa ## 2 4.9 3 1.4 0.2 setosa ## 3 4.7 3.2 1.3 0.2 setosa ## 4 4.6 3.1 1.5 0.2 setosa ## 5 5 3.6 1.4 0.2 setosa ## 6 5.4 3.9 1.7 0.4 setosa ## 7 4.6 3.4 1.4 0.3 setosa ## 8 5 3.4 1.5 0.2 setosa ## 9 4.4 2.9 1.4 0.2 setosa ## 10 4.9 3.1 1.5 0.1 setosa ## # … with 140 more rows 5.3 Pacote dplyr O pacote dpylr é comumente usado para limpar e trabalhar com dados (64). No nível mais básico, as funções do pacote referem-se a “verbos” de manipulação de dados, como select, filter, mutate, arrange, summarize, entre outros, que permitem encadear várias etapas em algumas linhas de código, como será visto adiante. O pacote dplyr é adequado para trabalhar com um único conjunto de dados, bem como para obter resultados complexos em grandes conjuntos de dados. As funções dplyr são processadas mais rápido do que as funções R base. Para trabalhar na manipulação dos dados serão usados alguns pacotes, já mencionados anteriormente, readxl(65) e dplyr, e o conjunto de dados dadosMater.xlsx. Para obter estes dados, clique aqui e faça o download para o seu diretório de trabalho, como orientado anteriormente. library(readxl) library(dplyr) mater &lt;- read_excel(&quot;Arquivos/dadosMater.xlsx&quot;) A função read_excel() carrega o arquivo e o coloca em objeto que foi, arbitrariamente, chamado de mater6. as_tibble(mater) ## # A tibble: 1,368 × 30 ## id idadeMae altura peso ganhoP…¹ anosEst cor eCivil renda fumo quant…² ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1 42 1.65 69.9 3.9 3 2 1 1.45 2 0 ## 2 2 29 1.66 78 16.5 11 1 2 2.41 2 0 ## 3 3 19 1.72 81 5 9 2 1 1.93 2 0 ## 4 4 31 1.55 74 43 5 2 2 1.45 2 0 ## 5 5 34 1.6 60 15 7 2 2 0.48 2 0 ## 6 6 29 1.5 60 11.4 8 2 2 0.96 1 10 ## 7 7 30 1.54 75.5 10.5 4 1 2 1.2 1 20 ## 8 8 34 1.63 61 9 6 1 2 2.41 2 0 ## 9 9 17 1.68 57 15 10 1 2 2.17 2 0 ## 10 10 32 1.5 70 11.4 1 2 2 0.72 2 0 ## # … with 1,358 more rows, 19 more variables: prenatal &lt;dbl&gt;, para &lt;dbl&gt;, ## # droga &lt;dbl&gt;, ig &lt;dbl&gt;, tipoParto &lt;dbl&gt;, pesoPla &lt;dbl&gt;, sexo &lt;dbl&gt;, ## # pesoRN &lt;dbl&gt;, compRN &lt;dbl&gt;, pcRN &lt;dbl&gt;, apgar1 &lt;dbl&gt;, apgar5 &lt;dbl&gt;, ## # utiNeo &lt;dbl&gt;, obito &lt;dbl&gt;, hiv &lt;dbl&gt;, sifilis &lt;dbl&gt;, rubeola &lt;dbl&gt;, ## # toxo &lt;dbl&gt;, infCong &lt;dbl&gt;, and abbreviated variable names ¹​ganhoPeso, ## # ²​quantFumo Por padrão, a função retorna as dez primeiras linhas. Além disso, colunas que não couberem na largura da tela serão omitidas. Também são apresentadas a dimensão da tabela e as classes de cada coluna. Observa-se que ele tem 1368 linhas (observações) e 30 colunas (variáveis). Além disso, verifica-se que todas as variáveis estão como numéricas (dbl) e, certamente, algumas, dependendo do objetivo na análise, precisarão ser transformadas. O significado de cada uma das variáveis do arquivo dadosMater.xlsx 7 são mostrados abaixo. id \\(\\longrightarrow\\) identificação do participante idadeMae \\(\\longrightarrow\\) idade da parturiente em anos altura \\(\\longrightarrow\\) altura da parturiente em metros peso \\(\\longrightarrow\\) peso da parturiente em kg ganhoPeso \\(\\longrightarrow\\) aumento de peso durante a gestação anosEst \\(\\longrightarrow\\) anos de estudo completos cor \\(\\longrightarrow\\) cor declarada pela parturiente: 1 = branca; 2 = não branca eCivil \\(\\longrightarrow\\) estado civil: 1 = solteira; 2 = casada ou companheira renda \\(\\longrightarrow\\) renda familiar em salários minimos fumo \\(\\longrightarrow\\) tabagismo: 1 = sim; 2 = não quantFumo \\(\\longrightarrow\\) quantidade de cigarros fumados diariamente prenatal \\(\\longrightarrow\\) realizou pelo menos 6 consultas no pré-natal? 1 = sim; 2 = não para \\(\\longrightarrow\\) número de filhos paridos droga \\(\\longrightarrow\\) drogadição? 1 = sim; 2 = não ig \\(\\longrightarrow\\) idade gestacional em semanas tipoParto \\(\\longrightarrow\\) tipo de parto: 1 = normal; 2 = cesareana pesoPla \\(\\longrightarrow\\) peso da placenta em gramas sexo \\(\\longrightarrow\\) sexo do recém-nascido (RN): 1 = masc; 2 = fem pesoRN \\(\\longrightarrow\\) peso do RN em gramas compRN \\(\\longrightarrow\\) comprimento do RN em cm pcRN \\(\\longrightarrow\\) perímetro cefálico dorecém-nascido em cm apgar1 \\(\\longrightarrow\\) escore de Apgar no primeiro minuto apgar5 \\(\\longrightarrow\\) escore de Apgar no quinto minuto utiNeo \\(\\longrightarrow\\) RN necessitou de terapia intesiva? 1 = sim; 2 = não obito \\(\\longrightarrow\\) obito no período neonatal? 1 = sim; 2 = não hiv \\(\\longrightarrow\\) parturiente portadora de HIV? 1 = sim; 2 = não sifilis \\(\\longrightarrow\\) paruriente portadora de sífilis? 1 = sim; 2 = não rubeola \\(\\longrightarrow\\) paruriente portadora de rubéola? 1 = sim; 2 = não toxo \\(\\longrightarrow\\) paruriente portadora de toxoplasmose? 1 = sim; 2 = não infCong \\(\\longrightarrow\\) paruriente portadora de alguma infecção congênita? 1 = sim; 2 = não 5.3.1 Função select() A função select () é usada para escolher com quais colunas (variáveis) entrarão na análise. Ela recebe os nomes das colunas como argumentos e cria um novo banco de dados usando as colunas selecionadas. A função select () pode ser combinada com outras funções, como filter (). Por exemplo, um novo banco de dados será criado (mater1), contendo as mesmas 1368 linhas, mas apenas com as variáveis idadeMae, altura, peso, anosEst, renda, ig, fumo, pesoRN, sexo. Consulte a ajuda (?select()) para obter maiores informações em relação aos argumentos da função: mater1 &lt;- select(mater, idadeMae, altura, peso, anosEst, renda, ig, tipoParto, fumo, pesoRN, sexo) Para visualizar este novo banco de dados, pode-se usar a função str(): str(mater1) ## tibble [1,368 × 10] (S3: tbl_df/tbl/data.frame) ## $ idadeMae : num [1:1368] 42 29 19 31 34 29 30 34 17 32 ... ## $ altura : num [1:1368] 1.65 1.66 1.72 1.55 1.6 1.5 1.54 1.63 1.68 1.5 ... ## $ peso : num [1:1368] 69.9 78 81 74 60 60 75.5 61 57 70 ... ## $ anosEst : num [1:1368] 3 11 9 5 7 8 4 6 10 1 ... ## $ renda : num [1:1368] 1.45 2.41 1.93 1.45 0.48 0.96 1.2 2.41 2.17 0.72 ... ## $ ig : num [1:1368] 29 33 33 33 33 33 33 33 34 34 ... ## $ tipoParto: num [1:1368] 2 2 1 1 2 1 2 1 1 2 ... ## $ fumo : num [1:1368] 2 2 2 2 2 1 1 2 2 2 ... ## $ pesoRN : num [1:1368] 1035 2300 1580 1840 2475 ... ## $ sexo : num [1:1368] 2 2 2 2 2 2 2 2 2 2 ... Como mostrado anteriormente, muitas variáveis numéricas do mater, na realidade, são fatores e necessitam de serem modificadas. Entretanto, das selecionadas, para constituir o novo banco de dados, apenas tipoParto, fumo e sexo necessitam serem transformadas para fator: mater1$tipoParto &lt;- factor(mater1$tipoParto, levels = c(1,2), labels = c(&quot;normal&quot;,&quot;cesareo&quot;)) mater1$fumo &lt;- factor (mater1$fumo, levels = c(1,2), labels = c(&#39;sim&#39;,&#39;não&#39;)) mater1$sexo &lt;- factor (mater1$sexo, levels = c(1,2), labels = c(&quot;masc&quot;,&quot;fem&quot;)) Usando, de novo, a função str(), é possível observar a transformação: str(mater1) ## tibble [1,368 × 10] (S3: tbl_df/tbl/data.frame) ## $ idadeMae : num [1:1368] 42 29 19 31 34 29 30 34 17 32 ... ## $ altura : num [1:1368] 1.65 1.66 1.72 1.55 1.6 1.5 1.54 1.63 1.68 1.5 ... ## $ peso : num [1:1368] 69.9 78 81 74 60 60 75.5 61 57 70 ... ## $ anosEst : num [1:1368] 3 11 9 5 7 8 4 6 10 1 ... ## $ renda : num [1:1368] 1.45 2.41 1.93 1.45 0.48 0.96 1.2 2.41 2.17 0.72 ... ## $ ig : num [1:1368] 29 33 33 33 33 33 33 33 34 34 ... ## $ tipoParto: Factor w/ 2 levels &quot;normal&quot;,&quot;cesareo&quot;: 2 2 1 1 2 1 2 1 1 2 ... ## $ fumo : Factor w/ 2 levels &quot;sim&quot;,&quot;não&quot;: 2 2 2 2 2 1 1 2 2 2 ... ## $ pesoRN : num [1:1368] 1035 2300 1580 1840 2475 ... ## $ sexo : Factor w/ 2 levels &quot;masc&quot;,&quot;fem&quot;: 2 2 2 2 2 2 2 2 2 2 ... Se houver necessidade de se excluir alguma variável (coluna), basta colocar o sinal de subtração (-) antes do nome da variável: mater2 &lt;- select(mater1, -altura) str(mater2) ## tibble [1,368 × 9] (S3: tbl_df/tbl/data.frame) ## $ idadeMae : num [1:1368] 42 29 19 31 34 29 30 34 17 32 ... ## $ peso : num [1:1368] 69.9 78 81 74 60 60 75.5 61 57 70 ... ## $ anosEst : num [1:1368] 3 11 9 5 7 8 4 6 10 1 ... ## $ renda : num [1:1368] 1.45 2.41 1.93 1.45 0.48 0.96 1.2 2.41 2.17 0.72 ... ## $ ig : num [1:1368] 29 33 33 33 33 33 33 33 34 34 ... ## $ tipoParto: Factor w/ 2 levels &quot;normal&quot;,&quot;cesareo&quot;: 2 2 1 1 2 1 2 1 1 2 ... ## $ fumo : Factor w/ 2 levels &quot;sim&quot;,&quot;não&quot;: 2 2 2 2 2 1 1 2 2 2 ... ## $ pesoRN : num [1:1368] 1035 2300 1580 1840 2475 ... ## $ sexo : Factor w/ 2 levels &quot;masc&quot;,&quot;fem&quot;: 2 2 2 2 2 2 2 2 2 2 ... 5.3.2 Função filter() A função filter() é usada para criar um subconjunto de dados que obedeçam determinadas condições lógicas: &amp; (e), | (ou) e ! (não). Por exemplo: y &amp; !x \\(\\longrightarrow\\) seleciona y e não x x &amp; !y \\(\\longrightarrow\\) seleciona x e não y x | !x \\(\\longrightarrow\\) seleciona x ou y x &amp; !x \\(\\longrightarrow\\) seleciona x e y Um recém-nascido é dito a termo quando a duração da gestação é igual a 37 a 42 semanas incompletas. Se quisermos extrair do banco de dados mater2 os recém-nascidos a termo, pode-se usar a função filter(): mater3 &lt;- filter (mater2, ig&gt;=37 &amp; ig&lt;42) Para exibir o resultado, execute a função str(): str(mater3) ## tibble [1,085 × 9] (S3: tbl_df/tbl/data.frame) ## $ idadeMae : num [1:1085] 28 31 27 28 18 28 22 28 25 14 ... ## $ peso : num [1:1085] 48.5 65 60 47 65.5 72 65 74 70 56.7 ... ## $ anosEst : num [1:1085] 6 5 8 8 7 11 6 5 9 6 ... ## $ renda : num [1:1085] 3.13 0.72 2.41 1.69 1.93 1.92 2.65 2.53 0.48 1.92 ... ## $ ig : num [1:1085] 37 37 37 38 39 39 39 39 39 39 ... ## $ tipoParto: Factor w/ 2 levels &quot;normal&quot;,&quot;cesareo&quot;: 1 2 2 1 1 2 2 1 1 1 ... ## $ fumo : Factor w/ 2 levels &quot;sim&quot;,&quot;não&quot;: 2 2 1 2 1 1 2 2 2 2 ... ## $ pesoRN : num [1:1085] 3285 3100 3100 2800 3270 ... ## $ sexo : Factor w/ 2 levels &quot;masc&quot;,&quot;fem&quot;: 1 1 1 1 1 1 1 1 1 1 ... Observe que, agora, o conjunto de dados mater3 tem 1085 linhas, número de recém-nascidos a termo do banco de dados original mater (1368). Logo, os recém nascidos a termo correspondem a 79.3% dos nascimentos, nesta maternidade. Outro exemplo Para selecionar apenas os meninos, codificados como \"masc\", procede-se da seguinte maneira8: meninos &lt;- filter (mater1, sexo == &#39;masc&#39;) str(meninos) ## tibble [731 × 10] (S3: tbl_df/tbl/data.frame) ## $ idadeMae : num [1:731] 19 27 28 31 27 28 18 28 22 28 ... ## $ altura : num [1:731] 1.53 1.75 1.5 1.55 1.6 1.58 1.76 1.63 1.54 1.55 ... ## $ peso : num [1:731] 70 62 48.5 65 60 47 65.5 72 65 74 ... ## $ anosEst : num [1:731] 7 11 6 5 8 8 7 11 6 5 ... ## $ renda : num [1:731] 0.92 2.41 3.13 0.72 2.41 1.69 1.93 1.92 2.65 2.53 ... ## $ ig : num [1:731] 36 36 37 37 37 38 39 39 39 39 ... ## $ tipoParto: Factor w/ 2 levels &quot;normal&quot;,&quot;cesareo&quot;: 2 2 1 2 2 1 1 2 2 1 ... ## $ fumo : Factor w/ 2 levels &quot;sim&quot;,&quot;não&quot;: 2 2 2 2 1 2 1 1 2 2 ... ## $ pesoRN : num [1:731] 2160 2800 3285 3100 3100 ... ## $ sexo : Factor w/ 2 levels &quot;masc&quot;,&quot;fem&quot;: 1 1 1 1 1 1 1 1 1 1 ... O banco de dados meninos é constituídos por 731 meninos. Isto representa 53.4% dos nascimentos. Uma outra maneira de se fazer o mesmo é usar a função grepl(), dentro da função filter (). Ela é usada para pesquisar a correspondência de padrões. No código a seguir, pesquisa-se os registros em que a variável sexo contém “fem”, correspondentes às meninas. meninas &lt;- filter (mater1, grepl(&quot;fem&quot;, sexo)) str(meninas) ## tibble [637 × 10] (S3: tbl_df/tbl/data.frame) ## $ idadeMae : num [1:637] 42 29 19 31 34 29 30 34 17 32 ... ## $ altura : num [1:637] 1.65 1.66 1.72 1.55 1.6 1.5 1.54 1.63 1.68 1.5 ... ## $ peso : num [1:637] 69.9 78 81 74 60 60 75.5 61 57 70 ... ## $ anosEst : num [1:637] 3 11 9 5 7 8 4 6 10 1 ... ## $ renda : num [1:637] 1.45 2.41 1.93 1.45 0.48 0.96 1.2 2.41 2.17 0.72 ... ## $ ig : num [1:637] 29 33 33 33 33 33 33 33 34 34 ... ## $ tipoParto: Factor w/ 2 levels &quot;normal&quot;,&quot;cesareo&quot;: 2 2 1 1 2 1 2 1 1 2 ... ## $ fumo : Factor w/ 2 levels &quot;sim&quot;,&quot;não&quot;: 2 2 2 2 2 1 1 2 2 2 ... ## $ pesoRN : num [1:637] 1035 2300 1580 1840 2475 ... ## $ sexo : Factor w/ 2 levels &quot;masc&quot;,&quot;fem&quot;: 2 2 2 2 2 2 2 2 2 2 ... 5.3.3 Função mutate() Esta função tem a finalidade de computar ou anexar uma ou mais colunas (variáveis) novas. O Índice de Massa Corporal (IMC) é igual a \\[ IMC=\\frac{peso}{altura^{2}} \\] Será acrescentado a variável imc, no banco de dados mater1, usando a função mutate(): mater1 &lt;- mutate(mater1, imc = peso/altura^2) Para ver esta variável presente no banco de dados, executar: str (mater1) ## tibble [1,368 × 11] (S3: tbl_df/tbl/data.frame) ## $ idadeMae : num [1:1368] 42 29 19 31 34 29 30 34 17 32 ... ## $ altura : num [1:1368] 1.65 1.66 1.72 1.55 1.6 1.5 1.54 1.63 1.68 1.5 ... ## $ peso : num [1:1368] 69.9 78 81 74 60 60 75.5 61 57 70 ... ## $ anosEst : num [1:1368] 3 11 9 5 7 8 4 6 10 1 ... ## $ renda : num [1:1368] 1.45 2.41 1.93 1.45 0.48 0.96 1.2 2.41 2.17 0.72 ... ## $ ig : num [1:1368] 29 33 33 33 33 33 33 33 34 34 ... ## $ tipoParto: Factor w/ 2 levels &quot;normal&quot;,&quot;cesareo&quot;: 2 2 1 1 2 1 2 1 1 2 ... ## $ fumo : Factor w/ 2 levels &quot;sim&quot;,&quot;não&quot;: 2 2 2 2 2 1 1 2 2 2 ... ## $ pesoRN : num [1:1368] 1035 2300 1580 1840 2475 ... ## $ sexo : Factor w/ 2 levels &quot;masc&quot;,&quot;fem&quot;: 2 2 2 2 2 2 2 2 2 2 ... ## $ imc : num [1:1368] 25.7 28.3 27.4 30.8 23.4 ... Lembrar que este banco de dados mater5 é igual ao mater1, subconjunto do banco de dados original mater, apenas com acréscimo da variável imc. 5.3.4 Função sample_n() Função usada para selecionar de forma aleatória linhas de um dataframe. Sempre consulte a ajuda (?sample_n) para obter informações das funções. Os seus argumentos básicos são: tbl \\(\\longrightarrow\\) dataframe size \\(\\longrightarrow\\) número de linhas para selecionar replace \\(\\longrightarrow\\) amostra com ou sem reposição?. Padrão = FALSE Uma mostra de 20 neonatos selecionados do banco de dados meninospode ser selecionada do seguinte modo: meninos1 &lt;- sample_n(meninos, 20) Usando a função str(), verifica-se a estrutura deste pequeno conjunto de dados que pode ser considerado uma miniatura do original (2.7%). str(meninos1) ## tibble [20 × 10] (S3: tbl_df/tbl/data.frame) ## $ idadeMae : num [1:20] 42 33 22 23 20 32 19 20 19 37 ... ## $ altura : num [1:20] 1.55 1.58 1.6 1.65 1.59 1.6 1.54 1.51 1.59 1.6 ... ## $ peso : num [1:20] 71 70 63 56 59 73 49.5 70 55 48 ... ## $ anosEst : num [1:20] 6 11 11 8 6 5 6 8 8 11 ... ## $ renda : num [1:20] 1.92 1.93 2.17 1.57 4.82 2.89 1.08 2.89 1.92 1.92 ... ## $ ig : num [1:20] 39 34 40 41 40 40 40 40 38 36 ... ## $ tipoParto: Factor w/ 2 levels &quot;normal&quot;,&quot;cesareo&quot;: 2 2 2 1 1 2 2 2 2 2 ... ## $ fumo : Factor w/ 2 levels &quot;sim&quot;,&quot;não&quot;: 2 2 2 2 1 2 2 2 2 2 ... ## $ pesoRN : num [1:20] 3630 2500 4315 4045 3320 ... ## $ sexo : Factor w/ 2 levels &quot;masc&quot;,&quot;fem&quot;: 1 1 1 1 1 1 1 1 1 1 ... Uma outra função semelhante a esta é sample_frac(). Ela usa os mesmos argumentos que a sample_n(), modificando o argumento size, onde se informa a fração desejada até 1 (100%). Por exemplo, para se ter uma amostra de tamanho semelhante a anterior, há necessidade de selecionar, aproximadamente, uma fração de 0.027 da amostra. meninos2 &lt;- sample_frac(meninos, 0.027) str(meninos2) ## tibble [20 × 10] (S3: tbl_df/tbl/data.frame) ## $ idadeMae : num [1:20] 24 24 24 26 32 26 36 27 28 16 ... ## $ altura : num [1:20] 1.64 1.65 1.5 1.65 1.66 1.55 1.56 1.55 1.58 1.59 ... ## $ peso : num [1:20] 50 52 67 60 75 50 70 68 53 68 ... ## $ anosEst : num [1:20] 10 10 10 6 5 11 8 4 11 9 ... ## $ renda : num [1:20] 2.17 1.92 1.2 1.2 1.2 2.41 1.92 2.89 4.82 1.2 ... ## $ ig : num [1:20] 39 42 39 41 41 39 40 42 41 39 ... ## $ tipoParto: Factor w/ 2 levels &quot;normal&quot;,&quot;cesareo&quot;: 1 1 2 2 1 2 1 2 2 1 ... ## $ fumo : Factor w/ 2 levels &quot;sim&quot;,&quot;não&quot;: 2 2 1 1 2 2 2 2 2 2 ... ## $ pesoRN : num [1:20] 3445 3320 3635 4050 4370 ... ## $ sexo : Factor w/ 2 levels &quot;masc&quot;,&quot;fem&quot;: 1 1 1 1 1 1 1 1 1 1 ... É importante mencionar que toda vez que estas funções forem executadas elas irão gerar amostras diferentes. Então, por exemplo, não se deve esperar que a média dos pesos dos recém-nascidos de amostras diferentes sejam iguais. No capítulo sobre Distribuições Amostrais, este assunto voltará à cena. As funções sample_n() e sample_frac() estão com os dias contados, pois foram substituídas por slice_sample() do conjunto de funções que acompanham a função slice() 5.3.5 Função slice() Esta função é usada para selecionar um subconjunto linhas com base em seus locais inteiros. Permite selecionar, remover e duplicar linhas. Para os exemplos, será usado o conjunto de dados meninos, criado acima. Selecionando um subconjunto de uma linha específica # Selecionando a linha 10 meninos %&gt;% slice(10) ## # A tibble: 1 × 10 ## idadeMae altura peso anosEst renda ig tipoParto fumo pesoRN sexo ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;fct&gt; &lt;fct&gt; &lt;dbl&gt; &lt;fct&gt; ## 1 28 1.55 74 5 2.53 39 normal não 3650 masc # Selecionando várias linhas, por exemplo, linhas de 1 a 5 meninos %&gt;% slice(1:5) ## # A tibble: 5 × 10 ## idadeMae altura peso anosEst renda ig tipoParto fumo pesoRN sexo ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;fct&gt; &lt;fct&gt; &lt;dbl&gt; &lt;fct&gt; ## 1 19 1.53 70 7 0.92 36 cesareo não 2160 masc ## 2 27 1.75 62 11 2.41 36 cesareo não 2800 masc ## 3 28 1.5 48.5 6 3.13 37 normal não 3285 masc ## 4 31 1.55 65 5 0.72 37 cesareo não 3100 masc ## 5 27 1.6 60 8 2.41 37 cesareo sim 3100 masc É possível também selecionar linhas de acordo com determinado grupo, usando a função group_by(), incluído no pacote dplyr. meninos %&gt;% group_by(fumo) %&gt;% slice (1) ## # A tibble: 2 × 10 ## # Groups: fumo [2] ## idadeMae altura peso anosEst renda ig tipoParto fumo pesoRN sexo ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;fct&gt; &lt;fct&gt; &lt;dbl&gt; &lt;fct&gt; ## 1 27 1.6 60 8 2.41 37 cesareo sim 3100 masc ## 2 19 1.53 70 7 0.92 36 cesareo não 2160 masc A função slice() é acompanhada por vários auxiliares para casos de uso comuns: slice_head() e slice_tail() selecionam a primeira ou a última linha; slice_sample() seleciona linhas aleatoriamente; slice_min() e slice_max() selecionam linhas com valores mais altos ou mais baixos de uma variável. Selecionando um subconjunto de forma aleatória A função slice_sample() substitui a sample_n(). Por exemplo, para selecionar uma amostra aleatória de 20 meninos, usa-se: meninos3 &lt;- meninos %&gt;% slice_sample(n = 20) meninos3 ## # A tibble: 20 × 10 ## idadeMae altura peso anosEst renda ig tipoParto fumo pesoRN sexo ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;fct&gt; &lt;fct&gt; &lt;dbl&gt; &lt;fct&gt; ## 1 23 1.75 62.5 11 1.92 39 normal sim 3260 masc ## 2 28 1.52 47 8 2.41 37 cesareo não 2910 masc ## 3 23 1.6 56 8 2.05 35 normal não 2525 masc ## 4 21 1.51 52 6 1.69 40 normal não 2860 masc ## 5 16 1.55 53 6 1.33 39 cesareo não 3050 masc ## 6 28 1.58 52 11 4.1 26 cesareo sim 765 masc ## 7 24 1.53 50 4 1.57 41 cesareo não 3580 masc ## 8 27 1.61 72 5 1.2 41 normal não 2990 masc ## 9 13 1.54 47.2 6 2.41 37 cesareo não 3469 masc ## 10 21 1.62 69 8 9.64 39 cesareo não 2930 masc ## 11 27 1.55 59 11 3.61 39 normal não 3200 masc ## 12 29 1.69 75 8 1.45 39 cesareo sim 3655 masc ## 13 24 1.65 65 5 1.92 39 cesareo sim 2330 masc ## 14 24 1.59 75 12 2.89 40 cesareo não 2710 masc ## 15 18 1.52 70 6 0.92 39 normal não 3295 masc ## 16 21 1.48 65 4 0.84 39 normal não 3060 masc ## 17 20 1.72 69 9 1.2 37 cesareo não 3010 masc ## 18 20 1.58 77.5 5 2.41 41 normal não 2945 masc ## 19 31 1.6 60 5 1.92 37 cesareo não 2890 masc ## 20 21 1.62 54 8 6.75 35 normal não 2330 masc Para maiores informações em relação a estas funções consulte a ajuda (?slice()). 5.3.6 Função arrange() Ordena as linhas pelos valores de uma coluna de forma ascendente ou descentente. Voltando a amostra meninos1, será colocado em ordem crescente a variável pesoRN: arrange(meninos1, pesoRN) ## # A tibble: 20 × 10 ## idadeMae altura peso anosEst renda ig tipoParto fumo pesoRN sexo ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;fct&gt; &lt;fct&gt; &lt;dbl&gt; &lt;fct&gt; ## 1 28 1.58 52 11 4.1 26 cesareo sim 765 masc ## 2 19 1.55 53 11 1.92 28 normal não 1270 masc ## 3 25 1.5 63 8 2.41 34 normal sim 1960 masc ## 4 33 1.58 70 11 1.93 34 cesareo não 2500 masc ## 5 37 1.6 48 11 1.92 36 cesareo não 2705 masc ## 6 16 1.59 68 9 1.2 39 normal não 2940 masc ## 7 19 1.55 58.5 6 1.92 39 cesareo não 3085 masc ## 8 31 1.51 48 4 1.2 39 cesareo não 3160 masc ## 9 20 1.51 70 8 2.89 40 cesareo não 3170 masc ## 10 32 1.6 73 5 2.89 40 cesareo não 3230 masc ## 11 41 1.67 78 8 6.02 37 normal não 3275 masc ## 12 20 1.59 59 6 4.82 40 normal sim 3320 masc ## 13 19 1.54 49.5 6 1.08 40 cesareo não 3385 masc ## 14 19 1.59 55 8 1.92 38 cesareo não 3430 masc ## 15 30 1.55 55 6 1.69 39 normal não 3560 masc ## 16 42 1.55 71 6 1.92 39 cesareo não 3630 masc ## 17 32 1.58 105 11 1.69 40 cesareo não 3800 masc ## 18 23 1.65 56 8 1.57 41 normal não 4045 masc ## 19 26 1.65 60 6 1.2 41 cesareo sim 4050 masc ## 20 22 1.6 63 11 2.17 40 cesareo não 4315 masc Para a ordem decrescente, colocar a função desc(), dentro da função arrange() arrange(meninos1, desc(pesoRN)) ## # A tibble: 20 × 10 ## idadeMae altura peso anosEst renda ig tipoParto fumo pesoRN sexo ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;fct&gt; &lt;fct&gt; &lt;dbl&gt; &lt;fct&gt; ## 1 22 1.6 63 11 2.17 40 cesareo não 4315 masc ## 2 26 1.65 60 6 1.2 41 cesareo sim 4050 masc ## 3 23 1.65 56 8 1.57 41 normal não 4045 masc ## 4 32 1.58 105 11 1.69 40 cesareo não 3800 masc ## 5 42 1.55 71 6 1.92 39 cesareo não 3630 masc ## 6 30 1.55 55 6 1.69 39 normal não 3560 masc ## 7 19 1.59 55 8 1.92 38 cesareo não 3430 masc ## 8 19 1.54 49.5 6 1.08 40 cesareo não 3385 masc ## 9 20 1.59 59 6 4.82 40 normal sim 3320 masc ## 10 41 1.67 78 8 6.02 37 normal não 3275 masc ## 11 32 1.6 73 5 2.89 40 cesareo não 3230 masc ## 12 20 1.51 70 8 2.89 40 cesareo não 3170 masc ## 13 31 1.51 48 4 1.2 39 cesareo não 3160 masc ## 14 19 1.55 58.5 6 1.92 39 cesareo não 3085 masc ## 15 16 1.59 68 9 1.2 39 normal não 2940 masc ## 16 37 1.6 48 11 1.92 36 cesareo não 2705 masc ## 17 33 1.58 70 11 1.93 34 cesareo não 2500 masc ## 18 25 1.5 63 8 2.41 34 normal sim 1960 masc ## 19 19 1.55 53 11 1.92 28 normal não 1270 masc ## 20 28 1.58 52 11 4.1 26 cesareo sim 765 masc 5.3.7 Função count() Permite contar rapidamente os valores únicos de uma ou mais variáveis. Esta função tem os seguintes argumentos: x \\(\\longrightarrow\\) dataframe wt \\(\\longrightarrow\\) pode ser NULL (padrão) ou uma variável sort \\(\\longrightarrow\\) padrão = FALSE; se TRUE, mostrará os maiores grupos no topo name \\(\\longrightarrow\\) O nome da nova coluna na saída; padrão = NULL Quando o argumento name é omitido, a função retorna n como nome padrão. Usando o dataframe mater1, a função count() irá contar o número de parturientes fumantes, variável dicotômica fumo: count(mater1, fumo) ## # A tibble: 2 × 2 ## fumo n ## &lt;fct&gt; &lt;int&gt; ## 1 sim 301 ## 2 não 1067 5.3.8 Operador pipe %&gt;% O operador pipe %&gt;% pode ser usado para inserir um valor ou um objeto no primeiro argumento de uma função. Ele pode ser acionado digitando %&gt;% ou usando o atalho ctrl+shift+M. Em vez de passar o argumento para a função separadamente, é possível escrever o valor ou objeto e, em seguida, usar o pipe para convertê-lo como o argumento da função na mesma linha. Funciona como se o pipe jogasse o objeto dentro da função seguinte. Vários comando foram utilizados, manipulando o banco de dados mater. Alguns orocedimentos, serão mostrados, usando, agora, o operador pipe. Em primeiro lugar, serão selecionadas algumas colunas do dataframe mater; adicionada a variável imc; selecionado os recém-nascidos a termo do sexo masculino, que no banco de dados mater está codificado como 1. Tudo em um só comando! meusDados &lt;- mater %&gt;% select(idadeMae, altura, peso, anosEst, renda, ig, tipoParto, fumo, pesoRN, sexo) %&gt;% mutate(imc = peso/altura^2) %&gt;% filter (ig&gt;=37 &amp; ig&lt;42, sexo == 1) str(meusDados) ## tibble [592 × 11] (S3: tbl_df/tbl/data.frame) ## $ idadeMae : num [1:592] 28 31 27 28 18 28 22 28 25 14 ... ## $ altura : num [1:592] 1.5 1.55 1.6 1.58 1.76 1.63 1.54 1.55 1.56 1.51 ... ## $ peso : num [1:592] 48.5 65 60 47 65.5 72 65 74 70 56.7 ... ## $ anosEst : num [1:592] 6 5 8 8 7 11 6 5 9 6 ... ## $ renda : num [1:592] 3.13 0.72 2.41 1.69 1.93 1.92 2.65 2.53 0.48 1.92 ... ## $ ig : num [1:592] 37 37 37 38 39 39 39 39 39 39 ... ## $ tipoParto: num [1:592] 1 2 2 1 1 2 2 1 1 1 ... ## $ fumo : num [1:592] 2 2 1 2 1 1 2 2 2 2 ... ## $ pesoRN : num [1:592] 3285 3100 3100 2800 3270 ... ## $ sexo : num [1:592] 1 1 1 1 1 1 1 1 1 1 ... ## $ imc : num [1:592] 21.6 27.1 23.4 18.8 21.1 ... Observe que o dataframe mater aparece apenas no início e, como ele é um argumento das outras funções, ele é transferido, automaticamente, não havendo necessidade de escrever dentro na função. No final, retornará um novo dataframe que foi colocado em um objeto, denominado meuDados, o qual contém informações de todos os 592 meninos, nascidos a termo e de suas mães. 5.4 Manipulação de datas Originalmente, todos os que trabalham com o R queixavam-se de como era frustrante trabalhar com datas. Era um processo que causava grande perda de tempo nas análises. O pacote lubridate foi criado para simplificar ao máximo a leitura de datas e extração de informações dessas datas. Antes de usar, há necessidade de instalar e carregar o pacote. install.packages(&quot;lubridate&quot;) library(lubridate) A função mais importante para leitura de dados no lubridate é a ymd(). Essa função serve para ler qualquer data de uma string no formato YYYY-MM-DD. Para iniciar, será registrada uma data qualquer. Observe que o R registrou esta dada como um objeto da classe numérica. data.hoje &lt;- &quot;29/10/2022&quot; class (data.hoje) ## [1] &quot;character&quot; Para converter esta data da classe character para a classe date, usar a função dmy(): data.hoje &lt;- dmy(data.hoje) class(data.hoje) ## [1] &quot;Date&quot; Uma grande facilidade que essas funções trazem é poder criar objetos com classe date a partir de números e character em diversos formatos. dmy(29102022) ## [1] &quot;2022-10-29&quot; dmy(&quot;29/10/2022&quot;) ## [1] &quot;2022-10-29&quot; dmy(&quot;29102022&quot;) ## [1] &quot;2022-10-29&quot; dmy(&quot;29.10.2022&quot;) ## [1] &quot;2022-10-29&quot; Se além da data, houver necessidade de especificar o horário, basta usar dmy_h(), dmy_hm() e dmy_hms(). Se for usado o padrão americano, pode ser usado ymd(). O lubridate traz diversas funções para extrair os componentes de um objeto da classe date. second() - extrai os segundos. minute() - extrai os minutos. hour() - extrai a hora. wday() - extrai o dia da semana. mday() - extrai o dia do mês. month() - extrai o mês. year() - extrai o ano. Por exemplo, dn &lt;- dmy(&quot;04/10/1947&quot;) year(dn) ## [1] 1947 Para acrescentar um horário ao objeto data de nascimento (dn): hour(dn) &lt;- 04 dn ## [1] &quot;1947-10-04 04:00:00 UTC&quot; Data e horário do dia em que essa página foi editada pela última vez. today() ## [1] &quot;2023-04-22&quot; now() ## [1] &quot;2023-04-22 10:38:19 -03&quot; 5.4.1 Operações com datas Intervalos Intervalos podem ser salvos em objetos com a função interval(). inicio &lt;- dmy(&quot;01/01/2022&quot;) final &lt;- dmy(&quot;29/10/2022&quot;) periodo &lt;- interval(inicio, final) periodo ## [1] 2022-01-01 UTC--2022-10-29 UTC class(periodo) ## [1] &quot;Interval&quot; ## attr(,&quot;package&quot;) ## [1] &quot;lubridate&quot; Aritmética com datas # Somando datas today() + ddays(60) # hoje + 60 dias ## [1] &quot;2023-06-21&quot; today() + dyears(1) # hoje + 1 ano ## [1] &quot;2024-04-21 06:00:00 UTC&quot; # Duração de um intervalo intervalo &lt;-dmy(&quot;10-01-2022&quot;) %--% dmy(&quot;17-10-2022&quot;) intervalo ## [1] 2022-01-10 UTC--2022-10-17 UTC intervalo/ddays(1) # Número de dias ## [1] 280 intervalo/dmonths(1) # Número de meses ## [1] 9.199179 intervalo / dweeks(1) # Número de semanas ## [1] 40 as.period(intervalo) ## [1] &quot;9m 7d 0H 0M 0S&quot; Para mais informações sobre o lubridate, consulte a ajuda do pacote. ATENÇÃO: Volta-se a insistir, o comando para carregar o conjunto de dados somente funciona, sem colocar o caminho (path) completo, se tudo está sendo realizado no diretório de trabalho.↩︎ Conjunto de dados coletados na maternidade-escola do Hospital Geral de Caxias do Sul↩︎ Lembrar que o sinal de igualdade, no R, é duplo =↩︎ "],["descrevendo-os-dados.html", "Capítulo 6 Descrevendo os dados 6.1 Dados brutos 6.2 Medidas resumidoras 6.3 Tabelas 6.4 Gráficos 6.5 Introdução ao ggplot2", " Capítulo 6 Descrevendo os dados Nos relatórios ou artigos científicos, a comunicação dos resultados é feita através da combinação de medidas resumidoras e visualização dos dados por meio de tabelas e gráficos. 6.1 Dados brutos Habitualmente, costuma-se armazenar os dados em bancos de dados (dataframes ou tibbles). Entretanto, eles estão registrados de forma aleatória e não classificada. Ao se visualizar um dataframe, é difícil responder perguntas em relação a qualquer variável, principalmente, em grandes banco de dados. Eles se constituem uma lista, um rol de valores colocados na ordem em que foram obtidos. Parecem um jogo de quebra cabeça antes de serem organizados e resumidos! São denominados de dados brutos ou, também, de dados não agrupados. 6.2 Medidas resumidoras As maneiras mais usadas para resumir o conjunto de dados são: Primeiro, um valor em torno do qual os dados têm uma tendência para se reunir ou se agrupar, denominado de medida sumária de localização ou medida de tendência central. Em segundo lugar, um valor que mede o grau em que os dados se dispersam, denominado de medida de dispersão ou variabilidade. Para trabalhar nesta seção, serão necessários os seguintes pacotes: pacman::p_load(dplyr, readxl) E o arquivo dadosMater15.xlsx, amostra de 15 recém-nascidos, que pode ser obtido aqui e baixado para o seu diretório de trabalho. Esta amostra é proveniente do banco de dados original (dadosMater.xlsx), veja seção 5.3. Agora, será criado um objeto, mater15, para receber os dados, a partir do diretório de trabalho, executando o seguinte código: mater15 &lt;- read_excel(&quot;Arquivos/dadosMater15.xlsx&quot;) 6.2.1 Medidas de tendência central 6.2.1.1 Média A média ( \\(\\overline{x}\\) ) é a mais usada medida de tendência central. Ela é calculada pela razão entre a soma de todas as observações de um conjunto de dados e o total de observações. A média é mais adequada para medidas numéricas simétricas. \\[ \\overline{x}= \\frac{\\sum(x_1 + x_2 + x_3 + ... + x_n)}{n} \\] Se no conjunto de dados houver algum valor ausente (missing), o comando mostra o resultado como NA (not available). Para corrigir isto, basta colocar o argumento na.rm = TRUE na função mean(). Assim, o R vai retornar a média, ignorando os valores ausentes. Recomenda-se sempre usar o argumento. A média aritmética dos pesos dos recém-nascidos (pesoRN) do arquivo dadosMater15.xlsx é calculado por: mean (mater15$pesoRN, na.rm = TRUE) ## [1] 3238.067 6.2.1.2 Mediana A mediana (Md) representa o valor central em uma série ordenada de valores. Assim, metade dos valores será igual ou menor que o valor mediano e a outra metade igual ou maior do que ele. No R, usa-se a função median() para calcular o valor da mediana. Vanos utilizar a variável mater15$apgar1. Como o Apgar é um escore, a medida resumidora mais adequada é a mediana. median (mater15$apgar1, na.rm = TRUE) ## [1] 8 6.2.1.3 Moda Moda (Mo) é o valor que ocorre com maior frequência em um conjunto de dados. Tem o menor nível de sofisticação. É usada primariamente para dados nominais porque há simplesmente contagem dos valores. Ao contrário das outras medidas de tendência central, a moda não informa nada sobre a ordem das variáveis ou variação dentro das variáveis. O R não tem uma função embutida padrão para calcular a moda. Portanto, há necessidade de ser criada uma função de usuário para calcular a moda. moda &lt;- function(x) { z &lt;- table(as.vector(x)) names(z)[z == max(z)]} Usando esta função pode-se calcular a moda para a variável mater15$apgar1. moda (mater15$apgar1) ## [1] &quot;8&quot; 6.2.1.4 Quantil Uma medida de localização bastante utilizada são os quantis que são pontos estabelecidos em intervalos regulares que dividem a amostra em subconjuntos iguais. Se estes subconjuntos são em número de 100, são denominados de percentis; se são em número de 10, são os decis e em número de 4, são os quartis. A função apropriada no R para obter o quantil é quantile(). Para determinar os três quartis do peso dos recém-nascidos (mater15$pexoRN), usa-se: quantile (mater15$pesoRN, c (0.25, 0.50, 0.75)) ## 25% 50% 75% ## 2962.5 3245.0 3515.0 Observe que o percentil 50º é igual a mediana. O percentil 75º é o ponto do conjunto de dados onde 75% dos recém-nascidos têm um peso inferior a 3515g e 25% está acima deste valor. 6.2.1.5 Média aparada As médias aparadas são estimadores robustos da tendência central. Para calcular uma média aparada, é removida uma quantidade predeterminada de observações em cada lado de uma distribuição e realizada a média das observações restantes. Um exemplo de média aparada é a própria mediana. A base R tem como calcular a média aparada acrescentando o argumento trim =, proporção a ser aparada. Se for aparado 20%, usa-se trim = 0.2. isto significa que serão removidos 20% dos dados dos dois extremos. No caso da amostra de 15 recém-nascidos, serão removidos três valores mais baixos e três valores mais altos, passando a mostra a ter 9 valores, e a média aparada será a média destes 9 valores. O comando para obter a média aparada é: mean (mater15$pesoRN, na.rm = TRUE, trim = 0.20) ## [1] 3253.889 6.2.2 Medidas de Dispersão 6.2.2.1 Amplitude A amplitude de um grupo de medições é definida como a diferença entre a maior observação e a menor. No conjunto de dados dos pesos dos recém-nascidos, a amplitude pode ser obtida, no R, com a função range(), que retorna o valor mínimo e o máximo. range (mater15$pesoRN, na.rm = TRUE) ## [1] 2051 4070 6.2.2.2 Intervalo Interquartil A intervalo interquartil (IIQ), também conhecido como amplitude interquartil (AIQ) é uma forma de média aparada. É simplesmente a diferença entre o terceiro e o primeiro quartil, ou seja, a diferença entre o percentil 75 e o percentil 25. Considere a escolaridade (anosEst) das parturientes da amostra dadosMater15.xlsx. Os percentis 25 e 75 são obtidos por: quantile (mater15$anosEst, c(0.25,0.75)) ## 25% 75% ## 6 8 Também podeser usada a função summary (): summary(mater15$anosEst) ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 4 6 7 7 8 11 Portanto, o IIQ está entre 6 a 8 anos de estudo ou, 8 – 6 = 2 anos de estudos completos. Em outras palavras, 50% das mulheres desta amostra têm de 6 a 8 anos de estudo. O R possui uma função específica para calcular o intervalo interquartil, denominada IQR() e incluída no pacote stats, pertencente ao R base. Ela possui os seguintes argumentos: x \\(\\longrightarrow\\) Representa o vetor numérico; na.rm \\(\\longrightarrow\\) Este assume um valor lógico, TRUE ou FALSE, indicando se os valores ausentes devem ser removidos ou não; type \\(\\longrightarrow\\) Representa um número inteiro selecionando um dos muitos algoritmos de quantil. Este é um parâmetro opcional. IQR(mater15$anosEst, na.rm = TRUE) ## [1] 2 6.2.2.3 Variância e Desvio Padrão A variância e o desvio padrão fornecem uma indicação de quão aglomerados em torno da média os dados de uma amostra estão. Estes tipos de medidas representam desvios (erros)da média. Quando se verifica o desvio de cada valor (x) em relação à média \\(\\overline{x}\\), os desvios positivos se anulam com os negativos, resultando em uma soma igual a zero. A consequência deste fato é que não é possível resumir os desvios numa única medida de variabilidade. Para se chegar a uma medida de variabilidade há necessidade de se eliminar os sinais, antes de somar todos os desvios em relação à média. Uma maneira de se fazer isso é elevar todas as diferenças ao quadrado. Assim, se obtém o desvio em relação à média elevado ao quadrado. A soma destes valores é denominada de Soma dos Quadrados (SQ) dos Desvios ou Soma dos Erros ao Quadrado. Se o interesse é apenas saber o erro ou desvio médio, divide-se por n (tamanho da amostra). No entanto, em geral o interesse se concentra em usar o desvio ou erro na amostra para estimar o erro na população. Dessa maneira, divide-se a Soma dos Quadrados por \\(n-1\\). Essa medida é conhecida como variância (\\(s^2\\)). O divisor, \\(n – 1\\), é denominado de graus de liberdade (gl) associados à variância. Os graus de liberdade representam o número de desvios que estão livres para variar. É um conceito de difícil explicação. Suponha uma maternidade há 50 anos atrás, quando não havia alojamento conjunto. Nessa época era comum os recém-nascidos normais ficarem em um berçário. A cada horário de amamentação eles eram levados para os quartos de suas mães para mamar. Posteriormente, eram trazidos para o berçário e colocados nos berços até a próxima mamada. Suponha que, em um determinado momento, havia 15 bebês e que, no berçário, existiam 15 berços (postos) para colocá-los durante o intervalo das mamadas. Quando o primeiro recém-nascido chega, a enfermeira poderá escolher qualquer um dos berços para o colocar. Depois, quando o próximo recém-nascido chegar, ela terá 14 opções de escolha, pois um dos berços está ocupado. Ainda existe uma boa liberdade de escolha. No entanto, à medida que os recém-nascidos forem sendo trazidos para o berçário, chegará a um ponto em que 14 berços estarão ocupados. Agora, a enfermeira não terá liberdade de escolha, pois só resta um berço. Nesse exemplo existem 14 graus de liberdade. Para o último recém-nascido não houve liberdade de escolha (66). Portanto, os graus de liberdade são iguais ao tamanho da amostra menos um (\\(n-1\\)). A variância é a razão entre a soma dos quadrados e as observações realizadas menos um. \\[ s^2= \\frac{\\sum(x_i - \\overline{x})^2}{\\overline{n-1}} \\] No R existem as funções sd() e var(), também incluídas no R base, que facilmente calculam essas medidas de dispersão. Usando a variável mater15$pesoRN, tem-se: var(mater15$pesoRN, na.rm =TRUE) ## [1] 273861.8 O desvio padrão é a raiz quadrada da variância: \\(s = \\sqrt var\\) sqrt (var(mater15$pesoRN)) ## [1] 523.318 Ou, sd (mater15$pesoRN, na.rm = TRUE) ## [1] 523.318 A variância e desvio padrão são medidas de variabilidade. Representam quão bem a média representa os dados. Informa se ela está funcionando bem como modelo. Pequenos desvios padrão mostram que existe pouca variabilidade nos dados, que eles se aproximam da média. Quando existe um grande desvio padrão, a média não é muito precisa para representar os dados. O desvio padrão, além de medir a precisão com que a média representa os dados, também informa sobre o formato dos dados e por isso é uma medida de dispersão. Em uma amostra onde desvio padrão é pequeno, os dados se agrupam próximo a média e o formato da distribuição fica mais pontiagudo (curva em azul, 6.1). Nesse caso a média representa bem os dados. Em outra amostra, com a mesma média anterior, mas com os dados mais dispersos entorno da média, o desvio padrão é maior e o formato da distribuição fica achatado (curva verde, na Figura 6.1). Nesse caso a média não é uma boa representação dos dados. Figure 6.1: Dispersão dos dados em torno da média. 6.2.2.4 Coeficiente de Variação O desvio padrão por si só tem limitações. Um desvio padrão de duas unidades pode ser considerado pequeno para um conjunto de valores cuja média é 100. Entretanto, se a média for 5, ele se torna muito grande. Além disso, o desvio padrão por ser expresso na mesma unidade dos dados, não permite aplicá-lo na comparação de dois ou mais conjunto de dados que têm unidades diferentes. Para eliminar essas limitações, é possível caracterizar a dispersão ou variabilidade dos dados em termos relativos, usando uma medida denominada Coeficiente de Variação (CV), também conhecido como como Desvio Padrão Relativo ou Coeficiente de Variação de Pearson. É expresso, em geral como uma porcentagem, sendo definido como a razão do desvio padrão pela média: \\[ CV = \\frac{s}{\\overline{x}} \\] Multiplicando o valor da equação por 100 tem-se o CV percentual. O R não possui uma função específica para calcular o CV. Foi criada uma função específica para isso,já multiplicada por 100. coef_var &lt;- function (valores) { (sd(valores, na.rm=T) / mean(valores, na.rm=T))*100} Portanto, o CV da variável mater15$pesoRN é igual a: coef_var (mater15$pesoRN) ## [1] 16.16144 Se usarmos outra variável do banco de dados, por exemplo, mater15$idadeMae, o CV será igual a: coef_var (mater15$idadeMae) ## [1] 25.83343 O peso do recem-nascido tem um CV = 16.2 e a idade materna um CV = 25.8, mostrando que esta tem uma maior variabilidade. Quanto menor o desvio padrão, menor o CV e, consequentemente, menor a variabilidade. Um CV \\(\\ge\\) 50%, sugere que a variável tem uma distribuição assimétrica. 6.2.3 Escolha da medida resumidora A seleção da medida de tendência central mais adequada depende de vários fatores, incluindo a natureza dos dados e do propósito da sumarização. O tipo da variável tem substancial influência na escolha da medida de tendência central a ser usada. A moda é mais apropriada para dados nominais e seu uso com variáveis ordinais resulta em uma perda no poder em termos de informação que se poderia obter dos dados. A mediana é mais adequada para variáveis ordinais, embora possa ser usada para variáveis contínuas, especialmente quando a distribuição dos dados é assimétrica. A mediana não deveria ser usada com dados nominais porque os postos assumidos não podem ser obtidos com dados de nível nominal. Finalmente, a média somente deve ser usada com dados contínuos simétricos, se houver assimetria a mediana deve ser preferida. As medidas de dispersão devem estar associadas a uma medida de tendência central. Elas caracterizam a variabilidade dos dados na amostra. Com dados ordinais usar a amplitude ou o intervalo interquartil. O desvio padrão não é apropriado em dados ordinais devido à natureza não numérica destes. Com os dados numéricos deve-se usar o desvio padrão, que utiliza toda a informação nos dados, ou o intervalo interquartil (IIQ). Quando os dados forem simétricos, usar a média acompanhada do desvio padrão, caso contrário, usar a mediana e o IIQ. Não misturar e combinar medidas (22). 6.3 Tabelas Existem muitas maneira de criar tabelas no R. Para mostrar como construir as tabelas, será feita a leitura do conjunto de dados (dadosMater.xlsx) mencionado acima (veja seção 5.3: library(readxl) mater &lt;- read_excel(&quot;Arquivos/dadosMater.xlsx&quot;) 6.3.1 Tabelas de Frequência Tabela de frequência para dados categóricos Uma maneira concisa que permite observar a variável e extrair informação sobre o seu comportamento, é a utilização de uma tabela de frequência. A tabela de frequência deve ser simples, clara e objetiva, ou seja, não deve ter um volume muito grande de informações. Deve ser autoexplicativa, não deve haver necessidade de ler o texto para entendê-la. A tabela de frequência agrupa os dados por categorias ou classes, contabilizando o número ocorrências em cada categoria. O número de observações em uma determinada classe recebe o nome de frequência absoluta (f). Além da frequência absoluta, costuma aparecer a frequência relativa (fr) que representa a proporção da classe em relação ao número total de observações (n), calculada por \\(fr = \\frac{f}{n}\\), a frequência percentual (fp), obtida pela multiplicação da frequência relativa por 100 e a frequência acumulada, que é a soma de todas as classes até a classe atual, podendo ser frequência acumulada absoluta (F), frequência acumulada relativa (Fr) ou frequência acumulada percentual (Fp). Em uma tabela, os dados são apresentados em colunas verticais indicadoras e linhas horizontais. Nas linhas aparecem as categorias e nas colunas as frequências, constituindo o corpo da tabela. O cabeçalho indica a natureza do conteúdo de cada coluna. No cruzamento das colunas e das linhas, tem-se as caselas ou casas. Existem algumas recomendações na construção de uma tabela de frequência (67): deve ter um título na parte superior que responda as perguntas: “o que? quando? onde?” relativas ao fato estudado; deve ter um rodapé, na parte inferior da tabela, onde se coloca notas necessárias e a fonte dos dados; as colunas externas da tabela devem ser abertas, o emprego de linhas verticais para a separação das colunas no corpo da tabela é opcional; Na parte superior e inferior, as tabelas devem, ser fechadas por linhas horizontais; Nenhuma casela deve ficar vazia, apresentando um número ou um símbolo. Se não se dispuser do dado, colocar reticências … e a presença de um X representa que o dado foi omitido para evitar a identificação. Se os dados forem nominais, a ordenação das categorias é arbitrária, costuma-se colocar em primeiro lugar a maior frequência (Tabela 6.1) , colocando-os em categorias ordenadas (68). Table 6.1: Distribuição de frequência de drogadição em parturientes do Hospital Geral de Caxias do Sul, RS, 2008. Drogadição f fr fp Fp Não drogaditas 904 0,955 95,5 95.5 Medicamentos 23 0,024 2,4 97.9 Álcool 17 0,018 1,8 99.7 Crack 2 0,002 0,2 99.9 Cocaína 1 0,001 0,1 100 Total 947 1,000 100,0 Construção da tabela de frequência Com frequência há necessidade se recodificar uma variável numérica para categórica. Por exemplo, que as gestantes são, classicamente, subdivididas em menores de 20 anos (adolescentes), 20 a 35 anos e maiores de 35 anos. No conjunto dadosMater, a variável idadeMae é uma variável numérica onde a mulher mais jovem tem 13 anos e mais velha tem 46. Não existe uma variável com a idade categorizada. Será feita uma transformação desta variável numérica em categórica com três níveis: &lt; 20 anos, 20 a 35 anos e &gt;35 anos. Será usada a função cut() do pacote do R base. Esta função tem vários argumentos: x \\(\\longrightarrow\\) vetor numérico breaks \\(\\longrightarrow\\) vetor numérico de dois ou mais pontos de corte exclusivos ou um único número (maior ou igual a 2) dando o número de intervalos nos quais x deve ser subdividido labels \\(\\longrightarrow\\) rótulos para os níveis das categorias resultante. Por padrão, os rótulos são construídos usando a notação de intervalo \\((a, b]\\) (aberto à esquerda e fechado à direita). include.lowest \\(\\longrightarrow\\) valor lógico, se o menor valor será incluido, ou o maior, se right = TRUE. Padrão = include.lowest=TRUE right \\(\\longrightarrow\\) valor lógico indicando se o intervalo deve ser fechado à direita e aberto a esquerda. Padrão = right = TRUE. ordered_result \\(\\longrightarrow\\) valor lógico indicando se o resultado deve ser um fator ordenado. mater$idadeCateg &lt;- cut(mater$idadeMae, breaks = c(13, 20, 36, 46), labels = c(&quot;&lt;20a&quot;, &quot;20-35a&quot;, &quot;&gt;35a&quot;), include.lowest = TRUE, right = FALSE, ordered_result =TRUE) Neste exemplo, foi usado right = FALSE, em consequência, o intervalo 13 a 20, incluirá o 13 (menor idade) e excluirá o 20, o intervalo 20 a 36, incluirá o 20 e excluirá o 36 e o último intervalo incluirá o 36 e excluirá o 46, que é o valor mais alto. Em função disso, foi incluído mais um argumento include.lowest=TRUE, para incluir o valor 46. Para se verificar como ficou a distribuição de frequência absoluta, constroi-se uma tabela, inicialmente com a função table(): f_abs &lt;- table (mater$idadeCateg) f_abs ## ## &lt;20a 20-35a &gt;35a ## 219 992 157 O cálculo das frequências relativas pode ser dada pela função prop.table(), usando a frequência absoluta e a função round() para arrerdondar os valores para 3 digitos: f_rel &lt;- round(prop.table(f_abs), 3) f_rel ## ## &lt;20a 20-35a &gt;35a ## 0.160 0.725 0.115 Multiplicando por 100 a f_rel, tem-se a frequência percentual: f_perc &lt;- round(f_rel*100, 2) f_perc ## ## &lt;20a 20-35a &gt;35a ## 16.0 72.5 11.5 f_abs &lt;- c (f_abs, sum(f_abs)) f_rel &lt;- c (f_rel, sum (f_rel)) f_perc &lt;- c (f_perc, sum (f_perc)) tab1 &lt;- cbind(f_abs, f_rel , f_perc) tab1 &lt;- as.data.frame(tab1) row.names(tab1)[4] &lt;- &quot;Total&quot; colnames(tab1) &lt;- c(&quot;Frequência&quot;, &quot;Freq.Relativa&quot;, &quot;Freq.Percentual&quot;) tab1 ## Frequência Freq.Relativa Freq.Percentual ## &lt;20a 219 0.160 16.0 ## 20-35a 992 0.725 72.5 ## &gt;35a 157 0.115 11.5 ## Total 1368 1.000 100.0 A função kable() do knitr(69) pode ser usada, retornando uma tabela muito simples e profissional (Tabela 6.2). Como a função somente trabalha com matrizes e dataframes, a tabela tab1 deve ser um data.frame. Para melhorar o aspecto da tabela, pode-se acrescentar funções do pacote kableExtra (70) com a sintax pipe ( %&gt;% ), como exemplo, kable_styling(). knitr::kable(tab1, booktabs = TRUE, caption = &quot;Distribuição das puérperas por faixa etária, Hospital Geral de Caxias do Sul, RS, 2008.&quot;, format.args = list(decimal.mark = &quot;,&quot;)) %&gt;% kableExtra::kable_classic(full_width = T, html_font = &quot;Cambria&quot;) %&gt;% kableExtra::row_spec(0, bold = TRUE) Table 6.2: Distribuição das puérperas por faixa etária, Hospital Geral de Caxias do Sul, RS, 2008. Frequência Freq.Relativa Freq.Percentual &lt;20a 219 0,160 16,0 20-35a 992 0,725 72,5 &gt;35a 157 0,115 11,5 Total 1368 1,000 100,0 Tabela de frequência para dados numéricos Como fazer a distribuição de frequência de uma variável contínua sem um critério pré-determinado para as classes? Como exemplo, será usado, agora, o IMC pré-gestacional das parturientes do banco de dados dadosMater.xlsx). Esta variável não existe, tem-se apenas o peso e a altura e, portanto, com estes dados, ela pode ser criada: mater$imc &lt;- round(mater$peso/mater$altura^2, 1) Após, segue-se os seguintes passos: Estabelecimento do número de classes (k): Antes, as classes foram estabelecidas de acordo com algum critério. Em geral, quando não há um padrão pré-determinado, o número de classes é estabelecido de acordo com o tamanho da amostra. Este número pode ser escolhido lembrando-se das oscilações que ocorrem nos dados e do interesse do pesquisador em mostrar seus dados. Não existe uma regra totalmente eficiente para determinar o número de classes. É importante ter bom senso, de maneira que seja possível ver como os valores se distribuem. Para a maioria dos dados, é recomendado e 8 a 20 classes, isto é, 8 \\(\\le\\) k \\(\\le\\) 20. Com poucas classes, perde-se precisão e, com muitas classes, a tabela torna-se muito extensa. Baseado na regra de Sturges , é sugerido usar a recomendação da Figura 6.2 (71). Figure 6.2: Número de classes baseado em Sturges Para a variável imc, como existem 1368 observações, deve-se usar ao redor de 10 classes. Executando a função nclass.Sturges (), abaixo, o número de classes é igual a: k &lt;- nclass.Sturges (mater$imc) k ## [1] 12 Amplitude e limites das classes: A classe possui um limite inferior e um limite superior. O importante é que os limites dos intervalos sejam mutuamente exclusivos, isto cada valor deve ser representado em um único intervalo. Além disso, os intervalos devem ser exaustivos, isto é, devem conter todos os valores possíveis entre o valor mínimo e o máximo. O recomendado é que as classes sejam homogêneas, ou seja, tenham a mesma amplitude. A amplitude dos valores pode ser obtida com a função range(): amplitude &lt;- range(mater$imc) amplitude ## [1] 11.8 48.7 Usando esta amplitude dos dados, é possível ter a largura (amplitude) das classes (h), usando a diferença entre o mínimo e máximo e divdindo pelo número de clsasses (k): h &lt;- round(diff(amplitude)/k, 0) h ## [1] 3 A fórmula é apenas a diferença absoluta dos limites inferior e superior dividida pelo número de classes, arredondado com o a função round () com 1 dígito decimal. A partir desses dados, é possível construir as classes. A primeira classe será o valor mínimo de 11,8, que pode ser arredondado para 11,8 até 14,8 (11,8 + 3) exclusive; a segunda classe será 14,8 até 17,8 (14,8 + 3) e assim por diante. Construção da tabela: Pode-se construir a tabela, usando a função table() e dentro desta a função cut() e dentro dela a função seq(limite inferior, limite superior, l = número de classes). nutriCateg &lt;- table(cut(mater$imc, rigth = TRUE, include.lowest = TRUE, seq(11.8, 48.7, l = k + 1))) nutriCateg ## ## [11.8,14.9] (14.9,18] (18,21] (21,24.1] (24.1,27.2] (27.2,30.3] ## 2 46 258 480 237 176 ## (30.3,33.3] (33.3,36.4] (36.4,39.5] (39.5,42.6] (42.6,45.6] (45.6,48.7] ## 87 39 22 12 5 4 Preste atenção! Estes comandos que vão gerar a tabela têm o argumento right = TRUE (padrão). Neste caso, ao contrário do comentado anteriormente, onde foi usado right = FALSE, os símbolos aparecem como (] (na tabela) e significa que o limite inferior da classe foi excluído (aberto à esquerda) e o superior foi incluído (fechado à direita). Aqui, também foi introduzido o argumento include.lowest = TRUE para incluir o valor mínimo dos dados (11,8), e a representação gráfica fica []. Olhando a saída do objeto nutriCateg, ela parece pouco esclarecedora e, no caso do IMC, talvez fosse melhor usar outro critério. Como por exemplo o que define o estado nutricional no 1° trimestre de gestação e classifica as gestantes em baixo peso (IMC \\(&lt;\\) 18,5 kg/\\(m^2\\)), peso adequado (18,5 \\(\\le\\) IMC \\(\\le\\) 24,9 kg/\\(m^2\\)), sobrepeso (25,0 \\(\\le\\) IMC \\(\\le\\) 29,9 kg/\\(m^2\\)) e obesidade (IMC \\(\\ge\\) 30 kg/\\(m^2\\)). Assim, é recomendado um ganho de peso total adequado de 12,5 kg a 18 kg para as gestantes classificadas como baixo peso; de 11,5 kg a 16,0 kg para as classificadas como peso adequado; de 7,0 a 11,5 kg nas classificadas com sobrepeso; e de 5,0 a 9,0 kg nas obesas (72). Desta forma, tem-se uma tabela que melhor define este grupo de mulheres quanto ao estado nutricional. mater$estNutri &lt;- cut(mater$imc, breaks = c(11.8, 18.5, 25, 30, 48.7), labels = c(&quot;Baixo Peso&quot;, &quot;Peso adequado&quot;, &quot;Sobrepeso&quot;, &quot;Obesidade&quot;), include.lowest = TRUE, right = FALSE, ordered_result =TRUE) f.abs &lt;- table (mater$estNutri) f.rel &lt;- round(prop.table(f.abs), 3) f.perc &lt;- round(f.rel*100, 2) f.abs &lt;- c (f.abs, sum(f.abs)) f.rel &lt;- c (f.rel, sum (f.rel)) f.perc &lt;- c (f.perc, sum (f.perc)) tab2 &lt;- cbind(f.abs, f.rel , f.perc) tab2 &lt;- as.data.frame(tab2) row.names(tab2)[5] &lt;- &quot;Total&quot; colnames(tab2) &lt;- c(&quot;Frequência&quot;, &quot;Freq.Relativa&quot;, &quot;Freq.Percentual&quot;) tab2 ## Frequência Freq.Relativa Freq.Percentual ## Baixo Peso 67 0.049 4.9 ## Peso adequado 791 0.578 57.8 ## Sobrepeso 335 0.245 24.5 ## Obesidade 175 0.128 12.8 ## Total 1368 1.000 100.0 Colocando em um formato mais científico, tem-se uma tabela (Tabela 6.3) bem mais elegante sobre o estado nutricional pré-gestacional: knitr::kable(tab2, caption = &quot;Estado nutricional pré-gestacional das parturientes, HGCS, 2008.&quot;, format.args = list(decimal.mark = &quot;,&quot;)) %&gt;% kableExtra::kable_classic(full_width = T, html_font = &quot;Cambria&quot;) %&gt;% kableExtra::row_spec(0, bold = TRUE) Table 6.3: Estado nutricional pré-gestacional das parturientes, HGCS, 2008. Frequência Freq.Relativa Freq.Percentual Baixo Peso 67 0,049 4,9 Peso adequado 791 0,578 57,8 Sobrepeso 335 0,245 24,5 Obesidade 175 0,128 12,8 Total 1368 1,000 100,0 6.3.2 Tabelas de contingência As tabelas de contingência, também chamadas tabelas cruzadas, são bastante usadas em estatísticas epidemiológicas para resumir a relação entre duas ou mais variáveis categóricas. Uma tabela de contingência é um tipo especial de tabela de distribuição de frequência, onde duas variáveis são mostradas simultaneamente. Por exemplo, um pesquisador pode estar interessado em saber se o hábito de fumar na gestação aumenta o risco de o recém-nascido precisar de cuidados intensivos. Existem duas variáveis fumo (fumo na gestação) e utiNeo (necessidade de cuidados intensivos neonatais) no banco de dados dadosMater.xlsx. Cada uma dessas variáveis tem duas alternativas, sim e não, por isso a tabela de cruzamento é denominada tabela de contingência 2 x 2. No arquivo, estão registradas como variáveis numéricas , 1 e 2, e devem ser transformadas para fatores (1 = sim e 2 = não)9, usando a função factor(). mater$fumo &lt;- factor (mater$fumo, ordered = TRUE, levels = c (1,2), labels = c (&quot;sim&quot;, &quot;não&quot;)) mater$utiNeo &lt;- factor (mater$utiNeo, ordered = TRUE, levels = c (1,2), labels = c (&quot;sim&quot;, &quot;não&quot;)) Basta agora, usar a função with() junto com a função table(variável da linha, variável das colunas). Por convenção, costuma-se colocar a variável explicativa ou explanatória nas linhas (fumo) e o desfecho nas colunas (utiNeo): tabFumo &lt;- with(data = mater, table(fumo, utiNeo)) tabFumo ## utiNeo ## fumo sim não ## sim 71 230 ## não 204 863 Para ter a soma das margens, usar a função addmargins (tabela, margin = c (1,2), FUN = sum) do pacote stats, incluído na instalação básica do R. A função adiciona a soma das linhas (1) e das colunas (2) às margens da tabela (tabFumo). Para melhorar visualmente, pode-se colocar sum em um objeto denominado de Total. Total &lt;- sum addmargins (tabFumo, margin = c(1,2), FUN = sum) ## Margins computed over dimensions ## in the following order: ## 1: fumo ## 2: utiNeo ## utiNeo ## fumo sim não sum ## sim 71 230 301 ## não 204 863 1067 ## sum 275 1093 1368 6.4 Gráficos Para descrever os dados e visualizar o que está acontecendo, recomenda-se utilizar um gráfico adequado. O que é adequado depende principalmente do tipo de dados, bem como das características particulares do que se quer explorar. Além disso, um gráfico em um relatório sempre é um fator de “impacto”. Ou seja, pode ter um efeito positivo no leitor ou fazê-lo abandonar a leitura. Finalmente, um gráfico de frequência pode ser utilizado para ilustrar, explicar uma situação complexa onde palavras ou uma tabela podem ser confusos, extensos ou de outro modo insuficiente. Por outro lado, deve-se evitar usar gráficos onde poucas palavras expressam claramente o que se quer mostrar. Aconselha-se que, ao analisar os dados, é importante inspecioná-los como se fossem uma imagem, uma fotografia, ver como eles se parecem, qual o seu aspecto, e só então pensar em interpretar os aspectos vitais da estatística (73). O R básico fornece uma grande variedade de funções para visualizar dados, elas de uma maneira relativamente simples permitem a construção de gráficos que facilitam a interpretação tanto de variáveis categórica como contínuas. Para gráficos mais sofisticados existe um pacote denominado ggplo2 (74). Este pacote é uma ferramenta extremamente versátil. É um pouco mais complexo e exige mais tempo para dominá-lo, mas, uma vez que se aprenda o básico sobre ele, oferece uma estrutura extremamente flexível para exibir os dados . Inicialmente, serão usadas as funções do R básico e,posteriormente, será feita uma introdução ao ggplot2. 6.4.1 Gráfico de setores Também conhecido como gráfico de pizza. Cada segmento (fatia) do gráfico de pizza deve ser proporcional à frequência da categoria que representa. A desvantagem do gráfico de pizza é que ele só pode representar uma variável, portanto, há necessidade de um gráfico separado para cada variável que se deseja representar. Além disso, um gráfico de pizza pode perder clareza se ele é usado para representar mais do que quatro ou cinco categorias. Na maioria das vezes, em um artigo ou relatório não há necessidade de se usar este tipo de gráfico. As tabelas são muito melhores. Segundo Edward Tufte, professor emérito de estatística, design gráfico e economia política na Universidade de Yale, o único gráfico pior do que um gráfico de pizza são vários deles (75)! Ele é usado mais no mundo dos negócios. Como regra, não use gráfico de pizza! Em uma consulta, entre estudantes de Medicina, foi perguntado a sua opinião em relação a este tipo de gráfico. A pergunta feita foi: “O que você sente ao ver um gráfico de pizza em um artigo científico?” As alternativas para a resposta eram quatro (ódio, irritação, indiferença, amor). O resultado do inquérito está na Tabela 6.4. Table 6.4: Sentimento dos alunos de Medicina em relação ao gráfico de pizza, UCS, 2012. Sentimento f fr fp Fp Odeiam 6 0,15 15 15 Não gostam 12 0,30 30 45 Indiferentes 14 0,35 35 80 Amam 8 0,20 20 100 Total 40 1,00 100 No R base, pacote graphics, existe a função pie()para obter um gráfico de setores simples. Esta função usa os seguintes argumentos basicos, consulte a ajuda do R para outras informações: x \\(\\longrightarrow\\) vetor numérico não negativo labels \\(\\longrightarrow\\) caracteres que fornecem nomes para as fatias. Para rótulos vazios ou NA (após coerção para caractere), nenhum rótulo ou linha indicadora é desenhada radius \\(\\longrightarrow\\) A pizza é desenhada centralizada em um quadrado cujos lados variam de -1 a +1. Se os caracteres que rotulam as fatias forem longos, pode ser necessário usar um raio menor. O padrão é 0,8. density \\(\\longrightarrow\\) Densidade das linhas de sombreamento, em linhas por polegada. O padrão é NULL significa que nenhuma linha de sombreamento é desenhada. Valores não positivos de densidade também inibem o desenho de linhas sombreadas col \\(\\longrightarrow\\) Vetor de cores a ser usado no preenchimento ou sombreamento das fatias. Se estiver faltando, um conjunto de 6 cores pastel é usado Os valores da coluna de frequência absoluta (f) da Tabela 6.4 serão usados como o argumento x. Ele informa a área (proporção de cada fatia. Os rótulos das fatias são escritos com a função concatenar c(). As cores também podeser estabelecidas com a função concatenar, mas para introduzir o pacote RColorBrewer, será usada 4 cores da sua paleta RdBu, mistura de vermelho e azul (Figura 6.3). library(RColorBrewer) pie(x = c(6, 12, 14, 8), labels = c(&quot;Odeiam&quot;, &quot;Não gostam&quot;, &quot;Indiferentes&quot;, &quot;Amam&quot;), col = brewer.pal(n = 4, name = &quot;RdBu&quot;)) Figure 6.3: Gráfico de Pizza: Opinião dos estudantes de Medicina. A função pie3D() permite construir um gráfico de setores em três dimensões. Para isso, há necessidade de instalar o pacote plotrix (76). Os argumentos são praticamente os mesmos do gráfico simples. Acrescenta-se radius = 0.9 que muda o raio da pizza e explode = 0.1 que determina o afastamento das fatias (0, as mantém juntas). Além disso, como o gráfico exibe rótulos com textos muito grandes, usa-se o argumento labelcex = 1 e coloca-se um título com o argumento main (Figura 6.4). library (plotrix) pie3D(x = c(6, 12, 14, 8), labels = c(&quot;Odeiam&quot;, &quot;Não gostam&quot;, &quot;Indiferentes&quot;, &quot;Amam&quot;), radius = 0.9, explode = 0.1, col = brewer.pal(n = 4, name = &quot;RdBu&quot;), labelcex = 1) Figure 6.4: Gráfico de Pizza: Opinião dos estudantes de Medicina. 6.4.2 Gráfico de barras Os gráficos de barra exibem a distribuição (frequências) de uma variável categórica através de barras verticais ou horizontais, ou sobrepostas (77). Assim como o gráfico de setores, o gráfico de barras é utilizado para representar a frequência absoluta ou percentual de diferentes categorias. As barras são proporcionais as frequências. A forma mais simples de solicitar um gráfico de barra no R é digitar a função barplot() do pacote básico. Esta função é específica para desenhar gráficos de barras horizontais e verticais e usa os seguintes argumentos: height \\(\\longrightarrow\\) um vetor ou matriz de valores que descreve as barras que constituem o gráfico; width \\(\\longrightarrow\\) especifica largura das barras, com padrão de 1, opcional; space \\(\\longrightarrow\\) a quantidade de espaço (como uma fração da largura média da barra) restante antes de cada barra. Pode ser fornecido como um único número ou um número por barra; beside \\(\\longrightarrow\\) argumento lógico para especificar se colunas devem ser mostradas lado a lado; col \\(\\longrightarrow\\) cores das barras componentes das barras, por padrão é usado grey (cinza); border \\(\\longrightarrow\\) cor das bordas das barras; … \\(\\longrightarrow\\) outros argumentos. Consulte a ajuda do R. Para a construção do gráfico de barras simples da Figura 6.5), foi utilizada a variável idadeCateg, anteriormente criada, a partir do conjunto de dados dadosMater.xlsx. barplot(table(mater$idadeCateg)) Figure 6.5: Gráfico de barra simples. Observando a Figura 6.5, verifica-se que não existem rótulos nos eixos x e y e o eixo y tem um tamanho inferior a barra mais alta. Estes e outros problemas podem ser resolvidos modificando-se ou acrescentando outros argumentos na função barplot(). Existem vários argumentos e para conhece-los melhorpesquise no Help do RStudio. Em um gráfico de barra simples são suficientes as seguintes modificações que irão resultar na Figura 6.6: Para corrigir a amplitude do eixo y, existe o argumento ylim = c(lim inf, lim sup). Na Tabela 4 ,observa-se que a frequência máxima é de 992, assim estende-se até 1000, bem próximo da frequência da categoria, acrescentando ylim = c (0,1000), separado por vírgulas de outros argumentos. Para os rótulos se utiliza os argumentos ylab = (“Frequência”) e xlab = (“Faixa Etária”). Também, pode ser incluído um título no gráfico com o argumento main = “Título”. Observe que os títulos estão entre aspas. Para modificar o tamanho das letras dos eixos x e y, que estão pouco visíveis, existe o argumento cex.lab = 1, que é o padrão. Para aumentar em 30%, por exemplo, usar cex.lab = 1.3. Os nomes tem padrão cex.names = 1, para modificar pode-se usar 1.3, 1.5, etc. Se nada for modificado, o R imprime o padrão. Para a cor das barras, use o argumento col = (“cor”). Escolha a cor entre as 657 opções, ou deixe o padrão cinza (grey). O argumento col.axis = “cor” controla a cor dos valores dos eixos. Para modificar a borda das barras que por padrão é preta, é possível mudar, usando o argumento border = “cor”. Sem borda basta colocar 0 (zero), no lugar da cor. Para colocar as barras na posição horizontal, pode ser utilizado o argumento horiz = TRUE. Lembrar de inverter as barras. Ou seja, a variável x passa a ser y e vice-versa. O argumento las = 1 faz o o texto do eixo y ficar horizontal A função box(bty = \"L\"), colocada após, e opcional, faz os eixos se encontraren em 0. barplot(table(mater$idadeCateg), ylim = c (0,1000), col= &quot;tomato&quot;, border = &quot;black&quot;, ylab= &quot;Frequência absoluta&quot;, xlab = &quot;Faixa etária&quot;, cex.lab = 1.2, las = 1) box(bty = &quot;L&quot;) Figure 6.6: Gráfico de barra simples modificado. Para que as barras fiquem horizontais como na Figura 6.7, usa-se o argumento horiz=TRUE: barplot(table(mater$idadeCateg), xlim = c (0,1000), col= &quot;steelblue&quot;, border = &quot;black&quot;, ylab= &quot;Faixa Etária&quot;, xlab = &quot;Frequência absoluta&quot;, cex.lab = 1.2, horiz=TRUE) box(bty = &quot;L&quot;) Figure 6.7: Gráfico com barras horizontais. Além disso, é possível fazer outras alterações para tornar o gráfico mais informativo . Por exemplo, pode-se colocar as frequência de cada barra no topo das mesmas (Figura 6.8): 1º Passo: Criar um gráfico de barras , colocando-o em um objeto x, que conterá a coordenada X do centro de cada uma das barras. Para verificar isso, basta executar o objeto x; 2º Passo: colocar a tabela table(mater$idadeCateg) com um objeto y da classe matriz; 3º Passo: usar a funçãoo text() para colocar os valores. x &lt;- barplot(table(mater$idadeCateg), ylim = c (0,1000), col= &quot;springgreen&quot;, border = &quot;black&quot;, ylab = &quot;Frequência absoluta&quot;, xlab = &quot;Faixa etária&quot;, cex.lab = 1.2, las = 1) box(bty = &quot;L&quot;) y &lt;- as.matrix(table(mater$idadeCateg)) text (x, y, labels = as.character(y), adj = c(0.5, 2), col = &quot;black&quot;) Figure 6.8: Gráfico de barra simples com frequências no topo. Gráfico de barras empilhadas Para este tipo de apresentação são utilizados, praticamente, os mesmos argumentos vistos para gerar um gráfico de barra simples. Como existem duas variáveis, há necessidade de avisar ao R como elas devem aparecer. Para isso, entra o argumento beside = FALSE, que informa que as barras não estarão uma ao lado da outra e sim empilhadas (Figura 6.9). O padrão é as barras ficarem uma ao lado da outra. Acrescenta-se uma legenda com a função legend() na parte superior esquerda (topleft). O argumento bty = \"n\" informa que será removido o quadro ao redor da legenda e fill = c(\"dimgrey\", \"salmon\") são as cores das barras. As duas variáveis a serem visualizadas são o hábito tabagista entre as puérperas de acordo com a idade. No conjunto de dados dadosMater.xlsx, o hábito tabagista está registrado na variável fumo, vista quando se estudou tabelas de contingência. Aqui se construirá uma tabela 3 x 2, tabFumo2: tabFumo2 &lt;- table(mater$fumo, mater$idadeCateg) barplot(tabFumo2, beside = FALSE, ylim = c(0, 1000), xlab=&quot;Faixa Etária&quot;, ylab = &quot;Frequência&quot;, col = c (&quot;dimgrey&quot;, &quot;cadetblue1&quot;), cex.lab = 1, cex.axis = 1, cex.names = 1, las = 1) box(bty = &quot;L&quot;) legend (&quot;topleft&quot;, legend = c(&quot;Fumantes&quot;, &quot;Não Fumantes&quot;), fill = c(&quot;dimgrey&quot;, &quot;cadetblue1&quot;), bty=&quot;n&quot;, cex = 1) Figure 6.9: Gráfico de barras empilhadas. Gráfico de barras lado a lado É igual a anterior, apenas com o argumento beside = TRUE (Figura 6.10). barplot(tabFumo2, beside = TRUE, ylim = c(0, 1000), xlab=&quot;Faixa Etária&quot;, ylab = &quot;Frequência&quot;, col = c (&quot;dimgrey&quot;, &quot;cadetblue1&quot;), cex.lab = 1, cex.axis = 1, cex.names = 1, las = 1) box(bty = &quot;L&quot;) legend (&quot;topleft&quot;, legend = c(&quot;Fumantes&quot;, &quot;Não Fumantes&quot;), fill = c(&quot;dimgrey&quot;, &quot;cadetblue1&quot;), bty=&quot;n&quot;, cex = 1) Figure 6.10: Gráfico de barras lado a lado Gráfico de barras para uma variável discreta A variável mater$para, número de filhos anteriores ao atual, é uma variável numérica discreta e, para representá-la, o mais adequado é usar um gráfico de barras simples Figura 6.11). tab_filhos&lt;- table (mater$para) barplot (tab_filhos, col = &quot;tomato&quot;, xlab=&quot;Número de filhos anteriores ao atual&quot;, ylab = &quot;Frequência&quot;, ylim = c(0, 500), cex.lab = 1, cex.axis = 1, cex.names = 1, las = 1) box(bty = &quot;L&quot;) Figure 6.11: Gráfico de barras para uma variável discreta 6.4.3 Gráfico de barra de erro O gráfico de barra de erro é um tipo de gráfico barra acrescido de uma medida de dispersão: desvio padrão, intervalos de confiança ou erro padrão. As barras de erro dão uma ideia geral de quão precisa é uma medição ou, inversamente, quão longe o valor observado está do valor verdadeiro. Continuando a usar o arquivo dadosMater.xlsx, será selecionada uma amostra de recém-nascidos a termo, definido pela OMS como o nascido de 37 semanas completas a 42 semanas incompletas (259 a 293 dias). A partir destes dados, será construido um gráfico de barra de erro dos recém-nascidos do sexo masculino e feminino. Inicialmente, deve ser instalado e carregado o pacote Hmisc (78), necessário para fornecer a função errbar() que irá construir o gráfico de de barra de erro. library (Hmisc) A seguir, carregar o arquivo dadosMater.xlsx e transformar em fator a variável sexo, usando os rótulos masc e fem. mater &lt;- read_excel(&quot;Arquivos/dadosMater.xlsx&quot;) mater$sexo &lt;- factor(mater$sexo, labels = c(&#39;masc&#39;, &#39;fem&#39;)) Em sequência, selecionar as variáveis necessárias ao objetivo (ig, pesoRN e sexo), usando a função select(); separar com a função filter() os recém-nascidos a termo (ig &gt;= 37 &amp; ig &lt; 42) e calcular, através da função summarise(), as medidas resumidoras, separando os grupos com a função group_by(), de acordo com o sexo. Todas essas funções são pertencentes ao pacotedplyr`. mater &lt;- mater %&gt;% select(ig, pesoRN, sexo) %&gt;% filter(ig &gt;= 37 &amp; ig &lt; 42) %&gt;% group_by(sexo) %&gt;% summarise(n = n(), media = mean(pesoRN, na.rm = T), dp = sd(pesoRN, na.rm = T), ep = dp/sqrt(n), l_inf = media - 1.96*dp, l_sup = media + 1.96*dp) No próximo passo, constroi-se um objeto, denominado barras, que irá conter as médias dos pesos dos recém-nascidos masculinos e femininos, que representam a altura das barras. Usando este objeto, constroi-se um gráfico de barras que será recebido por outro objeto, bp. Finalmente, coloca-se os limites inferiores e superiores para cada sexo, usando os valores calculados pela função summarise() que junto com o objeto bp constituem-se de argumentos da função errbar() (Figura 6.12). Veja maiores detalhes na ajuda do R (?errbar). barras &lt;- c(mater$media[1], mater$media[2]) bp &lt;- barplot(barras, ylim=c(0,4200), ylab = &quot;Peso do Recém-nascido (g)&quot;, cex.lab = 1, cex.axis = 0.8, cex.names = 1, space = c(0,0.5), names.arg=c(&quot;Meninos&quot;, &quot;Meninas&quot;), col = c(&quot;lightblue&quot;, &quot; pink2&quot;), las = 1) box(bty = &quot;L&quot;) lim_inf &lt;- c(mater$l_inf[1], mater$l_inf[2]) round(lim_inf, 2) ## [1] 2376.18 2249.69 lim_sup &lt;- c(mater$l_sup[1], mater$l_sup[2]) round(lim_sup, 2) ## [1] 4172.08 4044.09 errbar(bp, barras, lim_inf, lim_sup, add = T, xlab = NULL) Figure 6.12: Gráfico de barras de erro 6.4.4 Histograma O histograma é uma ferramenta gráfica que fornece informações sobre o formato da distribuição e dispersão dos dados, permitindo verificar se existe ou não simetria. É usado para dados contínuos. No histograma as frequências observadas são representadas por intervalos de classes de ocorrência que estão no eixo x e a altura das barras, representando a frequência de cada intervalo, no eixo y. A área de cada barra é proporcional à porcentagem de observações de cada intervalo. O R base possui uma função, denominada de hist() que constroi o histograma e possui vários argumentos: x \\(\\longrightarrow\\) um vetor numérico usado na construção do histograma breaks \\(\\longrightarrow\\) especifica o número de barras freq \\(\\longrightarrow\\) lógico; se TRUE (padrão), o histograma é uma representação de frequências; se FALSE, densidades de probabilidade, densidade de componentes, são plotados col \\(\\longrightarrow\\) cor a ser usada para preencher as barras. O padrão de NULL produz barras não preenchidas border \\(\\longrightarrow\\) cor da borda ao redor das barras. O padrão é usar a cor de primeiro plano padrão main, xlab, ylab \\(\\longrightarrow\\) rótulo do título, do eixo x e do eixo y. Para remover o rótulousar NULL. xlim, ylim \\(\\longrightarrow\\) limites do eixo x e do eixo y. Histograma Simples Os dados para a construção do histograma serão provenientes da variável altura do arquivo dadosMater.xlsx. mater &lt;- read_excel(&quot;Arquivos/dadosMater.xlsx&quot;) Para construir o histograma básico da Figura 6.13), executa-se o comando: hist(mater$altura) Figure 6.13: Histograma básico Observando o histograma gerado, observam-se alguns problemas que devem ser melhorados para tornar a sua aparência mais agradável. O rótulo dos eixo x está com o nome da variável e do eixo y está em inglês; O título do histograma está em inglês e repete o eixo x. Pode ser removido. O eixo y tem um limite superior menor do que a barra mais alta; O gráfico está na cor cinza, que conforme o interesse pode ser modificada; O número de barras pode ser modificado com o argumento breaks. Existe uma função no R que permite calcular o número de intervalos, usando a regra de Sturges (nclass.Sturges()). Entretanto, na maioria das vezes, é o objetivo do estudo quem determina o número de barras e, também, porque nem sempre o R obedece ao argumento. É importante saber o limite inferior e superior da variável, para construir o eixo x: min(mater$altura, na.rm = TRUE) ## [1] 1.4 max(mater$altura, na.rm = TRUE) ## [1] 1.85 nclass.Sturges(mater$altura) ## [1] 12 Acrescentado argumentos, modifica-se o aspecto do histograma (Figura 6.14): hist(mater$altura, breaks = 12, ylim = c (0, 450), xlim = c (1.4, 1.9), main= NULL, ylab = &quot;Frequência&quot;, xlab = &quot;Altura da gestante (metros)&quot;, col = &quot;tomato&quot;, las = 1) box(bty = &quot;L&quot;) Figure 6.14: Histograma modificado Observe que o formato do histograma é igual ao anterior, mudando a cor das barras, o limite do eixo y e os rótulos dos eixos. O R não modificou o número de barras. Ou seja, não obedeceu à modificação do argumento breaks = 12. Ele escolheu o que ele achou mais adequado! Histograma com curva normal sobreposta Eventualmente, para melhor comparar a distribuição dos dados, usamos uma curva normal sobreposta que servirá de indicador (Figura 6.15). A distribuição normal será discutida mais adiante. 1º Passo: Construir um histograma de densidade, que é a proporção de todas as observações que se enquadram dentro do intervalo. Na função hist(), modificar o argumento para freq = FALSE. 2º Passo: Adicionar uma curva normal ao histograma, usando a função curve(). Calcular antes a média e o desvio padrão da variável mater$altura. mu &lt;- mean(mater$altura, na.rm =TRUE) dp &lt;- sd(mater$altura, na.rm = TRUE) hist(mater$altura, ylim = c (0, 6), xlim = c (1.4, 1.9), main= NULL, ylab = &quot;Densidade&quot;, xlab = &quot;Altura da gestante (metros)&quot;, col =&quot;steelblue&quot;, freq = FALSE, border = &quot;white&quot;) box (bty = &quot;L&quot;) curve (dnorm (x, mean=mu, sd=dp), col=&quot;red&quot;, lty=1, lwd=2, add=TRUE) Figure 6.15: Histograma com curva normal sobreposta Componentes do Histograma Ao se criar um objeto h da classe histogram (Figura 6.16), pode-se verificar uma lista de componentes do mesmo. h &lt;- hist(mater$altura, breaks = 8, ylim = c (0, 450), xlim = c (1.4, 1.9), main= NULL, ylab = &quot;Frequência&quot;, xlab = &quot;Altura da gestante (metros)&quot;, col =&quot;seagreen2&quot;, freq = TRUE, border = &quot;white&quot;) box (bty = &quot;L&quot;) Figure 6.16: Histograma da altura da gestante h ## $breaks ## [1] 1.40 1.45 1.50 1.55 1.60 1.65 1.70 1.75 1.80 1.85 ## ## $counts ## [1] 18 87 304 406 334 151 50 16 2 ## ## $density ## [1] 0.26315789 1.27192982 4.44444444 5.93567251 4.88304094 2.20760234 0.73099415 ## [8] 0.23391813 0.02923977 ## ## $mids ## [1] 1.425 1.475 1.525 1.575 1.625 1.675 1.725 1.775 1.825 ## ## $xname ## [1] &quot;mater$altura&quot; ## ## $equidist ## [1] TRUE ## ## attr(,&quot;class&quot;) ## [1] &quot;histogram&quot; Estes componentes podem ser usados para outras análises. Construção de um histograma usando os componentes Pode-se colocar os valores correspondentes às barras usando os componentes do histograma (Figura 6.17). hist(mater$altura, breaks = 8, ylim = c (0, 450), xlim = c (1.4, 1.9), main= NULL, ylab = &quot;Frequência&quot;, xlab = &quot;Altura da gestante (metros)&quot;, col = &quot;salmon&quot;) box (bty = &quot;L&quot;) text (h$mids, h$counts, labels = h$counts, adj= c(0.5, -0.5)) Figure 6.17: Histograma com frequência no topo 6.4.5 Boxplot O boxplot descreve a distribuição de uma variável contínua exibindo o resumo de cinco números: mínimo, 1º quartil (percentil 25), mediana (percentil 50), 3ª quartil (percentil 75) e máximo (Figura 6.18). Pode também apresentar observações atípicas (outliers), valores fora do intervalo de ± 1,5 o intervalo interquartil, em geral, representados por (o). Valores que estão acima ou abaixo de 3 vezes o IIQ são considerados extremos, representados por (*). Figure 6.18: Boxplot Continuando a usar o arquivo dadosMater.xlsx, será selecionada uma amostra de recém-nascidos a termo da mesma maneira como foi feito para construção do gráfico de barra de erro. mater &lt;- read_excel(&quot;Arquivos/dadosMater.xlsx&quot;) mater$sexo &lt;- factor(mater$sexo, labels = c(&#39;masc&#39;, &#39;fem&#39;)) O R possui uma função no pacote básico denominada boxplot() que constroi o gráfico da Figura 6.19. boxplot (mater$pesoRN) Figure 6.19: Boxplot simples Este boxplot pode ser modificado (Figura 6.20), alterando alguns argumentos como colocação de um título no gráfico, e rótulos nos eixos e mudança na cor. Os argumento cex.lab, cex.axis e cex.names estabelecem o tamanho fontes. Por exemplo, para aumentar em 20%, usamos 1.2. boxplot (mater$pesoRN, col = &quot;lightblue2&quot;, main = &quot;RN a termo&quot;, ylab = &quot;Peso do Recém-nascido (g)&quot;, border = &quot;black&quot;, cex.lab = 1, cex.axis = 1, cex.names = 1, las = 1) Figure 6.20: Boxplot modificado Estatísticas do boxplot A função boxplot.stats() do pacote grDevices fornece as estatísticas do boxplot, facilitando a interpretação do mesmo, de modo semelhante ao visto para o histograma. boxplot.stats (mater$pesoRN) ## $stats ## [1] 1600.0 2697.5 3100.0 3430.0 4485.0 ## ## $n ## [1] 1368 ## ## $conf ## [1] 3068.709 3131.291 ## ## $out ## [1] 1035 1580 1440 750 1030 1098 1240 785 440 810 540 1075 1505 1040 830 ## [16] 1270 580 920 900 814 1195 915 1280 570 1050 765 1195 930 1160 1240 ## [31] 850 1200 1550 4735 4950 4535 4670 1425 4660 4795 890 1110 700 670 1360 ## [46] 1120 630 955 770 1160 1232 980 1240 1590 650 630 750 980 720 1110 ## [61] 920 1105 995 1170 1465 1400 1440 1245 1545 4620 $stats = é o resumo dos 5 números: mínimo, percentil 25, mediana, percentil 75 e máximo $n = nº de obs; $conf = limite inf/sup do entalhe se houver; $out = são os outliers Múltiplos boxplots Os boxplots são muito usados na comparação de grupos. A necessidade mais comum é ordenar as categorias de acordo com o aumento da mediana, mas isto é opcional. Permite identificar rapidamente qual grupo tem o maior valor e como as categorias são classificadas (Figura 6.21). boxplot (mater$pesoRN ~ mater$sexo, col = c(&quot;lightblue2&quot;, &quot;pink&quot;), ylab = &quot;Peso do Recém-nascido (g)&quot;, xlab = &quot;Sexo&quot;, ylim = c(1000, 5000), border = &quot;black&quot;, cex.lab = 1, cex.axis = 1, cex.names = 1, las = 1) Figure 6.21: Múltiplos boxplots Pode-se fazer um entalhe (notch) que podem ser interpretados como um intervalo de comparação em torno dos valores medianos (Figura 6.22). É calculado pela fórmula :\\(mediana \\pm 1.57\\times IIQ/\\sqrt{n}\\). No nosso exemplo, observe que o entalhe nos meninos está um pouco acima do das meninas.. boxplot (mater$pesoRN ~ mater$sexo, col = c(&quot;lightblue2&quot;, &quot;pink&quot;), ylab = &quot;Peso do Recém-nascido (g)&quot;, xlab = &quot;Sexo&quot;, ylim = c(1000, 5000), border = &quot;black&quot;, cex.lab = 1, cex.axis = 1, cex.names = 1, las = 1, notch = TRUE) Figure 6.22: Boxplots com entalhes Boxplots com stripcharts A função stripcharts() permite criar um gráfico de dispersão unidimensional sobre o boxplot (Figura 6.23). Você também pode personalizar o símbolo (pontos) para criar o gráfico, a largura da linha e sua cor com os argumentos pch, lwd e col, respectivamente. Alguns símbolos, como pch = 21 a 25 permitem que você modifique a cor de fundo do símbolo com o argumento bg. O argumento vertical = TRUE, coloca os pontos na vertical sobreposto ao boxplot, quando o argumento add = TRUE. O argumento cex = 0.3 é o tamanho dos pontos e method = \"jitter\", espalha os pontos. boxplot (mater$pesoRN ~ mater$sexo, col = c(&quot;lightblue2&quot;, &quot;pink&quot;), ylab = &quot;Peso do Recém-nascido (g)&quot;, xlab = &quot;Sexo&quot;, border = &quot;black&quot;, cex.lab = 1, cex.axis = 1, cex.names = 1, pch = 20, cex = 0.8, las = 1, outline = TRUE) stripchart(mater$pesoRN ~ mater$sexo, method = &quot;jitter&quot;, main=NULL, col = c(&quot;blue&quot;, &quot;red&quot;), vertical=TRUE, pch=16, cex = 0.3, add = TRUE) Figure 6.23: Boxplots com dispersão unidimensional Boxplots horizontais Para criar um boxplot horizontal (Figura 6.24), usamos o argumento horizontal = TRUE e invertemos os rotulos dos eixos x e y. boxplot (mater$pesoRN ~ mater$sexo, col = c(&quot;lightblue2&quot;, &quot;pink2&quot;), xlab = &quot;Peso do Recém-nascido (g)&quot;, ylab = &quot;Sexo&quot;, horizontal = TRUE, border = &quot;black&quot;, cex.lab = 1, cex.axis = 1, cex.names = 1, pch = 20, cex = 0.8) Figure 6.24: Boxplots horizontais 6.4.6 Gráfico de Dispersão Um gráfico de dispersão (Scatterplot) exibe a relação entre duas variáveis numéricas. Cada ponto representa uma observação. Suas posições nos eixos x (horizontal) e y (vertical) representam os valores das duas variáveis. O R Base é uma boa opção para construir um gráfico de dispersão, usando a função plot(). Ambas as variáveis numéricas do banco de dados devem ser especificadas nos argumentos x e y. Será construído um gráfico de dispersão (Figura 6.25) do comprimento e o peso dos recém-nascidos a termo. Com o conjunto de dados dadosMater.xlsx, usado até aqui, selecionamos as variáveis compRN, pesoRN, sexo e ig, incluindo apenas os neonatos a termo (37 semanas \\(\\le\\) idade gestacional \\(&lt;\\) 42 semanas) mater &lt;- read_excel(&quot;Arquivos/dadosMater.xlsx&quot;) mater$sexo &lt;- factor(mater$sexo, labels = c(&#39;masc&#39;, &#39;fem&#39;)) mater &lt;- mater %&gt;% select(ig, pesoRN, compRN, sexo) %&gt;% filter(ig &gt;= 37 &amp; ig &lt; 42) plot (x = mater$compRN, y = mater$pesoRN, ylab = &quot;Peso de Recém-nascido (g)&quot;, xlab = &quot;Comprimento do Recém-nascido (cm)&quot;, cex.axis = 0.8, las = 1) Figure 6.25: Gráfico de dispersão Este mesmo gráfico pode ser obtido, usando uma fórmula y~x e acrescentando o argumento bty = \"L\" (Figura 6.26). Este argumento permite personalizar a caixa ao redor do gráfico. o: caixa completa (parâmetro padrão), n: sem caixa 7: superior + direita L: inferior + esquerda C: superior + esquerda + inferior U: esquerda + inferior + direita plot (pesoRN ~ compRN, data = mater, ylab = &quot;Peso de Recém-nascido (g)&quot;, xlab = &quot;Comprimento do Recém-nascido (cm)&quot;, cex.axis = 0.8, las = 1, bty = &quot;L&quot;) Figure 6.26: Gráfico de dispersão Como em qualquer outro gráfico, este também pode ser melhorado em seu aspecto, tornando os pontos sólidos e coloridos. O argumento pch estabelece o tipo de pontos (Figura 6.27). Figure 6.27: Argumento pch Além disso, como os pontos estão aglomerados, devido a quantidade, é possível tentar espalhá-los, usando a função jitter() na variável compRN (Figura 6.28). O argumento 10 é variável e significa o grau de espalhamento: plot (jitter(mater$compRN,10), mater$pesoRN, col = &quot;steelblue&quot;, ylab = &quot;Peso de Recém-nascido (g)&quot;, xlab = &quot;Comprimento do Recém-nascido (cm)&quot;, las = 1, bty = &quot;L&quot;, pch = 19, cex = 1, cex.lab = 1.1, cex.axis = 0.8) Figure 6.28: Gráfico de dispersão com jitter Mapeamento dos pontos de acordo com uma variável categórica Inicialmente, será criado um vetor para representar as cores, de acordo com o sexo (meninos = azul; meninas = vermelho). Usa-se a função unclass() para discriminar os sexos (Figura 6.29). Acrescenta-se uma legenda para ilustrar a separação. cores &lt;- c(&quot;dodgerblue3&quot;, &quot;tomato&quot;) plot(x = jitter(mater$compRN, 10), y = mater$pesoRN, bg = cores[unclass(mater$sexo)], ylab = &quot;Peso de Recém-nascido (g)&quot;, xlab = &quot;Comprimento do Recém-nascido (cm)&quot;, las = 1, bty = &quot;L&quot;, cex = 1.5, pch=21, cex.lab = 1, cex.axis = 0.8) legend (legend = c(&quot;Meninos&quot;, &quot;Meninas&quot;), fill = cores, bty=&quot;n&quot;, cex = 1, &quot;topleft&quot;) Figure 6.29: Mapeamento dos pontos de acordo com uma variável categórica Adição da reta de ajuste Uma linha reta de ajuste dos dados (Figura 6.30) pode ser acrescentada usando a função abline (), associada a função lm (). Um modelo típico lm (linear model) tem o formato resposta (y) ~ preditor (x). Mais detalhes sobre o modelo de ajuste linear na regressão linear. # Construção do gráfico de dispersão plot (jitter(mater$compRN,10), mater$pesoRN, col = &quot;gray40&quot;, bg = &quot;darkturquoise&quot;, ylab = &quot;Peso de Recém-nascido (g)&quot;, xlab = &quot;Comprimento do Recém-nascido (cm)&quot;, las = 1, bty = &quot;L&quot;, pch = 21, cex = 1.3, cex.lab = 1, cex.axis = 0.8) # Criação do modelo de ajuste modelo &lt;- lm (mater$pesoRN ~ mater$compRN) # Adição da reta, usando o modelo abline (modelo, col=&quot;red&quot;, lwd=2, lty = 2) Figure 6.30: Gráfico de dispersão com reta de ajuste Ao executar o modelo, se obtém os parâmetros para a construção da equação da regressão linear: summary(modelo) ## ## Call: ## lm(formula = mater$pesoRN ~ mater$compRN) ## ## Residuals: ## Min 1Q Median 3Q Max ## -1434.56 -218.40 -19.56 177.76 2097.87 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) -3416.451 215.821 -15.83 &lt;2e-16 *** ## mater$compRN 137.674 4.475 30.77 &lt;2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 337.7 on 1083 degrees of freedom ## Multiple R-squared: 0.4664, Adjusted R-squared: 0.4659 ## F-statistic: 946.6 on 1 and 1083 DF, p-value: &lt; 2.2e-16 A equação de predição da regressão linear permite que ao conhecer o valor do comprimento é possível prever o peso do recem-nascido: \\[ \\hat{y} = b_{0}+ b_{1}\\times x \\] Desta forma, substituindo pelos valores contidos nas estimativas da tabela dos coeficientes do sumário do modelo, um bebê com 50 cm terá um peso de aproximadamente: \\[ \\hat{y} = -3416.45 + 137.67\\times 50 = 3467.05 \\] OBSERVAÇÃO: Para maiores detalhes sobre os parâmetros dos gráficos no R, consulte aqui. 6.5 Introdução ao ggplot2 O R tem vários sistemas para fazer gráficos e, na ,maioria das vezes, eles são suficientes. Entretanto, o surgimento do ggplot2 (79) trouxe a possibilidade de serem construídos gráficos mais elegantes e versáteis. Além disso, torna o processo mais rápido, baseado uma sofisticada gramática (80). O gráfico é construído, usando função ggplot(), a partir de alguns elementos básicos: Dados: os dados brutos que você deseja representar graficamente. Geometria geoms: As formas geométricas que irão representar os dados. Estética aes: Estética dos objetos geométricos e estatísticos, como posição, cor, tamanho, forma e transparência Escala scales: Mapas entre os dados e as dimensões estéticas, como intervalo de dados para plotar largura ou valores de fator para cores. Transformações estatísticas stats: resumos estatísticos dos dados, como quantis, curvas ajustadas e somas. Sistemas de coordenadas coordinates Systems: A transformação usada para mapear coordenadas de dados no plano do retângulo de dados. Facetas faceting: A organização dos dados em uma grade de gráficos. Temas visuais themes: Os padrões visuais gerais de um gráfico, como plano de fundo, grades, eixos, tipo de letra padrão, tamanhos e cores. O número de elementos pode variar dependendo de como você os agrupa e da pergunta a ser respondida. 6.5.1 Dados Antes de trabalahar com os dados, há necessidade de instalar e carregar alguns pacotes. O pacote pacman() (81) será utilizado pela sua versatilidade em buscar e carregar múltiplos pacotes. Será utilizada a função p_load(), deste pacote: if(!require(pacman)){install.packages(&quot;pacman&quot;)} ## Carregando pacotes exigidos: pacman pacman::p_load(readxl, ggplot2, dplyr, knitr, kableExtra, ggpubr, scales, forcats) Com os pacotes devidamente ativos, o conjunto de dados dadosMater.xlsx, já bastante conhecido, é carregado: mater &lt;- read_excel(&quot;Arquivos/dadosMater.xlsx&quot;) Este banco de dados é bastante extenso e contém muitas variáveis que não serão usadas. Por isso, ele será reduzido, usando a função select () do pacote dplyrpara criar um novo objeto com o nome dados: dados &lt;- mater %&gt;% select(idadeMae, anosEst, peso, renda, ig, tipoParto, fumo, pesoRN, compRN, sexo) %&gt;% filter(ig &gt;= 37 &amp; ig &lt; 42) Após este processo, algumas variáveis serão transformadas: Criação de das variáveis idadeCateg e escolaCateg A partir da variável idadeMae e usando a função cut() será criada a variável idadeCateg: dados$idadeCateg &lt;- cut(dados$idadeMae, breaks = c(13, 20, 36, 46), labels = c(&quot;&lt;20a&quot;, &quot;20-35a&quot;, &quot;&gt;35a&quot;), include.lowest = TRUE, right = FALSE, ordered_result =TRUE) A variável escolaCateg será criada da mesma maneira, a partir da variável anosest. Até 9 anos de estudos completos: ensino fundamental; de 10 a 12 anos, o ensino médio e a partir de 13 anos de estudo, o ensino superior. dados$escolaCateg &lt;- cut (dados$anosEst, breaks= c (0,10,13,18), right = FALSE, labels = c(&quot;Fundamental&quot;, &quot;Médio&quot;, &quot;Superior&quot;), include.lowest = TRUE, ordered_result =TRUE) Transformação de variáveis numéricas em fator As variáveis numéricas do banco que são categóricas serão modificadas para fatores: dados$fumo &lt;- factor (dados$fumo, levels = c(1, 2), labels = c(&quot;sim&quot;, &quot;não&quot;)) dados$tipoParto &lt;- factor (dados$tipoParto, levels = c(1, 2), labels = c(&quot;normal&quot;, &quot;cesareo&quot;)) dados$sexo &lt;- factor (dados$sexo, levels = c(1, 2), labels = c(&quot;masc&quot;, &quot;fem&quot;)) Desta forma, os dados tem a seguinte configuração: str(dados) ## tibble [1,085 × 12] (S3: tbl_df/tbl/data.frame) ## $ idadeMae : num [1:1085] 28 31 27 28 18 28 22 28 25 14 ... ## $ anosEst : num [1:1085] 6 5 8 8 7 11 6 5 9 6 ... ## $ peso : num [1:1085] 48.5 65 60 47 65.5 72 65 74 70 56.7 ... ## $ renda : num [1:1085] 3.13 0.72 2.41 1.69 1.93 1.92 2.65 2.53 0.48 1.92 ... ## $ ig : num [1:1085] 37 37 37 38 39 39 39 39 39 39 ... ## $ tipoParto : Factor w/ 2 levels &quot;normal&quot;,&quot;cesareo&quot;: 1 2 2 1 1 2 2 1 1 1 ... ## $ fumo : Factor w/ 2 levels &quot;sim&quot;,&quot;não&quot;: 2 2 1 2 1 1 2 2 2 2 ... ## $ pesoRN : num [1:1085] 3285 3100 3100 2800 3270 ... ## $ compRN : num [1:1085] 48.5 47 47 48 49 41.5 50 48 46 50 ... ## $ sexo : Factor w/ 2 levels &quot;masc&quot;,&quot;fem&quot;: 1 1 1 1 1 1 1 1 1 1 ... ## $ idadeCateg : Ord.factor w/ 3 levels &quot;&lt;20a&quot;&lt;&quot;20-35a&quot;&lt;..: 2 2 2 2 1 2 2 2 2 1 ... ## $ escolaCateg: Ord.factor w/ 3 levels &quot;Fundamental&quot;&lt;..: 1 1 1 1 1 2 1 1 1 1 ... As variáveis idadeMae e anosEst não são mais necessárias e serão removidas: dados &lt;-dados %&gt;% select(-idadeMae, -anosEst) Como forma de treinamento, os dados serão exibidos de uma forma, visualmente, mais elegante e em uma apresentação mais amigável (Tabela 6.5). A função kable(), do pacote knitr, e a função kable_styling() do pacote kableExtra, já vistas anteriormente, cumprem este papel. A função kable () pode usar a função head() embutida. Ao executar os códigos serão exibido apenas 10 linhas do banco de dados (se não for especificado, mostra apenas 6 linhas). Isto evita uma poluição visual: kable(head(dados, 10), booktabs = TRUE, caption = &quot;Dados do arquivo `dadosMater.xlsx` resumidos&quot;) %&gt;% kableExtra::kable_styling(full_width = FALSE, bootstrap_options = &quot;striped&quot;) %&gt;% kableExtra::kable_classic(html_font = &quot;Cambria&quot;) Table 6.5: Dados do arquivo dadosMater.xlsx resumidos peso renda ig tipoParto fumo pesoRN compRN sexo idadeCateg escolaCateg 48.5 3.13 37 normal não 3285 48.5 masc 20-35a Fundamental 65.0 0.72 37 cesareo não 3100 47.0 masc 20-35a Fundamental 60.0 2.41 37 cesareo sim 3100 47.0 masc 20-35a Fundamental 47.0 1.69 38 normal não 2800 48.0 masc 20-35a Fundamental 65.5 1.93 39 normal sim 3270 49.0 masc &lt;20a Fundamental 72.0 1.92 39 cesareo sim 1440 41.5 masc 20-35a Médio 65.0 2.65 39 cesareo não 3365 50.0 masc 20-35a Fundamental 74.0 2.53 39 normal não 3650 48.0 masc 20-35a Fundamental 70.0 0.48 39 normal não 2605 46.0 masc 20-35a Fundamental 56.7 1.92 39 normal não 3200 50.0 masc &lt;20a Fundamental O argumento full_width =FALSE, reduz a largura da tabela e a boostrap_options = admite vários opções além da basic, isoladas ou combinadas: striped: adiciona listras zebradas à tabela; hover: adiciona cor de fundo cinza nas linhas da tabela; condensed: torna a tabela mais compacta; responsive: faz rolagem horizontal quando há menos de 768 px (20,32 cm) 6.5.2 ggplot A sintaxe do ggplot2 é diferente do R básico. De acordo com os elementos básicos, um ggplot padrão precisa de três informações que devem ser especificadas: os dados, a estética e a geometria. Essas são as camadas principais. Vamos construir um ggplot padrão (Figura 6.31) que será recebido por um objeto g, usando data = dados e a estética (aes) usará, no eixo x, a variável compRN e, no eixo y, a variável pesoRN. g &lt;- ggplot (data = dados, aes (x = compRN, y = pesoRN)) g Figure 6.31: Gráfico ggplot padrão A este gráfico básico “vazio” adiciona-se uma camada que especifique o tipo de gemometria desejada (Figura 6.32). Será utilizada a geom_point() que retorna um gráfico de dispersão. g + geom_point() Figure 6.32: Gráfico de dipersão A estética (aes) pode ser definida tanto na camada ggplot como na geom. Especificando no ggplot, esta aes será usada em todos os geoms usados. Usando no geom, servirá apenas para ele. No exemplo. é indiferente o local de uso da aes, o resultado será o mesmo, pois temos apenas um geom. 6.5.3 Tipos de geoms Encontra-se uma grande possibilidade de geometrias, de acordo com o tipo de gráfico que será plotado. Elas podem ser visualizadas aqui. Por exemplo: Histograma Para a construção de um histograma, usaremos a variável pesoRN e o geom_histogram(). Aqui, há necessidade apenas do eixo x, pois existe uma única variável onde se observa a sua distribuição (Figura 6.33): ggplot(data = dados) + geom_histogram(aes(x = pesoRN)) Figure 6.33: Histograma no ‘ggplot2’ Gráfico de barras Sera construído um gráfico de barras (Figura 6.34) da variável idadeCateg, usando o geom_bar(). ggplot(data = dados) + geom_bar(aes(x = idadeCateg, y = after_stat(count/sum(count)))) Figure 6.34: Gráfico de barras no ‘ggplot2’ Boxplot Com o geom_boxplot(), serão construídos boxplots (Figura 6.35) comparando os pesos dos neonatos por sexo.. ggplot(data = dados) + geom_boxplot(aes(x = sexo, y = pesoRN)) Figure 6.35: Boxplot no ‘ggplot2’ Gráfico de linhas Para obter os dados clique aqui e baixar para o seu diretório de trabalho o arquivo dadosObitos.xlsx. Este conjunto de dados é constituído pelos óbitos por COVID-19 no Rio Grande do Sul, 2020-2022. Crie o objeto obitos para receber o banco de dados, a partir do diretório de trabalho. obitos &lt;- read_excel(&quot;Arquivos/dadosObitos.xlsx&quot;) str(obitos) ## tibble [25 × 2] (S3: tbl_df/tbl/data.frame) ## $ data : POSIXct[1:25], format: &quot;2020-03-01&quot; &quot;2020-04-01&quot; ... ## $ obitos: num [1:25] 4 60 182 440 1391 ... Para a construção do gráfico de linha (Figura @ref{fig:ggline)), será usado o geom_line(). ggplot(data = obitos) + geom_line(aes(x = data, y = obitos)) Figure 6.36: Gráfico de linha no ‘ggplot2’ 6.5.4 Modificando argumentos do geom Agora, serão modificados alguns argumentos no geom. Cada tipo de geom possibilita alterações específicas. Inicialmente, serão realizadas modificações no gráfico de dispersão, construído acima com o geom_point, modificando a cor, de acordo com o sexo do recém-nascido (Figura 6.37): ggplot(data = dados) + geom_point(aes(x = compRN, y = pesoRN, color = sexo)) Figure 6.37: Gráfico de dispersão modificado com cores de acordo com o sexo Como o argumento cor foi colocado dentro da aes, ele será definido por uma variável, no caso sexo. Neste caso, cada um dos sexos serão representados por pontos coloridos diferentes. A escolha da cor foi automática pelo ggplot2 entregando duas cores conforme o padrão da sua paleta. O tamanho dos pontos pode ser alterado com o argumento size (Figura 6.38). ggplot(data = dados) + geom_point(aes(x = compRN, y = pesoRN, color = sexo, size = sexo)) Figure 6.38: Gráfico de dispersão com cores e tamanhos diferentes dos pontos, de acordo com o sexo Ficou meio bagunçado, pois os pontos se sobrepõem e dificulta a visualização e inclusive o R libera um aviso informando que isto não é recomendado. O formato pode ser modificado com o argumento shape(Figura 6.39): ggplot(data = dados) + geom_point(aes(x = compRN, y = pesoRN, color = sexo, shape = sexo, size = sexo)) Figure 6.39: Gráfico de dispersão com formatos dos pontos diferentes, de acordo sexo Agora, ficou muito pior! Não teria, logicamente, muito sentido modificar tudo ao mesmo tempo, com a mesma variável. Foi realizado, aqui, apenas para mostrar a possibilidade do ggplot2. Estes argumentos foram modificados dentro da estética (aes), usando o nome da variável. Entretanto, também é possível colocar os argumentos fora da aes. Nesta situação (Figura 6.40), colocando a cor fora da aes, há necessidade de escolher uma determinada cor para os pontos. ggplot(data = dados) + geom_point(aes(x = compRN, y = pesoRN, shape = sexo), color = &quot;steelblue&quot;, size = 3) Figure 6.40: Gráfico de dispersão com alteração do formato O formato (shape) pode ser colocado fora do aes (Figura 6.41) e aqui se encontram vários formatos que podem ser usados no ggplot2També é possível observar os diferentes formatos (shape), usando o seguinte comando, encontrado no pacote ggpubr: ggpubr::show_point_shapes() ## Scale for y is already present. ## Adding another scale for y, which will replace the existing scale. ggplot(data = dados) + geom_point(aes(x = compRN, y = pesoRN), color = &quot;tomato&quot;, size = 2, shape = 25) Figure 6.41: Gráfico de dispersão por sexo com alteração do argumento color e shape 6.5.5 Reta de ajuste em um gráfico de dispersão Acrescenta-se uma nova camada , chamada geom_smoot, além da geom_point. Os argumentos são o method = \"lm\"que irá ajustar uma reta aos pontos. Também é possível colocar um intervalo de mais ou menos um erro padrão para a reta com o argumentose = TRUE. No exemplo (Figura 6.42), foi usado se = FALSE. Além disso, foi solicitado que cor da reta seja preta (color = \"black\"), reduzido o seu tamanho (size = 0.5) e estabelecido que a reta seja tracejada (linetype = \"dashed\") 10: ggplot(data = dados, aes(x = compRN, y = pesoRN)) + geom_point(color = &quot;tomato&quot;, size = 3) + geom_smooth(method = &quot;lm&quot;, se = FALSE, color = &quot;black&quot;, linewidth = 0.5, linetype = &quot;dashed&quot;) ## `geom_smooth()` using formula = &#39;y ~ x&#39; Figure 6.42: Gráfico de dispersão com reta de ajuste Quando se usa mais de um geom, é importante a ordem em que eles são escritos, pois, como cada um deles é uma camada, elas se sobrepõem e podem se confundir. 6.5.6 Filtrando dados para o gráfico Faz-se isso, usando a função filter() do pacote dplyr. Será construído um gráficoigual ao anterior, filtrando apenas o sexo masculino (Figura 6.43): dados %&gt;% filter (sexo == &quot;masc&quot;) %&gt;% ggplot(aes(x = compRN, y = pesoRN)) + geom_point(color = &quot;steelblue&quot;, size = 3) + geom_smooth(method = &quot;lm&quot;, se = FALSE, color = &quot;black&quot;, size = 0.5, linetype = &quot;dashed&quot;) ## Warning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0. ## ℹ Please use `linewidth` instead. ## This warning is displayed once every 8 hours. ## Call `lifecycle::last_lifecycle_warnings()` to see where this warning was ## generated. ## `geom_smooth()` using formula = &#39;y ~ x&#39; Figure 6.43: Gráfico de dispersão com reta de ajuste para o sexo masculino 6.5.7 Resumo dos dados usando o geom Inicialmente, serão usado os argumentos stat = \"summary\" e fun = \"mean\" dentro do geom_point() (Figura 6.44): ggplot(data = dados, aes(x = sexo, y = pesoRN, color = sexo)) + geom_point(stat = &quot;summary&quot;, fun = &quot;mean&quot;, size = 3, show.legend = FALSE) Figure 6.44: Gráfico resumo, mostrando as médias por sexo O argumento show.legend = FALSE foi acrescentado para evitar o aparecimento da legenda, indicando quem é masc ou fem, pois o eixo x já mostra. Pode-se chegar ao mesmo resultado, usando a função stat_summary() para acrescentar estatísticas de resumo. 6.5.8 Incluindo barras de erro Aqui, usamos uma camada geom_error bar(), com os argumentos stat = summary e fun.data = \"mean_se\". Este último argumento fornece a média e o erro padrão e o width = 0.1, o tamanho da barra horizontal, gerando o gráfico da Figura 6.45: ggplot(data = dados, aes(x = sexo, y = pesoRN, color = sexo)) + geom_point(stat = &quot;summary&quot;, fun = &quot;mean&quot;, size = 3, show.legend = FALSE) + geom_errorbar(stat = &quot;summary&quot;, fun.data = &quot;mean_se&quot;, width = 0.1, show.legend = FALSE) Figure 6.45: Gráfico de barra de erro no ggplot2 Usando o pacote ggpubr consegue-se criar um gráfico semelhante (Figura 6.46) ao anterior (média \\(\\pm\\) se), mas com o intervalo de confiança (média \\(\\pm\\) \\(1.96 \\times se\\)). ggplot(data = dados, aes(x = sexo, y = pesoRN, color = sexo)) + geom_point(stat = &quot;summary&quot;, fun = &quot;mean&quot;, size = 3, show.legend = FALSE) + geom_errorbar(stat = &quot;summary&quot;, fun.data = &quot;mean_ci&quot;, width = 0.1, show.legend = FALSE) Figure 6.46: Gráfico de barra de erro no ggpubr 6.5.9 Incluindo mais de um grupo no gráfico Agora, será construído o mesmo gráfico do peso dos recém nascidos por sexo, levando em consideração o tabagismo materno (Figura 6.47). Em primeiro lugar, filtra-se pelo tabagismo, presente ou ausente. Depois seguindo a mesma programação anterior, separando as cores pelo tabagismo (fumo). Coloca-se também o argumento position = position_dodge (0.4) para que não haja sobreposição das barras no gráfico e exibe-se a legenda (show.legend = TRUE): dados %&gt;% filter(fumo %in% c(&quot;sim&quot;, &quot;não&quot;)) %&gt;% ggplot(aes(x = sexo, y = pesoRN, color = fumo)) + geom_point(stat = &quot;summary&quot;, fun = &quot;mean&quot;, position = position_dodge(0.4), size = 3, show.legend = TRUE) + geom_errorbar(stat = &quot;summary&quot;, fun.data = &quot;mean_ci&quot;, width = 0.1, show.legend = TRUE, position = position_dodge(0.4)) Figure 6.47: Gráfico do peso do neonato de acordo com sexo e tabagismo materno 6.5.10 Modificando o tema O tema padrão do ggplot2 é uma aparência acinzentada que pode ser modificada pela definição de outro tema integrado, como o theme_bw() (Figura 6.48) que é uma variação de theme_grey(), padrão, que usa um fundo branco e linhas finas de grade cinza. Outro tema interessante é o theme_classic() que é um tema de aparência clássica, com linhas dos eixos x e y e sem linhas de grade, já usado no gráfico anterior. Para ver outras possibilidades clique aqui. ggplot(data = dados) + geom_boxplot(aes(x = sexo, y = pesoRN)) + theme_bw() Figure 6.48: Boxplots do peso do neonato de acordo com sexo Ou, adicionando cores aos boxplots e removendo a legenda, em uma nova camada, com o argumentolegend.position=\"none\" da função theme () (Figura 6.49): ggplot(data = dados) + geom_boxplot(aes(x = sexo, y = pesoRN, color = sexo)) + theme_classic() + theme(legend.position=&quot;none&quot;) Figure 6.49: Boxplots com outro tema e sem legenda 6.5.11 Trabalhando com os eixos Rótulo dos eixos Para adicionar ou modificar os rótulos dos eixos, adiciona-se labs(), escrevendo em cada rótulo (x e y) os seus respectivos rótulos (Figura 6.50): ggplot(data = dados) + geom_boxplot(aes(x = sexo, y = pesoRN, color = sexo)) + labs (x = &quot;Sexo do recém-nascido&quot;, y = &quot;Peso do recém-nascido (g)&quot;) + theme_classic() + theme(legend.position=&quot;none&quot;) Figure 6.50: Boxplots com rótulos dos eixos modificados Modificando o espaço entre o eixo e os rótulos do eixo A função theme() é um comando essencial para modificar elementos específicos do tema (textos e títulos, caixas, símbolos, planos de fundo,etc.). É bastante usado! Por enquanto, serão modificados elementos de texto (Figura 6.51). É possível alterar as propriedades de todos ou alguns específicamente (aqui os títulos dos eixos), substituindo o element_text () padrão com theme (): ggplot(data = dados) + geom_boxplot(aes(x = sexo, y = pesoRN, color = sexo)) + labs (x = &quot;Sexo do recém-nascido&quot;, y = &quot;Peso do recém-nascido (g)&quot;) + theme(axis.title.x = element_text(vjust = 0, size = 15), axis.title.y = element_text(vjust = 2, size = 15)) + theme_classic() + theme(legend.position=&quot;none&quot;) Figure 6.51: Boxplots com elementos dos textos modificados O argumento vjust se refere ao alinhamento vertical, que geralmente varia entre 0 e 1, mas pode-se especificar valores fora desse intervalo. Pode-se, também, alterar a distância especificando a margem de ambos os elementos de texto (Figura 6.52): ggplot(data = dados) + geom_boxplot(aes(x = sexo, y = pesoRN, color = sexo)) + labs (x = &quot;Sexo do recém-nascido&quot;, y = &quot;Peso do recém-nascido (g)&quot;) + theme(axis.title.x = element_text(margin = margin (t = 10), size = 15), axis.title.y = element_text(margin = margin (r = 10), size = 15)) + theme_classic() + theme(legend.position=&quot;none&quot;) Figure 6.52: Boxplots com outras modificações Os rótulos t e r dentro da função margin() referem-se ao topo e à direita, respectivamente. É possível especificar as quatro margens como margem (t, r, b, l). Observe que, agora, há necessidade de alterar a margem direita para modificar o espaço no eixo y, não a margem inferior. Acrescentando um título Pode-se adicionar um título através da função ggtitle() (Figura 6.53): ggplot(data = obitos) + geom_line(aes(x = data, y = obitos)) + labs(x = &quot;Data (ano/mês)&quot;, y = &quot;Nº de mortes&quot;) + ggtitle (&quot;Mortes por COVID-19 - SES/RS, 2020-22&quot;) + theme_classic() Figure 6.53: Boxplots com elementos dos textos modificados Uma outra maneira de colocar título, subtítulo e fonte no gráfico é (Figura 6.54): ggplot(data = obitos) + geom_line(aes(x = data, y = obitos)) + labs(x = &quot;Data (ano/mês)&quot;, y = &quot;Nº de mortes&quot;, title = &quot;Mortes por COVID-19&quot;, subtitle = &quot;RS - 2020-2022&quot;, caption = &quot;Fonte: SES&quot;) + theme_classic() Figure 6.54: Boxplots com elementos dos textos modificados Outro exemplo, modificando o tamanho, estilo e tipo de fonte (Figura 6.55). Isto é feito, adicionando a camada theme() com argumentos plot.title, plot.subtitle, etc. Para maiores detalhes consulte aqui. ggplot(data = dados, aes(x = sexo, y = pesoRN, color = sexo)) + geom_point(stat = &quot;summary&quot;, fun = &quot;mean&quot;, size = 3, show.legend = FALSE) + geom_errorbar(stat = &quot;summary&quot;, fun.data = &quot;mean_ci&quot;, width = 0.1, show.legend = FALSE) + labs(x = &quot;Sexo do recém-nascido&quot;, y = &quot;Peso do recém-nascido (g)&quot;, title = &quot;Peso do RN por sexo&quot;, subtitle = &quot;Maternidade do HGCS&quot;, caption = &quot;Fonte: Autor&quot;) + theme_classic() + theme (plot.title = element_text(size = 13, face = &quot;bold&quot;, color = &quot;navy&quot;), plot.subtitle = element_text(size = 11, face = &quot;bold&quot;, color = &quot;steelblue&quot;)) Figure 6.55: Boxplots com elementos dos textos modificados Modificando os limites dos eixos O sistema de coordenadas cartesianas é o tipo de sistema de coordenadas mais familiar e comum. Definir limites no sistema de coordenadas ampliará o gráfico (como se você estivesse olhando para ele com uma lupa) e não alterará os dados subjacentes, como definir limites em uma escala. Para realizar este trabalho, vamos usar a função coord_cartesian () ou scale_y_continuous () ou scale_x_continuous (). Será usado aqui o gráfico já construído acima (Figura 6.42) com pequenas alteraçõese vamos armazená-lo em um objeto, denominado gd (gráfico de dipersão). Isto facilita a repetição do gráfico em outros códigos, pois basta escrever gd e executar (Figura 6.56). gd &lt;- ggplot(data = dados, aes(x = compRN, y = pesoRN)) + geom_point(color = &quot;tomato&quot;, size = 3) + geom_smooth(method = &quot;lm&quot;, se = FALSE, color = &quot;black&quot;, size = 0.8, linetype = &quot;dashed&quot;) + labs(x = &quot;Comprimento do RN (cm)&quot;, y = &quot;Peso do RN (g)&quot;, title = &quot;Gráfico de Dispersão&quot;, caption = &quot;Fonte: Autor&quot;) + theme_classic() gd Figure 6.56: Gráfico de dispersão Função coord_cartesian() xlim, ylim \\(\\longrightarrow\\) limites dos eixos x e y expand \\(\\longrightarrow\\) Se TRUE, o padrão, adiciona um pequeno fator de expansão aos limites para garantir que dados e eixos não se sobreponham. Se FALSE, os limites são tirados exatamente dos dados ou xlim/ylim (Figura 6.57). gd + coord_cartesian(ylim = c(3500, 4000), xlim = c(45, 55), expand = TRUE) Figure 6.57: Gráfico de dispersão expandido Observe que é como se fizesse um zoom no gráfico nos limites estabelecidos. Há um corte um pouco acima dos limites. No eixo y, um pouco acima de 4000 e um pouco abaixo de 3500 e, no eixo x, um pouco à esquerda de 45 e um pouco à direita de 55. Isto aconteceu, porque colocamos expand = TRUE. Para extrair esta margem, colocar expand = FALSE: Usando escalas de posição contínuas Pode-se usar a função scale_y_continous() e scale_x_continuous() para fazer algo parecido com a coord_cartesian() (Figura 6.58): gd + scale_x_continuous(limits = c(45, 55)) + scale_y_continuous (limits = c(3500, 4000)) ## `geom_smooth()` using formula = &#39;y ~ x&#39; Figure 6.58: Gráfico de dispersão expandido A função removeu os casos que estão fora dos limites estabelecidos. No caso, a mensagem do R mostra que foram removidos 1132 casos. O gráfico foi construido sem estes casos e, no gráfico anterior, houve apenas uma aproximação (um zoom) dentro dos limites. Portanto, houve um impacto importante no gráfico. Se os dados não forem em escala contínua, é possível escolher outra escala, por esxemplo scale_y_discrete (). Modificando a expansão Mostrou-se que é possível interfir na expansão da margem com o argumento expand = TRUE ou FALSE que pode ser usado também com a função scale_y_continuous(). Agora, será visto um exemplo de um gráfico de barras das faixas etárias das gestantes (Figura 6.59): gb &lt;- ggplot(data = dados) + geom_bar(aes(x = idadeCateg, y = after_stat(count/sum(count)), fill = idadeCateg), show.legend = FALSE) + labs(y = &quot;Frequência&quot;, x = &quot;Faixa Etária da Parturiente&quot;) gb Figure 6.59: Gráfico de barras Observe que abaixo do 0 (zero) existe uma expansão (Figura 6.60). Para que as barras tenham início exatamente no 0, pode-se empregar a função scale_y_continuous() com o argumento expand = expansion (add = c(0,50)), significando que não se expande nada abaixo do 0 e se adiciona 50 unidades para cima, criando uma margem superior. gb + scale_y_continuous (expand = expansion(add = c(0,0.05))) Figure 6.60: Gráfico de barras com expansão Isto também poderia ser feito com mult no lugar do add (Figura 6.61), representando o multiplicador que se coloca acima e abaixo: gb + scale_y_continuous (expand = expansion(mult = c(0,0.05))) Figure 6.61: Gráfico de barras, igual a anterior Usando a proporção ou percentagem nos eixos Para usar a proporção no eixo y do gráfico anterior, devemos modificar a estética deste eixo, usando y = after_stat(count/sum(count))(Figura 6.62). gbp &lt;- ggplot(data = dados) + geom_bar(aes(x = idadeCateg, y = after_stat(count/sum(count)), fill = idadeCateg), show.legend = FALSE) + labs(y = &quot;Frequência&quot;, x = &quot;Faixa Etária da Parturiente&quot;, caption = &quot;Fonte: Autor&quot;) gbp Figure 6.62: Gráfico de barras com proporções no eixo y Para ter a percentagem (Figura 6.63), empregar a função percent_format() do pacote scales (82): gbp + scale_y_continuous (expand = expansion(mult = c(0,0.05)), labels = percent_format (accuracy = 0.1, decimal.mark = &quot;,&quot;)) Figure 6.63: Gráfico de barras com percentagens no eixo y Mudando o nome e a ordem dos rótulos do eixo x No gráfico acima, temos a faixa etária dividida em &lt;20a, 20-35a e &gt;35a. Pode haver interesse em mudar para adolescentes, adultas jovens e gestante idosa (Figura 6.64). Para fazer isso, sem mudar o banco de dados, simplemente modifica-se os rótulos no argumento labels da função scale_x_discrete(): gbp &lt;- ggplot(data = dados) + geom_bar(aes(x = idadeCateg, y = after_stat(count/sum(count)), fill = idadeCateg), show.legend = FALSE) + labs(y = &quot;Frequência&quot;, x = &quot;Faixa Etária da Parturiente&quot;, caption = &quot;Fonte: Autor&quot;) + scale_y_continuous (expand = expansion(mult = c(0,0.05)), labels = percent_format (accuracy = 0.1, decimal.mark = &quot;,&quot;)) + scale_x_discrete (labels = c(&quot;Adolescente&quot;, &quot;Adulta jovem&quot;, &quot;Gestante idosa&quot;)) gbp Figure 6.64: Gráfico de barras com eixo x modificado É viável, também, mudar esta ordem no eixo x, da maior frequência para a menor (Figura 6.65): gbp + scale_x_discrete (limits = c(&quot;20-35a&quot;, &quot;&lt;20a&quot;, &quot;&gt;35a&quot;), labels = c(&quot;Adulta jovem&quot;, &quot;Adolescente&quot;, &quot;Gestante idosa&quot;)) ## Scale for x is already present. ## Adding another scale for x, which will replace the existing scale. Figure 6.65: Gráfico de barras com eixo x modificado Pode-se conseguir o mesmo resultado anterior com o a função fct_infreq() do pacote forcats, colocada na estética do geom_bar(). ggplot(data = dados) + geom_bar(aes(x = fct_infreq (idadeCateg), y = after_stat(count/sum(count)), fill = idadeCateg), show.legend = FALSE) + labs(y = &quot;Frequência&quot;, x = &quot;Faixa Etária da Parturiente&quot;, caption = &quot;Fonte: Autor&quot;) + scale_y_continuous (expand = expansion(mult = c(0,0.05)), labels = percent_format (accuracy = 0.1, decimal.mark = &quot;,&quot;)) + scale_x_discrete (labels = c(&quot;Adulta jovem&quot;, &quot;Adolescente&quot;, &quot;Gestante idosa&quot;)) Moficando os intervalos dos valores do eixo O gráfico de linha de mortes por COVID no RS, 2020-2022, visto anteriormente (Figura 6.36), será atribuído a um objeto gl: gl &lt;- ggplot(data = obitos) + geom_line(aes(x = data, y = obitos)) + labs(x = &quot;Ano (mês)&quot;, y = &quot;Nº de mortes&quot;) + theme_classic() gl Figure 6.66: Mortes por COVID-19, 2020-2022, RS. Observe (Figura 6.66) que, no eixo y, os óbitos estão registrados a cada 2000 e, no eixo x, foram marcadas apenas 4 datas. Podemos modificar isso adicionando duas camadas, usando as funções scale_y_continuous() e scale_x_datetime(): gl + scale_y_continuous(n.breaks = 10) + scale_x_datetime(date_breaks = &quot;4 month&quot;, date_labels = &quot;%Y (%b)&quot;) Figure 6.67: Mortes por COVID-19, 2020-2022, RS. O aspecto do gráfico mudou um pouco (Figura 6.67). Agora, existem marcações no eixo y a cada 1000 mortes e o registro do tempo aparece a cada 4 meses, conforme estabelecido no argumento date_breaks = \"4 month\" e o formato foi modificado com o argumento date_labels = \"%Y %b\". Neste, %Y significa o ano e %b significa o mês abreviado (Jan-Dec). Para ver como customizar as datas, veja aqui 6.5.12 Modificação das cores Voltando a usar um gráfico de barra, já visto anteriormente (Figura 6.64), da distribuição da idade da gestante por faixa etária, onde ggplot2 escolheu as cores porque foi colocado o argumento fill = idadeCateg. Essas cores não foram escolhidas pelo autor e é possível mudá-las, usando uma paleta própria. por exemplo, adicionando uma camada com a função scale_fill_manual() (Figura 6.68): ggplot(data = dados) + geom_bar(aes(x = idadeCateg, y = after_stat(count/sum(count)), fill = idadeCateg), show.legend = FALSE) + labs(y = &quot;Frequência&quot;, x = &quot;Faixa Etária da Parturiente&quot;, caption = &quot;Fonte: Autor&quot;) + scale_y_continuous (expand = expansion(mult = c(0,0.05)), labels = percent_format (accuracy = 0.1, decimal.mark = &quot;,&quot;)) + scale_x_discrete (labels = c(&quot;Adolescente&quot;, &quot;Adulta jovem&quot;, &quot;Gestante idosa&quot;)) + scale_fill_manual(values = c(&quot;steelblue&quot;, &quot;navy&quot;, &quot;lightblue&quot;)) Figure 6.68: Frequência da faixa etária das parturientes da Maternidade do HCCS, 2008. As cores podem ser escolhidas aqui. Além de escrever o nome das cores aceitas pelo ggplot2, é possível usar o sistema hexadecimal que utiliza números e letras. Ver aqui o gerador de paletas. Copiar o código e colocar antes o símbolo #. É possível, também, usar uma paleta de pacotes do R, como o pacote RColorBrewer(Figura 6.69). ggplot(data = dados) + geom_bar(aes(x = idadeCateg, y = after_stat(count/sum(count)), fill = idadeCateg), show.legend = FALSE) + labs(y = &quot;Frequência&quot;, x = &quot;Faixa Etária da Parturiente&quot;, caption = &quot;Fonte: Autor&quot;) + scale_y_continuous (expand = expansion(mult = c(0,0.05)), labels = percent_format (accuracy = 0.1, decimal.mark = &quot;,&quot;)) + scale_x_discrete (labels = c(&quot;Adolescente&quot;, &quot;Adulta jovem&quot;, &quot;Gestante idosa&quot;)) + scale_fill_brewer(palette = &quot;Dark2&quot;) Figure 6.69: Frequência da faixa etária das parturientes da Maternidade do HCCS, 2008. Usando o pacote ggsci, pode-se escolher o padrão de algumas revistas médicas como a JAMA, Lancet, etc (Figura 6.70).Para maiores detalhes acesse aqui pacman::p_load(ggsci) ggplot(data = dados) + geom_bar(aes(x = idadeCateg, y = after_stat(count/sum(count)), fill = idadeCateg), show.legend = FALSE) + labs(y = &quot;Frequência&quot;, x = &quot;Faixa Etária da Parturiente&quot;, caption = &quot;Fonte: Autor&quot;) + scale_y_continuous (expand = expansion(mult = c(0,0.05)), labels = percent_format (accuracy = 0.1, decimal.mark = &quot;,&quot;)) + scale_x_discrete (labels = c(&quot;Adolescente&quot;, &quot;Adulta jovem&quot;, &quot;Gestante idosa&quot;)) + scale_fill_lancet() Figure 6.70: Frequência da faixa etária das parturientes da Maternidade do HCCS, 2008. 6.5.13 Exemplo final: Gráfico de barra de erro com colunas Será construído um gráfico de barras de erro para visualizar a influência do sexo e do tabagismo materno no peso do recém-nascido (Figura 6.71. Será incluído a representação das colunas (barras) e as barras de erro com intervalo de confiança de 95%, calculado usando média \\(\\pm\\) margem de erro, onde margem de erro = 1.96 \\(\\times\\) erro padrão. Estes conceitos serão discutidos em outros capítulos. Em primeiro lugar, faz-se um resumo dos dados que serão usados no gráfico: resumo &lt;- dados %&gt;% group_by(sexo, fumo) %&gt;% dplyr::summarise(n = n(), media = mean(pesoRN, na.rm = TRUE), dp = sd(pesoRN, na.rm = TRUE), me = 1.96 * dp/sqrt(n)) resumo ## # A tibble: 4 × 6 ## # Groups: sexo [2] ## sexo fumo n media dp me ## &lt;fct&gt; &lt;fct&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 masc sim 122 3162. 464. 82.4 ## 2 masc não 470 3303. 453. 40.9 ## 3 fem sim 110 2998. 503. 94.1 ## 4 fem não 383 3190. 435. 43.6 Onde, dp = desvio padrão e me = margem de erro. O objeto resumo pertence a classe data.frame e será empregado na construção do gráfico: ggplot(resumo, aes(x=sexo, y=media, fill=fumo)) + geom_bar(stat=&quot;identity&quot;, color=&quot;black&quot;, position=position_dodge()) + geom_errorbar(aes(ymin=media-me, ymax=media+me), width=.2, position=position_dodge(.9)) + labs(x=&quot;Sexo&quot;, y = &quot;Peso do RN (g)&quot;, fill = &quot;Tabagismo&quot;, caption = &quot;RN = Recém-nascido&quot;)+ theme_classic() + scale_fill_manual(values=c(&#39;gray80&#39;,&#39;darkslategray1&#39;)) Figure 6.71: Influência do sexo e tabagismo materno no peso ao nascer. Observe que o rótulo da legenda foi determinado com fill = \"Tabagismo\", porque a cor das barras foi estabelecida na estética do ggplot com o mesmo argumento. OBS.: Clique em ggplot2::cheat sheet para obter a planilha de dicas do ggplot2. Poderiam ser transformados em fatores sem trocar os rótulos e manter os números 1 e 2, como se fossem palavras. O autor prefere usar nomes.↩︎ Para outras opções do tipo de linha, pode-se usar a função show_lines_types() do pacote ggpubr↩︎ "],["introdução-à-teoria-das-probabilidades.html", "Capítulo 7 Introdução à Teoria das Probabilidades 7.1 Introdução 7.2 Processo aleatório 7.3 Definição frequentista de probabilidade 7.4 Propriedades das probabilidades 7.5 Distribuição de Probabilidades 7.6 Distribuição Normal 7.7 Distribuição Binomial 7.8 Distribuição de Poisson", " Capítulo 7 Introdução à Teoria das Probabilidades 7.1 Introdução A teoria das probabilidades é a base sobre a qual a estatística é desenvolvida. Os jogos de azar deram um grande impulso ao conhecimento da teoria da probabilidade, principalmente, pelo trabalho de Blaise Pascal (1623-1662) em parceria com Pierre de Fermat (1601-1665), estimulados por um nobre francês, Antoine Gombaud, conhecido como Chevalier de Mère, inveterado jogador, que estava cansado dos resultados negativos em suas apostas (83). A Teoria das probabilidades permite que seja possível modelar populações, experimentos ou qualquer situação que possa ser considerada aleatória. Estes modelos possibilitam fazer inferência sobre populações a partir da observação de uma amostra dessa população. Ao usar apenas uma parte da população, inevitavelmente, é cometido um erro o erro amostral. Este erro amostral pode ser dimensionado pela teoria das probabilidades. Existem duas interpretações alternativas de probabilidades: a frequentista e a bayesiana (84). Neste livro, será discutida, basicamente, a definição de probabilidade frequentista. O processo bayesiano de formulação de um modelo probabilístico faz uso do conhecimento subjetivo, estabelecendo uma especificação a priori, combinado com a informação objetiva ou empírica. A teoria bayesiana é a estrutura integradora dessas duas fontes de informação, derivando como resultado a distribuição a posteriori dos parâmetros de interesse. No capítulo sobre análise de testes diagnósticos, será abordado alguns aspectos relacionados a teoria bayesiana. 7.2 Processo aleatório Um processo ou experimento é dito aleatório quando em uma situação se sabe quais os resultados que podem acontecer, mas não se sabe qual resultado particular irá acontecer. Por exemplo, quando uma moeda é lançada, se conhece que a probabilidade de o desfecho cara ocorrer é de 50%, mas se desconhece o que irá ocorrer até que a moeda esteja no chão. O número de caras que podem surgir em vários lançamentos da moeda é chamado de variável aleatória, ou seja, uma variável que pode assumir mais de um valor com determinadas probabilidades (85). Da mesma forma, um dado lançado pode mostrar seis faces, numeradas de um a seis, com igual probabilidade de 16,7%. Portanto, quando a probabilidade é associada a todos os conjuntos de valores possíveis de uma variável, diz-se que ela é aleatória. O conjunto de todos os possíveis resultados de um experimento aleatório é denominado espaço amostral. Na área da saúde, trabalha-se com uma infinidade de variáveis aleatórias, por exemplo, o número de filhos de uma mulher, o número de mortos diários em uma epidemia, o número de vacinados em uma campanha, etc. Essas variáveis são a variáveis aleatórias discretas, pois apenas permitem ser quantificadas por processo de contagem. Por outro lado, o peso, a altura de uma mulher são ditos variáveis aleatórias contínuas, pois podem assumir qualquer valor real entre uma medida e outra, dependendo da precisão do aparelho usado. Em geral, Variáveis aleatórias são representadas por letras maiúsculas, como X, Y e Z e sua a probabilidade pode ser denotada por: \\[ P[X] \\quad ou \\quad P[X=x] \\] 7.3 Definição frequentista de probabilidade A probabilidade se relaciona a eventos futuros ou que ainda não ocorreram, desta forma a probabilidade pode ser entendida como uma medida de incerteza em relação ao evento. A probabilidade de um evento ocorrer, em determinadas circunstâncias, pode ser definida como a proporção de vezes que o evento é observado quando o experimento é repetido um número infinitamente grande de vezes (84). A chamada Lei dos Grandes Números diz que à medida que múltiplas observações são coletadas, a proporção observada de ocorrências de um determinado desfecho, após n ensaios, converge para a probabilidade real P desse desfecho. Ou seja, quanto mais vezes for repetido uma experiência, a melhor estimativa de probabilidade tende a ocorrer. O resultado dos comandos abaixo simulam 1000 lançamentos de uma moeda, mostrando que quando chega próximo de 300 lançamentos, a probabilidade se mantém praticamente constante em torno de 50% (Figura 7.1). x=1:1000 y=cumsum (sample (0:1,1000, rep=TRUE)) plot (x,y/1:1000, ylab=&quot;Probabilidade&quot;, xlab = &quot;Lançamentos da moeda&quot;, ylim=c (0.3,0.8), xlim=c (0,1000), pch=16, col=&quot;steelblue&quot;) abline(h = 0.5, col = &quot;red&quot;, lty = 2) Figure 7.1: Simulação do lançamento de 1000 moedas. A definição frequentista também pode ser aplicada a uma medida contínua como a altura de mulheres. No conjunto de dados dadosMater.xlsx (veja seção 5.3), encontra-se o registro da altura de 1368 mulheres. Esssas alturas serão selecionadas e colocas em objeto wh (women height): library(readxl) library(dplyr) wh &lt;- read_excel(&quot;Arquivos/dadosMater.xlsx&quot;) %&gt;% select(altura) summary (wh) ## altura ## Min. :1.400 ## 1st Qu.:1.550 ## Median :1.600 ## Mean :1.598 ## 3rd Qu.:1.650 ## Max. :1.850 A mediana da altura das gestantes é 1,60 m. Ou seja, metade dessas mulheres têm uma altura acima de 1,60 m. Em um longo conjunto de sorteios, a probabilidade de uma mulher ter altura acima de 1,60 m é 50%. O percentil 75 (3º quartil) é igual a 1,65 m, a probabilidade de estar acima deste valor, portanto, é 25%. É possível encontrar a probabilidade de a altura estar acima, abaixo ou entre quaisquer valores. Quando se faz a mensuração de uma variável contínua, fica-se limitado ao método usado, portanto, quando se diz que uma mulher tem 1,60 m, significa dizer que está entre 159,5 e 165,5 m, dependendo da precisão do instrumento de medição. Logo, o interesse está na probabilidade de a variável aleatória assumir valores entre certos limites. A probabilidade de encontrar um valor exatamente de 1,60 m é quase igual a zero (na realidade, \\(2.7 \\times 10^{-124}\\)). Como se verá adiante, isto pode ser facilmente calculado no R: # Distância do valor de 1,60 e a média em desvios padrão (escores Z) z &lt;- (1.60 - mean(wh$altura))/sd(wh$altura) # Probabilidade pnorm (z, mean(wh$altura),sd(wh$altura)) ## [1] 7.387473e-127 7.4 Propriedades das probabilidades As seguintes propriedades simples decorrem da definição de probabilidade. Sendo E um evento aleatório, a \\(P[E]\\) está entre 0 e 1, ou seja \\(0\\le P[E]\\le 1\\). Quando o evento certamente não ocorre, a probabilidade é 0, quando sempre ocorre a probabilidade é 1. Quando a probabilidade for igual a 0,50 tem-se máxima incerteza. Regra de adição (regra do “ou”) Dois eventos A e B são mutuamente exclusivos, ou seja, quando A acontece, B não pode acontecer. Então, a probabilidade de que um ou outro aconteça é a soma de suas probabilidades. Por exemplo, um dado lançado pode mostrar um ou dois, mas não ambos. A probabilidade de mostrar um ou dois é igual a \\(1/6 + 1/6 = 1/3\\). \\[ P[A ou B]=P[A]+P[B] \\] Se A e B não são mutuamente exclusivos, ou seja, quando A acontece pode também ocorrer B. Por exemplo, o nascimento de uma menina pode ser concomitante com o fato de ser branca. \\[ P[A ou B]=P[A]+P[B]-P[A \\space e \\space B] \\] Regra de multiplicação (regra do “e”) Suponha que dois eventos (A e B) sejam independentes, ou seja, saber que um aconteceu não nos diz nada sobre se o outro aconteceu. Então, a probabilidade de que ambos aconteçam é o produto de suas probabilidades. Por exemplo, suponha que jogamos duas moedas. Uma moeda não influencia a outra, portanto os resultados dos dois lançamentos são independentes e a probabilidade de ocorrerem duas caras é 050 × 0,50 = 0,25. \\[ P[A \\quad e\\quad B]=P[A]×P[B] \\] Se os eventos são dependentes, a probabilidade que ambos aconteçam é igual a: \\[ P[A \\quad e \\quad B]=P[A]×P[B \\rvert A] \\] 7.5 Distribuição de Probabilidades Um conjunto de eventos que são mutuamente excludentes e que inclui todos os eventos que podem acontecer, é chamado de exaustivo. A soma de suas probabilidades é 1. O conjunto dessas probabilidades constitui uma distribuição de probabilidade. Existem diversos modelos probabilísticos que procuram descrever vários tipos de variáveis aleatórias discretas ou contínuas. Estas distribuições também são chamadas de modelos probabilísticos estocástico que são definidas por duas funções matemáticas: a função de probabilidade (fp) para variáveis discretas, que atribui a cada valor a sua probabilidade de ocorrência (P(X=x)) e função densidade de probabilidade (fdp) para variáveis contínuas. A função de probabilidade é a função que atribui probabilidades a cada um dos possíveis valores da variável aleatória discreta, usando, em geral, as frequências relativas, apresentadas em uma tabela de frequência. O modelo de Bernoulli ou Binomial e o modelo de Poisson são exemplos de modelo probabilístico de variáveis discretas. A função densidade de probabilidade é a função que atribui probabilidade a qualquer intervalo de número reais, ou seja, um conjunto de valores não enumerável (infinito). Não é possível atribuir probabilidades para um determinado valor, é possível apenas para um intervalo. Por exemplo, o peso dos recém-nascidos. Para atribuir probabilidade a intervalos de valores é utilizada uma função e as probabilidades são representadas por áreas. Existem diversos modelos contínuos de probabilidade, mas o mais importante deles, é o modelo normal, também conhecido como modelo gaussiano. 7.6 Distribuição Normal O modelo probabilístico normal ou gaussiano é extremamente importante em estatística, pois serve como um fundamento para técnicas de inferência. Variáveis como os pesos dos recém-nascidos a termo, as alturas das mulheres adultas, a renda familiar em reais e muitas outras variáveis, na natureza, se ajustam ao modelo da distribuição normal. O modelo de distribuição normal sempre descreve uma curva simétrica, unimodal e em forma de sino (Figura 7.2). Figure 7.2: Curva normal. No entanto, essas curvas podem parecer diferentes dependendo dos detalhes do modelo. Especificamente, o modelo de distribuição normal pode ser ajustado usando dois parâmetros: média e desvio padrão. Como é fácil prever, alterar a média desloca a curva de sino para a esquerda ou para a direita, enquanto a alteração do desvio padrão estende ou achata a curva, ou seja, muda a dispersão da distribuição. A Figura 7.3, mostra a distribuição normal com média 0 e desvio padrão 1, na curva à direita, a distribuição normal com média 1.5 e desvio padrão 1. Sobrepondo-se à curva da esquerda observa-se uma curva mais achatada (verde) que tem média 0 e desvio padrão 1.5. Observa-se, como mencionado, que modificando os parâmetros da curva, altera-se a posição ou o formato da curva. curve (dnorm (x, mean=0, sd=1), col=&quot;dodgerblue3&quot;, lty=1, lwd=2, ylim = c(0, 0.4), xlim = c(-4.5, 4.5), ylab = &quot;Densidade&quot;, xlab = &quot;X&quot;, bty = &quot;n&quot;) box(bty = &quot;L&quot;) abline (v= 0, lwd = 1, lty = 2, col = &quot;dodgerblue3&quot;) curve (dnorm (x, mean=0, sd=1.5), col=&quot;darkolivegreen3&quot;, lty=1, lwd=2, add=T) curve (dnorm (x, mean=1.5, sd=1), col=&quot;firebrick3&quot;, lty=1, lwd=2, add=T) abline (v= 0, lwd = 1, lty = 2, col = &quot;firebrick3&quot;) Figure 7.3: Curvas normais com modificação dos parâmetros. 7.6.1 Características da distribuição normal A curva normal apresenta as seguintes características: A média e o desvio padrão descrevem exatamente uma distribuição normal, eles são chamados de parâmetros da distribuição. Se uma distribuição normal tem média \\(\\mu\\) e desvio padrão \\(\\sigma\\), pode-se escrever a distribuição como \\(N (\\mu,\\sigma)\\). As três distribuições do gráfico anterior. podem ser escritas como: \\[ N(\\mu = 0,\\sigma = 1) \\quad, N(\\mu = 0,\\sigma = 1.5) \\quad e \\quad N(\\mu = 1.5,\\sigma = 1) \\] Na distribuição normal, a média, a mediana e a moda coincidem. A curva normal é simétrica em torno da média (\\(\\mu\\)). As extremidades da curva, em ambos os lados da média, se estendem cada vez mais próximas do eixo x (abscissa) sem jamais tocá-lo. É assintótica. Os pontos de inflexão da curva são \\(\\mu - \\sigma\\) e \\(\\mu + \\sigma\\). A área total sob a curva é 1 ou 100%. 7.6.2 Distribuição normal padronizada Cada variável aleatória contínua tem a sua média e seu desvio padrão e, portanto, a sua curva normal correspondente. Para facilitar a comparação entre variáveis, foi criado o conceito de curva normal padronizada, que é uma curva normal com média 0 e desvio padrão 1. A distribuição normal padrão também pode ser chamada de distribuição normal centrada ou reduzida. Para calcular probabilidades associadas a distribuição normal, costuma-se converter a variável aleatória original X, em unidades reduzidas ou padronizadas, denominadas de escore Z. Esta transformação é realizada pela equação que indica o número de desvios padrão envolvidos no afastamento do valor x em relação à média: \\[ z =\\frac{x-\\mu}{\\sigma} \\] onde: z \\(\\longrightarrow\\) escore z x \\(\\longrightarrow\\) valor qualquer da variável aleatória X \\(\\mu\\) \\(\\longrightarrow\\) média da variável X \\(\\sigma\\) \\(\\longrightarrow\\) desvio padrão da variável X Qualquer distribuição de uma variável aleatória normal pode ser padronizada, usando o escore z. Isto permite que se calcule a probabilidade de se encontrar determinados intervalos de valores (86). A altura das puérperas do conjunto de dados dadosMater.xlsx tem as seguintes medidas resumidoras: mater &lt;- readxl::read_excel(&quot;Arquivos/dadosMater.xlsx&quot;) %&gt;% select(altura) %&gt;% dplyr::summarise(n = n(), media = mean(altura, na.rm = TRUE), dp = sd(altura, na.rm = TRUE), min = min(altura, na.rm = TRUE), max = max(altura, na.rm = TRUE)) mater ## # A tibble: 1 × 5 ## n media dp min max ## &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1368 1.60 0.0655 1.4 1.85 Desta forma, pode-se verificar quantos desvios padrão uma mulher que mede 1,725m, pertencente a esta população, está afastada da média de 1.598m. Assim: z &lt;- (1.725 - mater$media)/mater$dp z ## [1] 1.940054 Esta mulher está distante praticamente 2 desvios padrão acima da média da sua população. Portanto, ela é considerada alta. Por que? Para responder a essa pergunta, há necessidade de calcular a probabilidade de encontrar uma mulher com esta altura, nesta população. No R, existem as funções dnorm(), pnorm() e qnorm(), que permitem calcular a densidade de probabilidade, distribuição cumulativa e função quantílica da distribuição normal para um conjunto de valores. Além disso, a função rnorm() permite obter observações aleatórias que seguem uma distribuição normal (87). Função pnorm() A função pnorm() fornece a Função de Distribuição Cumulativa (CDF) da distribuição Normal, que é a probabilidade de que a variável X contenha um valor menor ou igual a x. Sintaxe: pnorm(q, mean = 0, sd = 1, lower.tail = TRUE) Argumentos: q \\(\\longrightarrow\\) vetor de quantis mean \\(\\longrightarrow\\) média sd \\(\\longrightarrow\\) desvio padrão lower.tail \\(\\longrightarrow\\) Se TRUE, as probabilidades são (\\(P \\le x\\)), caso contrário \\(P(X &gt; x)\\) Se for usado \\(mean = 0\\) e \\(sd = 1\\), o valor de q = z, caso contrário, toma-se os valores da média, o desvio padrão da população e o valor de x. Com esta função pode-se responder a pergunta feita anteriormente em relação a probabilidade de encontrar uma mulher com mais de 1,725m, equivalente a 1.9400545 desvios padrão acima da média, em uma população com média = 1.5979678 e desvio padrão = 0.0654787. p &lt;- pnorm(z, mean = 0, sd = 1, lower.tail = FALSE) p ## [1] 0.02618654 Ou, usando os valores: pnorm(1.725, mean = mater$media, sd = mater$dp, lower.tail = FALSE) ## [1] 0.02618654 Observa-se que, nesta população, apenas 2.6% das mulheres têm acima de 1,725m, razão de considerar-se uma mulher acima deste valor como sendo alta. Ou seja, é pouco provável encontrar mulheres acima dessa altura, nesta população. A Figura 7.4 representa com clareza esta pequena probabilidade. source(&quot;Arquivos/normal_area.R&quot;) normal_area(media = 0, dp = 1, linf = 1.94, lsup = 3, cor = &quot;tomato&quot;, lwd = 2 ) text(2.6, 0.05, &quot;2.6%&quot;) Figure 7.4: Probabilidade de encontrar mulheres com mais de 1,725m A função normal_area() é uma função criada para desenhar a uma curva normal com a área da probabilidade desejada colorida. Ela pode ser obtida aqui e baixada no seu diretório. Foi usada a função text() para escrever o valor da probabilidade. Função qnorm() A função qnorm() permite encontrar o quantil (percentil) q para qualquer probabilidade p. Portanto, a função qnorm é o inverso da função pnorm. A sintaxe do qnorm é a seguinte: Sintaxe qnorm(p, mean = 0, sd = 1, lower.tail = TRUE) Argumentos: p \\(\\longrightarrow\\) vetor de probabilidades mean \\(\\longrightarrow\\) média sd \\(\\longrightarrow\\) desvio padrão lower.tail \\(\\longrightarrow\\) Se TRUE, as probabilidades são (\\(P \\le x\\)), caso contrário \\(P(X &gt; x)\\) No exemplo anterior, a probabilidade de se encontrar mulheres, na maternidade, com mais de 1,725m foi de 2.6%. Poderia ser calculado com a função qnorm() qual o escore z correspondente: qnorm(p, mean = 0, sd = 1, lower.tail = FALSE) ## [1] 1.940054 Outro exemplo, na mediana (p = 0,5), o escore z é igual a: qnorm(0.50, mean = 0, sd = 1) ## [1] 0 Função dnorm() Essa função retorna o valor da função de densidade de probabilidade (pdf) da distribuição normal dada uma certa variável aleatória X, uma média populacional \\(\\mu\\) e o desvio padrão populacional \\(\\sigma\\). Sintaxe dnorm(x, mean = 0, sd = 1) Argumentos: x \\(\\longrightarrow\\) vetor de quantis mean \\(\\longrightarrow\\) média sd \\(\\longrightarrow\\) desvio padrão Embora x represente a variável independente da pdf para a distribuição normal, também é útil pensar em x como um escore z. Por exemplo, a densidade de probabilidade quando x = 0 é igual: dnorm(x = 0, mean = 0, sd = 1) ## [1] 0.3989423 Agora, para melhor comprenssão, será mostrado o que foi dito, representando a função de densidade de probabilidade da distribuição normal com o dnorm(). Inicialmente, será construído um vetor de escores z: escores_z &lt;- seq(-3,3, by = 0.1) escores_z ## [1] -3.0 -2.9 -2.8 -2.7 -2.6 -2.5 -2.4 -2.3 -2.2 -2.1 -2.0 -1.9 -1.8 -1.7 -1.6 ## [16] -1.5 -1.4 -1.3 -1.2 -1.1 -1.0 -0.9 -0.8 -0.7 -0.6 -0.5 -0.4 -0.3 -0.2 -0.1 ## [31] 0.0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0 1.1 1.2 1.3 1.4 ## [46] 1.5 1.6 1.7 1.8 1.9 2.0 2.1 2.2 2.3 2.4 2.5 2.6 2.7 2.8 2.9 ## [61] 3.0 Um objeto, valores_d, receberá os valores das densidades de probabilidade gerados com a função dnorm(), usando os escores_z: valores_d &lt;- dnorm(escores_z, mean = 0, sd = 1) Estes valores serão plotados para construir a curva normal (Figura 7.5): plot(valores_d, type = &quot;l&quot;, # Tipo de gráfico em linha lwd = 2, # Espessura da linha 2x padrão col = &quot;steelblue&quot;, # Cor da linha xaxt = &quot;n&quot;, # Eixo x sem rótulos ylab = &quot;Densidade de Probabilidade&quot;, xlab = &quot;Escores z&quot;) # Rótulos do eixo x axis(1, at = which(valores_d == dnorm(0)), labels = c(0)) axis(1, at=which(valores_d == dnorm(1)), labels=c(-1, 1)) axis(1, at=which(valores_d == dnorm(2)), labels=c(-2, 2)) axis(1, at=which(valores_d == dnorm(3)), labels=c(-3, 3)) Figure 7.5: Função densidade de probabilidade. Como se pode ver, dnorm() fornece a “altura” do pdf da distribuição normal em qualquer escore z que se forneça como argumento. Função rnorm() A função rnorm() gera n números aleatórios com distribuição normal com média \\(\\mu\\) e desvio padrão \\(\\sigma\\). A sintaxe da função rnorm() no R é a seguinte: Sintaxe: qnorm(n, mean = 0, sd = 1) Argumentos: n \\(\\longrightarrow\\) número de observações a serem geradas mean \\(\\longrightarrow\\) média sd \\(\\longrightarrow\\) desvio padrão Com esta função é possível, por exemplo, gerar 10 observações de uma distribuição normal: rnorm(10) ## [1] 0.015305388 -0.272723667 -0.908691508 0.197587988 -0.517940153 ## [6] -1.667928545 0.008352216 -0.626068881 0.582384366 -1.892057041 No entanto, deve-se notar que, se não especificar uma “semente” (seed), a saída não será reproduzível: rnorm(10) ## [1] 0.3290992 0.4568480 -0.8792838 1.5159664 -0.5204036 -0.1960757 ## [7] -1.9630947 1.2378553 0.7286831 -0.2606930 Pode-se usar a função set.seed() para tornar o código reproduzível. O valor da “semente” (número) não é importante desde que seja consistente na sua utilização. O que é verdadeiramente importante é que o código seja reproduzido fielmente. Para ilustrar, será construído dois conjuntos de 10 números que serão recebidos pelos objetos x e y. Para gerar o conjunto de números x, sera usado o número 123 como “semente”. A “semente” funciona como uma espécie de marca. Para o y não será usado a set.seed(). n &lt;- 10 set.seed (123) x &lt;- rnorm (n) x ## [1] -0.56047565 -0.23017749 1.55870831 0.07050839 0.12928774 1.71506499 ## [7] 0.46091621 -1.26506123 -0.68685285 -0.44566197 y &lt;- rnorm(n) y ## [1] 1.2240818 0.3598138 0.4007715 0.1106827 -0.5558411 1.7869131 ## [7] 0.4978505 -1.9666172 0.7013559 -0.4727914 Comparando os conjuntos com a função identical() do R base, observa-se que os conjuntos são diferentes: identical(x, y) ## [1] FALSE Agora, repetindo os mesmos comandos, mas usando antes a mesma “semente”: set.seed (123) x &lt;- rnorm (n) x ## [1] -0.56047565 -0.23017749 1.55870831 0.07050839 0.12928774 1.71506499 ## [7] 0.46091621 -1.26506123 -0.68685285 -0.44566197 set.seed (123) y &lt;- rnorm(n) y ## [1] -0.56047565 -0.23017749 1.55870831 0.07050839 0.12928774 1.71506499 ## [7] 0.46091621 -1.26506123 -0.68685285 -0.44566197 identical(x, y) ## [1] TRUE Observa-se que, agora, tem-se conjuntos idênticos. Agora, para usar rnorm(), serão gerados três vetores diferentes de números aleatórios de uma distribuição normal. set.seed(1234) n10 &lt;- rnorm(10, mean = 0, sd = 1) n100 &lt;- rnorm(100, mean = 0, sd = 1) n10000 &lt;- rnorm(10000, mean = 0, sd = 1) A seguir, serão construídos histogramas (Figura 7.6), onde se pode observar que, aumentando o número de observações, tem-se gráficos que irão progressivamente se aproximando da verdadeira função de densidade normal. # Este comando coloca os gráficos em uma mesma linha, o argumento mfrow(c(1,3)) diz ao R para construir uma linha e três colunas: par(mfrow=c(1,3)) # Histogramas hist(n10, breaks = 5, main = &quot;n =10&quot;, ylab = &quot;Frequência&quot;) hist(n100, breaks = 20, main = &quot;n =100&quot;, ylab = &quot;Frequência&quot;) hist(n10000, breaks = 50, main = &quot;n =10000&quot;, ylab = &quot;Frequência&quot;) Figure 7.6: Histogramas construídos com amostras geradas pela função rnorm. # Restaura as configurações basais de plotagem par(mfrow=c(1,1)) 7.6.3 Regra Empírica 68-95-99.7 A regra empírica diz que, se uma população de um conjunto de dados tem uma distribuição normal com média 0 e desvio padrão 1 (X ~ Norm (0,1)) pode-se afirmar que aproximadamente, 68%, 95% e 99,7% dos valores encontram-se, respectivamente, dentro de \\(\\pm\\) 1, 2 e 3 desvio padrão acima e abaixo média. Esta regra pode ser usada para descrever uma população e ajudar a decidir se uma amostra de dados veio de uma distribuição normal. Se uma amostra é grande o suficiente e a observação do histograma tem um formato parecido com um sino, é possível verificar se os dados seguem as especificações 68-95-99,7%. Se sim, é razoável concluir que os dados vieram de uma distribuição normal. Usando a amostra dos recém-nascidos a termo da maternidade-escola do Hospital Geral de Caxias do Sul e for observado o histograma com uma curva normal sobreposta, tem-se # Selecionando os recém-nascidos a termo mater &lt;- readxl::read_excel(&quot;Arquivos/dadosMater.xlsx&quot;)%&gt;% filter(ig &gt;= 37 &amp; ig &lt; 42) # Média dos pesos dos recém-nascidos a termo media &lt;- mean(mater$pesoRN, na.rm =TRUE) media ## [1] 3216.316 # Desvio padrão dos pesos dos recém-nascidos a termo dp &lt;- sd(mater$pesoRN, na.rm =TRUE) dp ## [1] 462.1205 Figure 7.7: Histograma com curva normal sobreposta e pode-se aceitar que a distribuição é aproximadamente normal (Figura 7.7). Consequentemente, 68% desses bebês pesam entre 2754.2 e 3678.4g (média \\(\\pm\\) 1 desvio padrão). As linhas verticais tracejadas são apenas para melhorar a visualização, pois não se necessita, praticamente, de nenhum cálculo. 7.6.4 Exercitando o raciocínio com a curva normal Suponha-se que em uma determinada região existam duas populações etnicamente diferentes onde as mulheres têm as seguintes medidas de altura: população 1 tem \\(\\mu\\) = 160 cm e \\(\\sigma\\) = 6,6 cm e a população 2 tem \\(\\mu\\) = 139 cm e \\(\\sigma\\) = 6,6 cm. Essas duas populações vivem misturadas e têm o mesmo aspecto físico, podendo ser distinguidas apenas geneticamente. A qual população pertence uma mulher de 150 cm? Probabilidade de pertencer à População 1 x &lt;- 150 mu1 &lt;- 160 sigma1 &lt;- 6.6 z1 &lt;- (x - mu1)/sigma1 z1 ## [1] -1.515152 p1 &lt;- pnorm (z1) p1 ## [1] 0.06486702 Ou seja, na população 1, apenas 6.5% das mulheres tem altura abaixo de 1,50, 93.5% é mais alta do que este valor. Probabilidade de pertencer à População 2 x &lt;- 150 mu2 &lt;- 140 sigma2 &lt;- 6.6 z2 &lt;- (x - mu2)/sigma2 z2 ## [1] 1.515152 p2 &lt;- pnorm (z2) p2 ## [1] 0.935133 Na população 2, 6.5% das mulheres têm altura acima de 150 cm. Este valor valor está 1.52 desvios padrão distante da média. Isto significa que se ela pertencesse a população 2, ela seria considerada alta, quer dizer, praticamente 93.5% das mulheres desta população são menores do que ela. No gráfico abaixo, pode-se visualizar a posição de uma mulher de 1,50 m (linha vermelha tracejada) em relação às duas populações (Figura 7.8). Figure 7.8: Posição de uma mulher com 1,50m comparando duas populações Concluindo, ela pode pertencer a qualquer uma das populações. Pode ser uma mulher alta da população 2 ou uma “baixinha” da população 1! Usando as populações do exercício 1, qual a probabilidade de se encontrar mulheres, em qualquer das populações, abaixo do escore z -1.96? pnorm (-1.96) ## [1] 0.0249979 Usando as populações do exercício 1, qual a probabilidade de se encontrar mulheres, em qualquer das populações, acima do escore z 1.96? pnorm (1.96, lower.tail = FALSE) ## [1] 0.0249979 Em outras palavras, se forem observadas as respostas das perguntas 2 e 3, chega-se a conclusão que entre os escores z -1,96 e 1,96 encontram-se 95% das mulheres de qualquer população cujo parametro tem distribuição normal. Na “regra empírica 68-95-99.7” usou-se o valor de 1,96 arredondado para 2. Qual é o escore z do 50º percentil da distribuição normal? qnorm (0.50) ## [1] 0 Qual o escore z para o 97,5º percentil da distribuição normal? qnorm (0.975) ## [1] 1.959964 7.7 Distribuição Binomial A distribuição normal padrão é apenas um dos exemplos de distribuição de probabilidade. Uma boa parte das situações se ajustam a ela. Entretanto, diversas situações reais muitas vezes se aproximam de outras distribuições estocásticas definidas por algumas hipóteses. Daí a importância de se conhecer e manipular algumas destas distribuições. Entre elas, a distribuição binomial. Quando um experimento aleatório resulta em um de dois, mutuamente exclusivos, desfechos, tais como vivo/morto, positivo/negativo, sim/não, masculino/feminino é denominado de Ensaio de Bernoulli. Recebeu esta denominação em homenagem ao matemático suíço, Jacob Bernoulli (1654-1705), considerado fundador do cálculo e da teoria da probabilidade (88). A distribuição de frequências que descreve as proporções de um ensaio de Bernoulli, chama-se Distribuição Binomial. A probabilidade binomial dá a probabilidade de determinado desfecho ocorrer em determinado número de ensaios independentes. Uma sequência de ensaios de Bernoulli forma um Processo de Bernoulli. A distribuição binomial é importante para variáveis discretas. Existem poucas condições que precisam ser atendidas antes se considere uma variável aleatória para distribuição binomial: Cada ensaio resulta em um de dois desfechos, mutuamente exclusivos, denominados, arbitrariamente, de sucesso e fracasso; A probabilidade de sucesso é fixa, igual a p, constante em cada ensaio, e a probabilidade de fracasso é igual a 1 – p; O número de repetições n em um ensaio é fixo. Os ensaios são independentes A distribuição binomial é na verdade uma família de distribuições, cujos membros são definidos pelos valores de n e p (parâmetros da distribuição binomial). A probabilidade de sucesso 11, em uma distribuição binomial, é dada pela fórmula: \\[ P(X = x)= C \\times p^x \\times (1 - p)^{n-x} \\] onde n = ensaios, x = sucessos, p = probabilidade de um sucesso e C representa o número possível de combinações em um ensaio. O número de combinações, C de x sucessos entre n repetições podem ser computado pela fórmula: \\[ C = \\frac{n!}{x!(n - x)!} \\] ou, no R, com a função choose (n, x). O modelo de distribuição binomial trata de encontrar a probabilidade de sucesso de um evento que tem apenas dois resultados possíveis em uma série de experimentos. Usando dados de uma distribuição binomial, é possível calcular os valores esperados de uma variável aleatória conforme ela passa por tentativas independentes. Em outras palavras, é possível prever o número exato de caras ou coroas que se deve esperar ao jogar uma moeda um certo número de vezes. Também, pode-se usar a probabilidade binomial cumulativa para encontrar a probabilidade de obter um determinado intervalo de resultados. Por exemplo, saber a probabilidade do nascimento de até três meninos em 10 nascimentos consecutivos quando a probabilidade de nascer um menino é 0,50. O R tem quatro funções embutidas para gerar distribuição binomial. Ela são descritas a seguir. Função pbinom() Esta função retorna o valor da função de densidade cumulativa (cdf) da distribuição binomial dada uma certa variável aleatória q, número de tentativas (size) e probabilidade de sucesso em cada tentativa (prob). Sintaxe: pbinom(q, size, prob, lower.tail = TRUE) Argumentos: q \\(\\longrightarrow\\) vetor de quantis size \\(\\longrightarrow\\) numero de ensaios prob \\(\\longrightarrow\\) probabilidade de sucesso em cada ensaio lower.tail \\(\\longrightarrow\\) Se TRUE, as probabilidades são (\\(P \\le x\\)), caso contrário \\(P(X &gt; x)\\) Por exemplo, qual é a probabilidade de nascer até três meninos em cinco nascimentos, sabendo que a probabiliade de nascer um menino é igual a 0.50? pbinom (3, 5, 0.50) ## [1] 0.8125 Isso corresponde a soma das probabilidades de nascer nenhum menino, um menino, dois meninos e três meninos (Figura 7.9). Isto é calculado pela equação \\(P(X = x)\\), vista anteriormente: n = 5 p = 0.50 x &lt;- 0:5 # Probabilidades de meninos Fx &lt;- (factorial(n)/(factorial(x)*factorial(n-x)))* p^x *(1-p)^(n-x) Fx ## [1] 0.03125 0.15625 0.31250 0.31250 0.15625 0.03125 Figure 7.9: Distribuição binomial, mostrando a P (x &lt; 4) com n = 5 e p = 0.50 ## [1] 0.8125 Função qbinom() Esta função retorna o valor da função de densidade cumulativa inversa (cdf) da distribuição binomial dada uma certa variável aleatória q, número de tentativas (size) e probabilidade de sucesso em cada tentativa (prob). Com o uso desta função, podemos descobrir o quantil da distribuição binomial. Sintaxe: qbinom(p, size, prob, lower.tail = TRUE) Argumentos: p \\(\\longrightarrow\\) probabilidade ou vetor de probabilidades size \\(\\longrightarrow\\) numero de ensaios prob \\(\\longrightarrow\\) probabilidade de sucesso em cada ensaio lower.tail \\(\\longrightarrow\\) Se TRUE, as probabilidades são (\\(P \\le x\\)), caso contrário \\(P(X &gt; x)\\) Por exemplo, quantos meninos nascerão em 5 partos com 81.25% de probabilidade cumulativa? qbinom (0.8125, size = 5, prob = 0.50) ## [1] 3 Função rbinom() A função rbinom() permite extrair n observações aleatórias de uma distribuição binomial. Os argumentos da função são descritos abaixo: Sintaxe: qbinom(n, size, prob) Argumentos: n \\(\\longrightarrow\\) número de observações aleatórias a ser gerado size \\(\\longrightarrow\\) numero de ensaios prob \\(\\longrightarrow\\) probabilidade de sucesso em cada ensaio Se há necessidade de fazer uma simulação de 1000 amostras aleatoriamente, de tamanho 5 e a probabilidade de nascer menino (0,50): menino &lt;- rbinom(n = 1000, size = 5, prob = 0.5) mean(menino) ## [1] 2.536 No entanto, se não for especificado uma “semente” (seed) antes de executar a função, será obtido um conjunto diferente de observações aleatórias a cada execução e , portanto, a média a cada execução será diferente. Para tornar a saída reproduzível, pode-se definir uma “semente” da seguinte maneira: set.seed(23) menino &lt;- rbinom(n = 1000, size = 5, prob = 0.5) mean(menino) ## [1] 2.515 Quanto maior o número de variáveis aleatória criadas, mais próximo a média do número de sucessos estará do número esperado de sucessos que é igual ao número de sucessos vezes a probabilidade de sucesso em cada ensaio (2.5) Função dbinom() Essa função retorna o valor da função de densidade de probabilidade (pdf) da distribuição binomial dada uma determinada variável aleatória X, número de tentativas (size) e probabilidade de sucesso em cada tentativa (prob). A função tem a seguinte sintaxe: Sintaxe: dbinom(x, size, prob) Argumentos: x \\(\\longrightarrow\\) vetor de números size \\(\\longrightarrow\\) numero de ensaios prob \\(\\longrightarrow\\) probabilidade de sucesso em cada ensaio A função é usada para encontrar a probabilidade de um determinado valor para dados que seguem a distribuição binomial, ou seja, encontra P(X=x), probabilidade de x sucessos em tentativas de tamanho (size) n quando a probabilidade (p) de sucesso é prob. Obtém o mesmo resultado da fórmula: \\[ P(X = x)= C \\times p^x \\times (1 - p)^{n-x} \\] Por exemplo, no nascimento de uma criança, as duas possibilidades, menino ou menina, são mutuamente excludentes e esses são os únicos eventos que podem acontecer. A probabilidade de nascimento de menino, como visto, é 0,50, qual seria a probabilidade de nascerem 4 meninos em 5 partos consecutivos (Figura 7.10)? dbinom(4, size = 5, prob = 0.50) ## [1] 0.15625 # Probabilidades de nascer meninos em 5 nascimentos Fx &lt;- dbinom(0:5, 5, 0.50) Fx ## [1] 0.03125 0.15625 0.31250 0.31250 0.15625 0.03125 Figure 7.10: Distribuição binomial para P (x = 4) com n = 5 e p = 0,50 7.7.1 Média e desvio padrão da distribuição binomial Quando o número de repetições é grande, geralmente há necessidade de resumir as probabilidades. A distribuição binomial pode ser descrita por sua média e variância. A média é o valor médio da variável aleatória em um longo número de repetições. É também chamada de valor esperado ou expectativa. A expectativa de uma variável aleatória X, geralmente, é denotada por \\(E(X)\\) e obtida pela multiplicação do número de ensaios independentes (n) pela probabilidade (p) de sucesso em cada ensaio: \\[ \\mu = E(X) = n \\times p \\] Portanto, a expectativa (esperança) de nascimento de meninos em 5 partos é \\(E(X)=5 \\times 0,50 = 2,5\\), como visto na função rbinom(). Observe que o valor esperado de uma variável aleatória discreta não tem um valor que a variável aleatória pode realmente assumir. Por exemplo, para o número médio de meninos em um parto, ou não se tem menino ou se tem 1 menino, cada uma possibilidade com probabilidade de 0,50 e o valor esperado é (0 × 0,50) + (1 × 0,50) = 0,50. O número de meninos deve ser 0 ou 1, mas o valor esperado é a metade, a média que se obteria no longo prazo. A variância de uma variável aleatória discreta X é igual a \\[ \\sigma^2=var(X) = n\\times p \\times (1-p) \\] Consequentemente, o desvio padrão é igual a \\[ \\sigma = \\sqrt{var(X)} = \\sqrt{n\\times p \\times (1-p)} \\] Para o exemplo de 5 nascimentos, a média foi de 2,5 meninos e o desvio padrão \\[ \\sigma =\\sqrt{5\\times 0.50 \\times (1-0.50)}=\\sqrt{2.5 \\times 0.50}= 1.12 \\] Portanto, se espera que ocorram em média 2,5 (\\(\\sigma\\) = 1,12) nascimentos de meninos em 5 partos. 7.8 Distribuição de Poisson A distribuição de Poisson é utilizada para descrever a probabilidade do número de ocorrências em um intervalo contínuo (de tempo ou espaço). No caso da distribuição binomial, a variável de interesse é o número de sucessos em um intervalo discreto (n ensaios de Bernoulli). A unidade de medida (tempo ou espaço) é uma variável contínua, mas a variável aleatória, o número de ocorrências, é discreta. Esta distribuição segue as mesmas premissas da distribuição binomial: as tentativas são independentes; a variável aleatória é o número de eventos em cada amostra; a probabilidade é constante em cada intervalo Ela é utilizada para modelar eventos discretos que ocorrem com pouca frequência no tempo ou espaço, por isso é algumas vezes denominada de distribuição de eventos raros. Pode-se usar a distribuição de Poisson como uma aproximação da distribuição Binomial quando n, o número de tentativas, for grande e p ou (1 – p) for pequeno (eventos raros). Um bom princípio básico é usar a distribuição de Poisson quando \\(n \\ge 20\\) e \\(n \\times p\\) ou \\(n \\times (1- p)\\) &lt; 5% (89). Nessas condições, a probabilidade que uma variável aleatória X adote um valor x é \\[ P(X = x) = \\frac {e^{-\\lambda} \\times \\lambda^x}{x!} \\] onde \\(\\lambda\\) (lambda) representa o número de ocorrências de um evento em um intervalo de tempo e é conhecida como parâmetro da distribuição de Poisson e é igual em média a \\(n \\times p\\). No R, essa probabilidade é dada pela função dpois(x, lambda). Exemplo: Suponha que a probabilidade de uma puérpera ter infecção congênita (rubéola) seja igual a 0,0009. Qual seria a probabilidade, em uma população de 6000 gestantes, de que 5 estejam infectadas? p &lt;- 0.0009 x &lt;- 5 n &lt;- 6000 lambda &lt;- n * p P &lt;- dpois(x, lambda) round (P, 3) ## [1] 0.173 Portanto, a probabilidade de se encontrar 5 mulheres com infecção congênita é de aproximadamente 17%. Sucesso, aqui, não está no sentido de vitória, êxito, triunfo, glória e sim como obter o desfecho esperado. Por exemplo, se uma moeda é lançada e se espera obter cara, sucesso significa um resultado igual a cara.↩︎ "],["assimetria-e-curtose.html", "Capítulo 8 Assimetria e Curtose 8.1 Assimetria 8.2 Curtose 8.3 Testando o raciocínio", " Capítulo 8 Assimetria e Curtose 8.1 Assimetria A assimetria analisa a proximidade ou o afastamento de um conjunto de dados quantitativos em relação à distribuição normal. Mede o grau de afastamento de uma distribuição em relação a um eixo central (geralmente a média). Quando a curva é simétrica, a média, a mediana e a moda coincidem, num mesmo ponto, havendo um perfeito equilíbrio na distribuição. Quando o equilíbrio não acontece, isto é, a média, a mediana e a moda recaem em pontos diferentes da distribuição esta será assimétrica; enviesada a direita ou esquerda. podendo-se caracterizar como curvas assimétricas à direita ou à esquerda. Quando a distribuição é assimétrica à esquerda ou assimetria negativa, a cauda da curva localiza-se à esquerda, desviando a média para este lado (Figura 8.1). Na assimetria positiva, ocorre o contrário, a cauda está localizada à direita e da mesma forma a média (90). Figure 8.1: Assimetria O R dispões de diversas maneiras para o cálculo do coeficiente de assimetria (g1). O coeficiente de assimetria é um método numérico estatístico para medir a assimetria da distribuição ou conjunto de dados. Ele fala sobre a posição da maioria dos valores de dados na distribuição em torno do valor médio. Quando a \\(assimetria = 0\\), tem-se uma distribuição simétrica e a média, a mediana e a moda coincidem; quando a \\({assimetria} &lt; {0}\\), \\({média} &lt; {mediana} &lt; {moda}\\), a distribuição tem assimetria negativa e quando a \\({assimetria} &gt; {0}\\), \\({média} &gt; {mediana} &gt; {moda}\\), a distribuição tem assimetria positiva. A Tabela 8.1 sugere uma forma de interpretar o coeficiente de assimetria (91). Table 8.1: Interpretação do g1 g1 Assimetria -1 a +1 leve -1 a -2 e +1 a +2 moderada -2 a -3 e +2 a +3 importante &lt; -3 ou &gt; +3 grave Como exemplo, de avaliação do coeficiente de assimetria, será usada a distribuição da variável altura, correspondente a altura em metros de 1368 parturientes da Maternidade do HGCS (dadosMater.xlsx), já mostrado anteriormente (Figura 6.15), repetido aqui com um boxplot sobreposto (Figura 8.2): # Dados mater &lt;- readxl::read_excel(&quot;Arquivos/dadosMater.xlsx&quot;) # Estruturação do layout do gráfico layout(matrix(c(1,2), nrow = 2 , ncol =1, byrow = TRUE), heights = c(1, 8)) # Boxplot par (mar=c (0, 4.3, 1.1, 2)) boxplot (mater$altura, horizontal = TRUE, ylim = c (1.4, 1.9), xaxt = &quot;n&quot;, col = &quot;lightblue&quot;, frame = FALSE) #Histograma par (mar=c (4, 4.3, 1.1, 2)) hist (mater$altura, breaks=15, col = &quot;lightblue&quot;, border = &quot;black&quot;, main = &quot;&quot;, xlab = &quot;Altura das Puérperas (m)&quot;, ylab = &quot;Frequência&quot;, xlim = c(1.4,1.9), las = 1) box(bty = &quot;L&quot;) Figure 8.2: Posição de uma mulher com 1,50m comparando duas populações # Restauração do padrão par (mar = c(5, 4, 4, 2) + 0.1) Observando o formato da distribuição no histograma e do boxplot, conclui-se que a variável altura tem uma assimetria positiva, provocada por alguns outliers, como uma mulher com altura de 1,85m. Para examinar os outliers, pode-se verificar as estatísticas do boxplot, que entregam as estatísticas dos 5 números (min, P25, mediana, P75 e max), o total de observações, o limite inferior e superior do intervalo de confiança de 95% e os valores aípicos (outliers): boxplot.stats(mater$altura) ## $stats ## [1] 1.42 1.55 1.60 1.65 1.78 ## ## $n ## [1] 1368 ## ## $conf ## [1] 1.595728 1.604272 ## ## $out ## [1] 1.40 1.82 1.80 1.40 1.40 1.85 1.80 O formato formato dos dados se ajusta bem, como visto na Figura 8.2, ao modelo normal e os pressupostos deste modelo poderiam ser aplicados a estes dados. O valor da assimetria (skewness) pode ser obtida com a função skewness() do pacote moments (92). moments::skewness(mater$altura) ## [1] 0.1812196 O resultado da saída, confirmam a impressão visual, a variável altura tem uma distribuição praticamente simétrica. Esta conclusão tambem pode ser feita, analisando as medidas resumidoras dessa variável: media &lt;- mean(mater$altura, na.rm = TRUE) round(media, 2) ## [1] 1.6 dp &lt;- sd(mater$altura, na.rm = TRUE) round(dp,3) ## [1] 0.065 mediana &lt;- median (mater$altura, na.rm = TRUE) mediana ## [1] 1.6 coefVar &lt;- dp/media round(coefVar, 3) ## [1] 0.041 Os resultados mostram um desvio padrão pequeno, média igual à mediana e um coeficiente de variação igual a 0.041, muito próximo de 0, características consideradas pertencentes a uma amostra que provavelmente se ajusta à distribuição normal. 8.2 Curtose É o grau de achatamento de uma distribuição, em relação a distribuição normal. A curtose indica como o pico e as caudas de uma distribuição diferem da distribuição normal. A assimetria mede essencialmente a simetria da distribuição, enquanto a curtose determina o peso das caudas da distribuição. Portanto, é uma medida dos tamanhos combinados das duas caudas; mede a quantidade de probabilidade nas caudas. Uma curtose em excesso é uma medida que compara a curtose de uma distribuição com a curtose de uma distribuição normal. A curtose de uma distribuição normal é igual a 3. Portanto, o excesso de curtose é determinado subtraindo 3 da curtose: \\[ Excesso \\space de \\space curtose = curtose - 3 \\] Os dados que seguem uma distribuição mesocúrtica mostram um excesso de curtose de zero ou próximo de zero. Isso significa que se os dados seguem uma distribuição normal, eles seguem uma distribuição mesocúrtica. A distribuição leptocúrtica mostra caudas pesadas em ambos os lados, indicando grandes valores discrepantes. Uma distribuição leptocúrtica manifesta uma curtose excessiva positiva. Uma distribuição platicúrtica mostra uma curtose excessiva negativa, revela uma distribuição com cauda plana (Figura 8.3). Figure 8.3: Assimetria A função kurtosis(), também do pacote moments, pode ser usada para o cálculo do coeficiente de curtose e do resultado deve-se subtrair o valor 3. moments::kurtosis(mater$altura) ## [1] 3.124257 Se o coeficiente de curtose é maior do que 3, há um excesso de curtose e a distribuição dos dados é leptocúrtica com um pico mais acentuado no gráfico. O resultado do exemplo aponta para uma distribuição leptocúrtica, pois existe um pequeno excesso de curtose (moments::kurtosis(mater$altura) - 3). Quando o coeficiente de curtose é menor do que 3, a distribuição é platicúrtica e a curva fica mais achatada. Quando o coeficiente de curtose é igual a 3, ou próximo de 3, a distribuição é mesocúrtica, como a distribuição normal. 8.3 Testando o raciocínio Criar um conjunto de dados com distribuição normal com média 0 e desvio padrão 1 e n = 100000 # Criação da variável n100000 n100000 &lt;- rnorm(100000, mean = 0, sd = 1) Construa um histograma (Figura 8.4) com curva normal sobreposta: library(ggplot2) ggplot() + geom_histogram(aes(x = n100000, y =..density..), bins = 20, fill=&#39;tomato&#39;, col=alpha(&#39;red&#39;,0.2)) + geom_function(fun=dnorm, args=list(mean=0,sd=1), col=&#39;dodgerblue4&#39;, lwd=1, lty=2) + labs(x=&#39;X&#39;, y=&#39;Densidade de probabilidade&#39;, caption = &quot;PFOF&quot;)+ theme_bw() Figure 8.4: Histograma com curva normal Observe a skewness e a kurtosis print(moments::skewness(n100000)) ## [1] 0.0007816012 print(moments::kurtosis(n100000)) ## [1] 3.032317 Como era de se esperar, usando a rnorm(), a distribuição é um exemplo de distribuição normal, \\(skewness \\approx 0\\) e \\(kurtosis \\approx 3\\). Observe que a cada vez que os comandos forem executados, os resultados serão discretamente diferentes. Para evitar isso, deve-se usar set.seed(), veja a seção 7.6.2. Faça o teste! "],["distribuições-amostrais.html", "Capítulo 9 Distribuições Amostrais 9.1 Pacotes necessários para este capítulo 9.2 Distribuições populacional e amostral 9.3 Erros amostrais e não amostrais 9.4 Média e desvio padrão da média 9.5 Teorema do Limite Central 9.6 Proporções populacional e amostral", " Capítulo 9 Distribuições Amostrais 9.1 Pacotes necessários para este capítulo pacman::p_load(dplyr, ggplot2, kableExtra, knitr, readxl) 9.2 Distribuições populacional e amostral Estatísticas da amostra, como a média, a mediana, a moda e o desvio padrão, são medidas numéricas de resumo calculadas para dados de uma amostra. Por outro lado, as mesmas medidas numéricas de resumo calculadas para dados populacionais são chamadas de parâmetros populacionais. Um parâmetro populacional é sempre uma constante, enquanto uma estatística de amostra é sempre uma variável aleatória. Como cada variável aleatória deve possuir uma distribuição de probabilidade, cada estatística de amostra possui uma distribuição de probabilidade. A distribuição de probabilidade de uma estatística de amostra é mais comumente chamada de distribuição amostral. Os conceitos abordados neste capítulo são a base da estatística inferencial. 9.2.1 Distribuição populacional A distribuição populacional é a distribuição de probabilidade derivada das informações sobre todos os elementos de uma população. O conjunto de dados de 1368 observações de puérperas e recém-nascidos da Maternidade-escola do Hospital Geral de Caxias do Sul, RS, será, para fins didáticos, considerado a população. O gráfico, abaixo, mostra a distribuição da altura das puérperas dessa ‘população’ (Figura 9.1). mater &lt;- readxl::read_excel(&quot;Arquivos/dadosMater.xlsx&quot;) media = mean(mater$altura, na.rm =TRUE) dp = sd(mater$altura, na.rm =TRUE) Figure 9.1: Histograma da altura de 1368 puérperas Os valores da média e do desvio padrão calculados para essa população fornecem os valores dos parâmetros populacionais \\(\\mu\\) e \\(\\sigma\\). Esses valores são \\(\\mu =\\) 1.598m e \\(\\sigma =\\) 0.065m. 9.2.2 Distribuição amostral Conforme mencionado no início deste capítulo, o valor de um parâmetro da população é sempre constante. Por exemplo, para qualquer conjunto de dados populacionais, há apenas um valor para a média populacional, \\(\\mu\\). No entanto, não se pode dizer o mesmo sobre a média amostral. Amostras diferentes do mesmo tamanho, retiradas da mesma população, produzem valores diferentes da média amostral, \\(\\bar{x}\\). O valor da média amostral, para qualquer amostra, dependerá dos elementos incluídos nessa amostra. Em decorrência, a média amostral é uma variável aleatória. Portanto, como outras variáveis aleatórias, a média amostral possui uma distribuição de probabilidade, que é mais comumente chamada de distribuição amostral da média. Outras estatísticas de amostra, como mediana, moda e desvio padrão, também possuem distribuições amostrais. Em geral, a distribuição de probabilidades de uma amostra é denominada de distribuição amostral. Voltando à variável altura das puérperas da Maternidade do HGCS, convencionada a priori como a população de interesse. Isso raramente acontece na vida real. Reunir informação sobre uma população inteira costuma ser muito custoso ou impossível. Por essa razão, a prática é selecionar apenas uma amostra da população e a usar para compreender as suas características. Usando a função slice_sample() do pacote dplyr, será extraída uma amostra de n = 30 da população e calculada a média e o desvio padrão: mater &lt;- readxl::read_excel(&quot;Arquivos/dadosMater.xlsx&quot;) %&gt;% dplyr::select(altura) amostra1 &lt;- mater %&gt;% dplyr::slice_sample(n = 30) media1 &lt;- mean(amostra1$altura, na.rm =TRUE) dp1 &lt;- sd(amostra1$altura, na.rm =TRUE) print(c(media1, dp1)) ## [1] 1.59600000 0.07636573 A amostra1 tem média igual a 1.596 e desvio padrão igual a 0.076. Se este processo for repetido várias vezes, ninguém ficará surpreso se, a cada amostra aleatória, a média amostral for diferente das anteriores, gerando médias e desvios padrão diferentes. amostra2 &lt;- mater %&gt;% dplyr::slice_sample(n = 30) media2 &lt;- mean(amostra2$altura, na.rm =TRUE) dp2 &lt;- sd(amostra2$altura, na.rm =TRUE) print(c(media2, dp2)) ## [1] 1.58266667 0.07362221 À medida que o número de amostras possíveis forem aumentando, elas constituem uma distribuição cuja média, média das médias, \\(\\bar{x}_{\\bar{x}}\\), é igual a média populacional, \\(\\mu\\). Essa distribuição, no caso da média, recebe o nome de distribuição amostral das médias. Agora, para exemplificar este conceito, serão geradas 5000 amostras e calculada a média de cada uma das amostras de n = 30 que constituirão a distribuição, mostrada no gráfico da Figura 9.2. # extraindo 5000 amostras amostras5000 &lt;- rep (0, 5000) for (i in 1:5000) { amostra &lt;- mater %&gt;% dplyr::slice_sample (n = 30) amostras5000 [i] &lt;- mean(amostra$altura) } # Media e desvio padrão das 5000 amostras round (mean (amostras5000), digits = 3) ## [1] 1.598 round (sd (amostras5000), digits = 3) ## [1] 0.012 Figure 9.2: Distribuição amostral das médias de 5000 amostras de n = 30 Se a média, \\(\\bar{x}_{\\bar{x}}\\), dessas 5000 amostras de n = 30, for comparada com a média populacional, \\(\\mu\\), observa-se que até 3 dígitos decimais não há uma diferença. Entretanto, o desvio padrão é bem menor (0.012) que o da população (0.065). 9.3 Erros amostrais e não amostrais Normalmente, amostras diferentes selecionadas da mesma população darão resultados diferentes porque contêm elementos diferentes. Isso é evidente nas medias das amostra1 e amostra2, 1.596m e 1.583m, respectivamente, comparadas com a média da população igual a 1.598m . erro1 &lt;- abs(mean(amostra1$altura, na.rm =TRUE) - mean(mater$altura, na.rm =TRUE)) round(erro1, 3) ## [1] 0.002 erro2 &lt;- abs(mean(amostra2$altura, na.rm =TRUE) - mean(mater$altura, na.rm =TRUE)) round(erro2, 3) ## [1] 0.015 Se outras amostras forem extraídas, o resultado obtido de qualquer amostra geralmente será diferente do resultado obtido da população correspondente. A diferença (erro) entre o valor de uma estatística amostral obtida de uma amostra e o valor do parâmetro populacional correspondente, é chamada de erro amostral. Observe que essa diferença representa o erro amostral apenas se a amostra for aleatória e não houver nenhum erro não amostral. Caso contrário, apenas uma parte dessa diferença será devido ao erro de amostragem. \\[ \\mu = \\bar{x}_{i} + erro \\quad amostral \\] É importante lembrar que o erro amostral ocorre devido ao acaso. Os erros que ocorrem por outros motivos, como erros cometidos durante a coleta, registro e tabulação dos dados, são chamados de erros não amostrais. Esses erros ocorrem, em geral, por causa de erros humanos e não por acaso. 9.4 Média e desvio padrão da média A média e o desvio padrão calculados para a distribuição amostral da média são chamados de média (\\(\\mu_{\\bar{x}}\\)) e desvio padrão (\\(\\sigma_{\\bar{x}}\\)) da média. Na verdade, a média e o desvio padrão da média são, respectivamente, a média e o desvio padrão das médias de todas as amostras do mesmo tamanho selecionadas de uma população. O desvio padrão da média é, comumente, chamado de erro padrão da média (\\(\\sigma_{\\bar{x}}\\)). A média amostral, \\(\\bar{x}\\), é chamada de estimador da média da população, \\(\\mu\\). Quando o valor esperado (ou média) de uma estatística amostral é igual ao valor do parâmetro populacional correspondente, essa estatística amostral é considerada um estimador não enviesado, consistente. Para a média amostral \\(\\bar{x}\\), \\(\\mu_{\\bar{x}} = \\mu\\). Logo, \\(\\bar{x}\\), é um estimador imparcial de \\(\\mu\\). Esta é uma propriedade muito importante que um estimador deve possuir. No entanto, o desvio padrão da média, \\(\\sigma_{\\bar{x}}\\), não é igual ao desvio padrão, \\(\\sigma\\), da distribuição populacional (a menos que n = 1). O desvio padrão da média amostral é igual ao desvio padrão da população dividido pela raiz quadrada do tamanho amostral: \\[ \\sigma_{\\bar{x}} = \\frac {\\sigma}{\\sqrt{n}} \\] A dispersão da distribuição amostral da média é menor do que dispersão da distribuição populacional correspondente, como mostrado acima. Em outras palavras, \\(\\sigma_{\\bar{x}} &lt; \\sigma\\). Isso é visível na fórmula do \\(\\sigma_{\\bar{x}}\\) . Quando n é maior que 1, o que geralmente é verdadeiro, o denominador em \\(\\frac {\\sigma}{\\sqrt{n}}\\) é maior que 1. Desta forma, \\(\\sigma_{\\bar{x}}\\) é menor que \\(\\sigma\\). O desvio padrão da distribuição amostral da média diminui à medida que o tamanho amostral aumenta. Sempre que o n for grande, em geral &gt; 30 (93), pode ser assumido que a distribuição será uma curva normal e que o desvio padrão da amostra (s) é um estimador não enviesado do desvio padrão populacional (\\(\\sigma\\)). Então, o erro padrão da média (\\(\\sigma_{\\bar{x}}\\)) pode ser estimado pelo \\(EP_{\\bar{x}}\\): \\[ EP_{\\bar{x}} = \\frac {s}{\\sqrt{n}} \\] 9.5 Teorema do Limite Central Na maioria das vezes, a população da qual as amostras são extraídas não é normalmente distribuída. Em tais casos, a forma da distribuição amostral de X é inferida de um teorema muito importante chamado teorema do limite central. De acordo com este teorema para um grande tamanho de amostra (&gt; 30), a distribuição amostral da média é aproximadamente normal, independentemente da forma da distribuição da população (93). Esta aproximação tornar-se-á mais acurada à medida que aumenta o tamanho amostral: a média da distribuição amostral, \\(\\mu_{\\bar{x}}\\), é igual a média populacional, \\(\\mu\\); desvio padrão da distribuição amostral, \\(\\sigma_{\\bar{x}}\\), é igual a \\(\\frac {\\sigma}{\\sqrt{n}}\\); o erro padrão da média, \\(\\sigma_{\\bar{x}}\\), é sempre menor que o desvio padrão populacional, \\(\\sigma\\) (Figura 9.3). Figure 9.3: Erro padrão versus desvio padrão. Se for tomado como exemplo a variável renda, do conjunto de dados dadosMater.xlsx, que representa a renda familiar em salários mínimos (SM. Como foi feito anteriormente, suponha que essa variável seja a população de estudo. Ela tem as seguintes medidas resumidoras e de assimetria: mater &lt;- readxl::read_excel(&quot;Arquivos/dadosMater.xlsx&quot;) media.sm &lt;- mean (mater$renda, na.rm = TRUE) media.sm ## [1] 2.224949 dp.sm &lt;- sd(mater$renda, na.rm = TRUE) dp.sm ## [1] 1.226359 mediana.sm &lt;- median(mater$renda, na.rm = TRUE) mediana.sm ## [1] 1.92 print(moments::skewness(mater$renda)) ## [1] 2.223336 print(moments::kurtosis(mater$renda)) ## [1] 11.22392 O desvio padrão é grande em relação à média, com um coeficiente de variação de 55.1185153% e uma mediana &lt; média. Estas métricas junto com os coeficientes de assimetria e curtose apontam para a assimetria positiva da variável renda familiar. O gráfico da Figura 9.4 confirma esta afirmação: Figure 9.4: Distribuição assimétrica positiva Os valores da média e do desvio padrão calculados para a distribuição de probabilidade dessa população fornecem os valores dos parâmetros populacionais \\(\\mu\\) e \\(\\sigma\\). Esses valores são \\(\\mu =\\) 2.225m e \\(\\sigma =\\) 1.226m. Se extrairmos múltiplas amostras dessa população, observa-se a modificação do formato da distribuição à medida que aumenta o tamanho amostral, se aproximando progressivamente do modelo normal, com um número grande de amostras. # extraindo 1000 amostras amostras1000 &lt;- rep (0, 1000) for (i in 1:1000) { amostra.sm &lt;- sample (mater$renda, 30) amostras1000 [i] &lt;- mean(amostra.sm) } # Media e desvio padrão das 1000 amostras round (mean (amostras1000), digits = 3) ## [1] 2.221 round (sd (amostras1000), digits = 3) ## [1] 0.22 round (median(amostras1000), digits = 3) ## [1] 2.218 print(moments::skewness(amostras1000)) ## [1] 0.2404874 print(moments::kurtosis(amostras1000)) ## [1] 2.857316 Figure 9.5: Distribuição praticamente normal Ou seja, extraindo-se 1000 amostras de n = 30 e calculando as mesmas métricas anteriores, verifica-se que, agora, a variável está com distribuição praticamente normal (Figura 9.5). 9.6 Proporções populacional e amostral O conceito de proporção é o mesmo que o conceito de frequência relativa e o conceito de probabilidade de sucesso em um experimento binomial, discutidos anteriormente, na distribuição binomial. A frequência relativa de uma categoria ou classe dá a proporção da amostra ou população que pertence a essa categoria ou classe. Da mesma forma, a probabilidade de sucesso em um experimento binomial representa a proporção da amostra ou população que possui uma determinada característica. A proporção populacional, representada por p, é obtida considerando a razão entre o número de elementos em uma população com uma característica específica e o número total de elementos na população. A proporção amostral, denotada por \\(\\hat{p}\\) (pronuncia-se p-chapéu), fornece uma proporção semelhante para uma amostra. \\[ p = \\frac{X}{N} \\quad e \\quad \\hat{p}= \\frac{x}{n} \\] onde, N = número total de elementos em uma população n = número total de elementos em uma amostra X = número de elementos na população que possui determinada característica x = número de elementos na amostra que possui determinada característica Como no caso da média, a diferença entre a proporção amostral e a proporção populacional correspondente, determina o erro amostral, assumindo que a amostra é aleatória e nenhum erro não amostral foi cometido. Ou seja, \\[ erro \\quad amostral = \\hat{p} - p \\] No conjunto de dados dadosMater.xlsx, pserá veriificado a proporção de fumantes com: mater &lt;- readxl::read_excel(&quot;Arquivos/dadosMater.xlsx&quot;) mater$fumo &lt;- factor (mater$fumo, levels = c (1,2), label = c (&quot;sim&quot;, &quot;não&quot;)) fumo &lt;- with(mater, table(fumo)) fr.fumo &lt;- prop.table(fumo) Assim, a proporção de gestantes fumantes foi de 0.22. Considerando que este resultado fosse desconhecido e que as mulheres da maternidade do HGCS fosse a população, para verificar a proporção de mulheres fumantes, se extrairá uma amostra de n = 100 (Tabela 9.1). amostra.fumo &lt;- mater %&gt;% dplyr::slice_sample(n = 100) tabagismo &lt;- with(amostra.fumo, table(fumo)) fr &lt;- prop.table(tabagismo) fp &lt;- fr*100 tab.fumo &lt;- cbind(n = tabagismo, fr = round(fr, 2), fp = round(fp, 2)) tab.fumo &lt;- as.data.frame(tab.fumo) Table 9.1: Proporção de Tabagismo nas gestantes n Freq. Relativa Freq. Percentual sim 23 0.23 23 não 77 0.77 77 A proporção de uma amostra é uma variável aleatória: varia de amostra para amostra de uma forma que não pode ser prevista com certeza. Foi visto que esta variável aleatória é escrita como \\(\\hat{p}\\). E que tem uma média \\(\\mu_{\\hat{p}}\\) e um desvio padrão \\(\\sigma_{\\hat{p}}\\). Suponha que amostras aleatórias de tamanho n sejam retiradas de uma população na qual a proporção com uma característica de interesse seja p. A média e o desvio padrão da proporção amostral \\(\\hat{p}\\) satisfazem \\[ \\mu_{\\hat{p}} = p \\quad e \\quad \\sigma_{\\hat{p}}= \\sqrt{\\frac{pq}{n}} \\] O Teorema do Limite Central também se aplica aqui. No entanto, a condição de que a amostra seja grande é um pouco mais complicada do que apenas ter um tamanho de pelo menos 30. 9.6.1 Distribuição amostral da proporção amostral Para amostras grandes, a proporção amostral é aproximadamente normalmente distribuída, com média \\(\\mu_{\\hat{p}} = p\\) e desvio padrão \\(\\sigma_{\\hat{p}}= \\sqrt{\\frac{pq}{n}}\\). Uma amostra é grande se o intervalo [\\(p - 3\\sigma_{\\hat{p}}\\), \\(p + 3\\sigma_{\\hat{p}}\\)] estiver totalmente dentro do intervalo [0,1]. Na prática, p não é conhecido, portanto, \\(\\sigma_{\\hat{p}}\\) também não é. Nesse caso, para verificar se a amostra é suficientemente grande, substitui-se o valor de p pelo valor conhecido de \\(\\hat{p}\\). Isso significa verificar se o intervalo encontra-se totalmente dentro do intervalo [0,1], usando: \\[ \\left(\\hat{p} - 3 \\times\\sqrt{\\frac{\\hat{p}(1 - \\hat{p})}{n}}, \\quad \\hat{p} + 3\\times\\sqrt{\\frac{\\hat{p}(1 - \\hat{p})}{n}}\\right) \\] Transportando os dados da amostra de gestantes, para a fórmula e usando o R para o cálculo, tem-se: p.chapeu &lt;- tab.fumo[1,2] n &lt;- tab.fumo[1,1] + tab.fumo[2,1] li &lt;- p.chapeu - 3*sqrt((p.chapeu*(1-p.chapeu))/n) li ## [1] 0.1037502 ls &lt;- p.chapeu + 3*sqrt((p.chapeu*(1-p.chapeu))/n) ls ## [1] 0.3562498 Dessa forma, tem-se que a amostra de n = 100 é aceitável para uma população onde p = 0.22 "],["referências.html", "Referências", " Referências "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
